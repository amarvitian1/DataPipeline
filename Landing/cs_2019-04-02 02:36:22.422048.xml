<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>cs updates on arXiv.org</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">Computer Science (cs) updates on the arXiv.org e-print archive</description>
<dc:language>en-us</dc:language>
<dc:date>2019-04-01T20:30:00-05:00</dc:date>
<dc:publisher>www-admin@arxiv.org</dc:publisher>
<dc:subject>Computer Science</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00001" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00003" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00004" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00008" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00009" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00014" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00035" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00044" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00045" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00048" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00049" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00051" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00055" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00057" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00058" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00063" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00068" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00069" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00070" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00071" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00073" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00077" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00078" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00079" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00093" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00101" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00103" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00107" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00110" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00112" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00118" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00124" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00129" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00132" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00138" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00141" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00143" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00150" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00152" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00156" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00157" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00158" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00160" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00167" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00168" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00170" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00172" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00173" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00176" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00182" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00184" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00187" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00188" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00189" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00195" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00197" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00198" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00200" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00202" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00205" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00224" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00226" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00227" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00229" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00230" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00231" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00234" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00237" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00240" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00242" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00243" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00244" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00247" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00248" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00249" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00264" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00275" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00276" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00277" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00284" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00285" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00287" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00289" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00291" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00296" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00303" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00306" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00310" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00313" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00314" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00315" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00317" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00318" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00319" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00320" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00324" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00325" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00326" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00327" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00328" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00335" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00338" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00344" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00346" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00349" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00350" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00352" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00355" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00357" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00358" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00365" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00368" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00370" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00373" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00374" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00375" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00377" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00378" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00381" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00386" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00388" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00389" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00392" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00396" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00402" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00403" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00411" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00415" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00420" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00421" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00424" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00433" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00435" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00438" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00441" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00442" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00445" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00447" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00450" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00453" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00457" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00459" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00460" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00462" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00463" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00464" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00469" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00472" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00478" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00479" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00484" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00503" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00507" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00510" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00511" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00512" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00513" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00516" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00518" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00523" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00526" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00537" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00538" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00540" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00542" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00548" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00549" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00551" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00553" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00558" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00560" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00561" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00562" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00566" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00575" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00577" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00579" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00583" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00585" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00592" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00597" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00601" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00605" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00607" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00609" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00613" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00614" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00615" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00616" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00617" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00618" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00619" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00620" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00623" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00625" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00629" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00631" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00634" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00637" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00639" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00641" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00646" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00647" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00648" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00649" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00655" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00661" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00664" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00665" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00669" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00670" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00671" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00672" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00674" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00676" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00680" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00682" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00685" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00687" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00688" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00689" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00690" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00691" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00692" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00696" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00699" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00702" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00704" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00708" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00712" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00714" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00717" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00720" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00721" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00722" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00724" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00726" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00727" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00731" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00732" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00733" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00734" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00735" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00736" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00737" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00738" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00739" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00740" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00741" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00742" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00744" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00746" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00747" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00748" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00750" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00753" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00758" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00759" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00760" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00761" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00762" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00763" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00764" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00765" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00766" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00767" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00768" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00770" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00771" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00775" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00776" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00781" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00783" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00784" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00785" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00786" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00787" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00788" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00790" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00791" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00792" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00796" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00800" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00805" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00812" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00813" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00815" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00816" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00817" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00818" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00820" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00824" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00825" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00827" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00830" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00832" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00833" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00836" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00838" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00839" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00842" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00850" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00853" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00859" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00863" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00864" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00865" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00868" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00876" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00880" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00887" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00889" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00904" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00905" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00906" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00912" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00923" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00928" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00929" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00930" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00934" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00935" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00936" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00937" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00938" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00942" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00943" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00944" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00946" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00948" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00952" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00954" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00956" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00962" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00964" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00973" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00976" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00977" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00979" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00982" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00987" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00993" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1904.00996" />
  <rdf:li rdf:resource="http://arxiv.org/abs/0801.3669" />
  <rdf:li rdf:resource="http://arxiv.org/abs/0801.3680" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1308.3301" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1409.6365" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1606.09589" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1610.02336" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1701.03077" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1701.04695" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1706.03459" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1706.04894" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1707.08552" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1708.00598" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1708.01706" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1709.06965" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1711.00681" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1711.06705" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1712.08268" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1803.10431" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1804.00257" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1804.01429" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1804.02973" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1804.07888" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1805.00257" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1805.02628" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1805.03472" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1805.04882" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1805.06262" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1805.12279" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1806.06575" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1807.01455" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1807.01989" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1807.04193" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1807.06403" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1807.11399" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1808.00327" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1808.03216" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1808.05678" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1808.07042" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1808.07747" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1808.08983" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1809.01752" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1809.02156" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1809.02341" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1809.03551" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1809.05725" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1809.06180" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1809.06963" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1809.07764" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1809.09478" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1810.00495" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1810.01405" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1810.03450" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1810.03980" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1810.06985" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1810.08276" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1810.08380" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1810.10121" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1810.11829" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1810.11968" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1810.13137" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1811.01233" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1811.01248" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1811.04713" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1811.04815" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1811.06397" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1811.08982" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1811.09751" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1811.09845" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1811.10322" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1811.10983" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1811.11205" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1811.11431" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1811.12019" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1811.12104" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1812.00202" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1812.00408" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1812.01243" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1812.01659" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1812.01687" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1812.02532" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1812.03050" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1812.04081" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1812.04368" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1812.04478" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1812.05866" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1812.07045" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1812.09526" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1812.09658" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1812.10956" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1901.01062" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1901.01751" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1901.01874" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1901.02182" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1901.02808" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1901.03146" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1901.04106" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1901.04452" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1901.04846" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1901.06587" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1901.07226" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1901.07675" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1901.11512" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1902.00629" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1902.03223" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1902.03988" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1902.05379" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1902.05965" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1902.06042" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1902.06384" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1902.08982" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1902.09314" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1902.09514" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1902.09679" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1902.10658" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1902.10807" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.00237" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.02163" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.03178" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.03243" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.03495" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.05164" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.05942" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.07221" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.09022" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.09094" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.09341" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.09722" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.09769" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.09795" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.09847" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.09927" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.10841" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.11054" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.11205" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.11394" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.11444" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.11783" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.11848" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12020" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12141" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12287" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12436" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12453" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12600" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.10209" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.11579" />
 </rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image>
<item rdf:about="http://arxiv.org/abs/1904.00001">
<title>Open Problems in Engineering Machine Learning Systems and the Quality Model. (arXiv:1904.00001v1 [cs.SE])</title>
<link>http://arxiv.org/abs/1904.00001</link>
<description rdf:parseType="Literal">&lt;p&gt;Fatal accidents are a major issue hindering the wide acceptance of
safety-critical systems that use machine learning and deep learning models,
such as automated driving vehicles. To use machine learning in a
safety-critical system, it is necessary to demonstrate the safety and security
of the system to society through the engineering process. However, there have
been no such total concepts or frameworks established for these systems that
have been widely accepted, and needs or open problems are not organized in a
way researchers can select a theme and work on. The key to using a machine
learning model in a deductively engineered system, developed in a rigorous
development lifecycle consisting of requirement, design, and verification, cf.
V-Model, is decomposing the data-driven training of machine-learning models
into requirement, design, and verification, especially for machine learning
models used in safety-critical systems. In this study, we identify, classify,
and explore the open problems in engineering (safety-critical) machine learning
systems, i.e., requirement, design, and verification of machine learning models
and systems, as well as related works and research directions, using automated
driving vehicles as an example. We also discuss the introduction of
machine-learning models into a conventional system quality model such as SQuARE
to study the quality model for machine learning systems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kuwajima_H/0/1/0/all/0/1&quot;&gt;Hiroshi Kuwajima&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yasuoka_H/0/1/0/all/0/1&quot;&gt;Hirotoshi Yasuoka&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nakae_T/0/1/0/all/0/1&quot;&gt;Toshihiro Nakae&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00003">
<title>Firsthand Opiates Abuse on Social Media: Monitoring Geospatial Patterns of Interest Through a Digital Cohort. (arXiv:1904.00003v1 [cs.CY])</title>
<link>http://arxiv.org/abs/1904.00003</link>
<description rdf:parseType="Literal">&lt;p&gt;In the last decade drug overdose deaths reached staggering proportions in the
US. Besides the raw yearly deaths count that is worrisome per se, an alarming
picture comes from the steep acceleration of such rate that increased by 21%
from 2015 to 2016. While traditional public health surveillance suffers from
its own biases and limitations, digital epidemiology offers a new lens to
extract signals from Web and Social Media that might be complementary to
official statistics. In this paper we present a computational approach to
identify a digital cohort that might provide an updated and complementary view
on the opioid crisis. We introduce an information retrieval algorithm suitable
to identify relevant subspaces of discussion on social media, for mining data
from users showing explicit interest in discussions about opioid consumption in
Reddit. Moreover, despite the pseudonymous nature of the user base, almost 1.5
million users were geolocated at the US state level, resembling the census
population distribution with a good agreement. A measure of prevalence of
interest in opiate consumption has been estimated at the state level, producing
a novel indicator with information that is not entirely encoded in the standard
surveillance. Finally, we further provide a domain specific vocabulary
containing informal lexicon and street nomenclature extracted by user-generated
content that can be used by researchers and practitioners to implement novel
digital public health surveillance methodologies for supporting policy makers
in fighting the opioid epidemic.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Balsamo_D/0/1/0/all/0/1&quot;&gt;Duilio Balsamo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bajardi_P/0/1/0/all/0/1&quot;&gt;Paolo Bajardi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Panisson_A/0/1/0/all/0/1&quot;&gt;Andr&amp;#xe9; Panisson&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00004">
<title>Tweeting MPs: Digital Engagement between Citizens and Members of Parliament in the UK. (arXiv:1904.00004v1 [cs.SI])</title>
<link>http://arxiv.org/abs/1904.00004</link>
<description rdf:parseType="Literal">&lt;p&gt;Disengagement and disenchantment with the Parliamentary process is an
important concern in today&apos;s Western democracies. Members of Parliament (MPs)
in the UK are therefore seeking new ways to engage with citizens, including
being on digital platforms such as Twitter. In recent years, nearly all (579
out of 650) MPs have created Twitter accounts, and have amassed huge followings
comparable to a sizable fraction of the country&apos;s population. This paper seeks
to shed light on this phenomenon by examining the volume and nature of the
interaction between MPs and citizens. We find that although there is an
information overload on MPs, attention on individual MPs is focused during
small time windows when something topical may be happening relating to them.
MPs manage their interaction strategically, replying selectively to UK-based
citizens and thereby serving in their role as elected representatives, and
using retweets to spread their party&apos;s message. Most promisingly, we find that
Twitter opens up new avenues with substantial volumes of cross-party
interaction, between MPs of one party and citizens who support (follow) MPs of
other parties.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Agarwal_P/0/1/0/all/0/1&quot;&gt;Pushkal Agarwal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sastry_N/0/1/0/all/0/1&quot;&gt;Nishanth Sastry&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wood_E/0/1/0/all/0/1&quot;&gt;Edward Wood&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00008">
<title>Quadrotor Manipulation System: Development of a Robust Contact Force Estimation and Impedance Control Scheme Based on DOb and FTRLS. (arXiv:1904.00008v1 [cs.RO])</title>
<link>http://arxiv.org/abs/1904.00008</link>
<description rdf:parseType="Literal">&lt;p&gt;The research on aerial manipulation systems has been increased rapidly in
recent years. These systems are very attractive for a wide range of
applications due to their unique features. However, dynamics, control and
manipulation tasks of such systems are quite challenging because they are
naturally unstable, have very fast dynamics, have strong nonlinearities, are
very susceptible to parameters variations due to carrying a payload besides the
external disturbances, and have complex inverse kinematics. In addition, the
manipulation tasks require estimating (applying) a certain force of (at) the
end-effector as well as the accurate positioning of it. Thus, in this article,
a robust force estimation and impedance control scheme is proposed to address
these issues. The robustness is achieved based on the Disturbance Observer
(DOb) technique. Then, a tracking and performance low computational linear
controller is used. For teleoperation purpose, the contact force needs to be
identified. However, the current developed techniques for force estimation have
limitations because they are based on ignoring some dynamics and/or requiring
of an indicator of the environment contact. Unlike these techniques, we propose
a technique based on linearization capabilities of DOb and a Fast Tracking
Recursive Least Squares (FTRLS) algorithm. The complex inverse kinematics
problem of such a system is solved by a Jacobin based algorithm. The stability
analysis of the proposed scheme is presented. The algorithm is tested to
achieve tracking of task space reference trajectories besides the impedance
control. The efficiency of the proposed technique is enlightened via numerical
simulation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khalifa_A/0/1/0/all/0/1&quot;&gt;Ahmed Khalifa&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fanni_M/0/1/0/all/0/1&quot;&gt;Mohamed Fanni&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00009">
<title>Reconstructing Rational Functions with $\texttt{FireFly}$. (arXiv:1904.00009v1 [cs.SC])</title>
<link>http://arxiv.org/abs/1904.00009</link>
<description rdf:parseType="Literal">&lt;p&gt;We present the open-source $\texttt{C++}$ library $\texttt{FireFly}$ for the
reconstruction of multivariate rational functions over finite fields. We
discuss the involved algorithms and their implementation. As an application, we
use $\texttt{FireFly}$ in the context of integration-by-parts reductions and
compare runtime and memory consumption to a fully algebraic approach with the
program $\texttt{Kira}$.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Klappert_J/0/1/0/all/0/1&quot;&gt;Jonas Klappert&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lange_F/0/1/0/all/0/1&quot;&gt;Fabian Lange&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00014">
<title>RAPID: Early Classification of Explosive Transients using Deep Learning. (arXiv:1904.00014v1 [astro-ph.IM])</title>
<link>http://arxiv.org/abs/1904.00014</link>
<description rdf:parseType="Literal">&lt;p&gt;We present RAPID (Real-time Automated Photometric IDentification), a novel
time-series classification tool capable of automatically identifying transients
from within a day of the initial alert, to the full lifetime of a light curve.
Using a deep recurrent neural network with Gated Recurrent Units (GRUs), we
present the first method specifically designed to provide early classifications
of astronomical time-series data, typing 12 different transient classes. Our
classifier can process light curves with any phase coverage, and it does not
rely on deriving computationally expensive features from the data, making RAPID
well-suited for processing the millions of alerts that ongoing and upcoming
wide-field surveys such as the Zwicky Transient Facility (ZTF), and the Large
Synoptic Survey Telescope (LSST) will produce. The classification accuracy
improves over the lifetime of the transient as more photometric data becomes
available, and across the 12 transient classes, we obtain an average area under
the receiver operating characteristic curve of 0.95 and 0.98 at early and late
epochs, respectively. We demonstrate RAPID&apos;s ability to effectively provide
early classifications of transients from the ZTF data stream. We have made
RAPID available as an open-source software package
(https://astrorapid.readthedocs.io) for machine learning-based alert-brokers to
use for the autonomous and quick classification of several thousand light
curves within a few seconds.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+Muthukrishna_D/0/1/0/all/0/1&quot;&gt;Daniel Muthukrishna&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+Narayan_G/0/1/0/all/0/1&quot;&gt;Gautham Narayan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+Mandel_K/0/1/0/all/0/1&quot;&gt;Kaisey S. Mandel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+Biswas_R/0/1/0/all/0/1&quot;&gt;Rahul Biswas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+Hlozek_R/0/1/0/all/0/1&quot;&gt;Ren&amp;#xe9;e Hlo&amp;#x17e;ek&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00035">
<title>Autonomous Highway Driving using Deep Reinforcement Learning. (arXiv:1904.00035v1 [cs.RO])</title>
<link>http://arxiv.org/abs/1904.00035</link>
<description rdf:parseType="Literal">&lt;p&gt;The operational space of an autonomous vehicle (AV) can be diverse and vary
significantly. This may lead to a scenario that was not postulated in the
design phase. Due to this, formulating a rule based decision maker for
selecting maneuvers may not be ideal. Similarly, it may not be effective to
design an a-priori cost function and then solve the optimal control problem in
real-time. In order to address these issues and to avoid peculiar behaviors
when encountering unforeseen scenario, we propose a reinforcement learning (RL)
based method, where the ego car, i.e., an autonomous vehicle, learns to make
decisions by directly interacting with simulated traffic. The decision maker
for AV is implemented as a deep neural network providing an action choice for a
given system state. In a critical application such as driving, an RL agent
without explicit notion of safety may not converge or it may need extremely
large number of samples before finding a reliable policy. To best address the
issue, this paper incorporates reinforcement learning with an additional short
horizon safety check (SC). In a critical scenario, the safety check will also
provide an alternate safe action to the agent provided if it exists. This leads
to two novel contributions. First, it generalizes the states that could lead to
undesirable &quot;near-misses&quot; or &quot;collisions &quot;. Second, inclusion of safety check
can provide a safe and stable training environment. This significantly enhances
learning efficiency without inhibiting meaningful exploration to ensure safe
and optimal learned behavior. We demonstrate the performance of the developed
algorithm in highway driving scenario where the trained AV encounters varying
traffic density in a highway setting.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nageshrao_S/0/1/0/all/0/1&quot;&gt;Subramanya Nageshrao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tseng_E/0/1/0/all/0/1&quot;&gt;Eric Tseng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Filev_D/0/1/0/all/0/1&quot;&gt;Dimitar Filev&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00044">
<title>Graph Computing based Fast Screening in Contingency Analysis. (arXiv:1904.00044v1 [cs.DC])</title>
<link>http://arxiv.org/abs/1904.00044</link>
<description rdf:parseType="Literal">&lt;p&gt;During last decades, contingency analysis has been facing challenges from
significant load demand increase and high penetrations of intermittent
renewable energy, fluctuant responsive loads and non-linear power electronic
interfaces. It requires an advanced approach for high-performance contingency
analysis as a safeguard of the power system operation. In this paper, a
graph-based method is employed for N-1 contingency analysis (CA) fast
screening. At first, bi-directional breadth-first search (BFS) is proposed and
adopted on graph model to detect the potential shedding component in
contingency analysis. It implements hierarchical parallelism of the graph
traverse and speedup its process. Then, the idea of evolving graph is
introduced in this paper to improve computation performance. For each
contingency scenario, N-1 contingency graph quickly derives from system graph
in basic status, and parallelly analyzes each contingency scenario using graph
computing. The efficiency and effectiveness of the proposed approach have been
tested and verified by IEEE 118-bus system and a practical case SC 2645-bus
system.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1&quot;&gt;Yiting Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yuan_C/0/1/0/all/0/1&quot;&gt;Chen Yuan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1&quot;&gt;Sun Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_G/0/1/0/all/0/1&quot;&gt;Guangyi Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dai_R/0/1/0/all/0/1&quot;&gt;Renchang Dai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1&quot;&gt;Zhiwei Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00045">
<title>Interpreting Black Box Models with Statistical Guarantees. (arXiv:1904.00045v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1904.00045</link>
<description rdf:parseType="Literal">&lt;p&gt;While many methods for interpreting machine learning models have been
proposed, they are frequently ad hoc, difficult to evaluate, and come with no
statistical guarantees on the error rate. This is especially problematic in
scientific domains, where interpretations must be accurate and reliable. In
this paper, we cast black box model interpretation as a hypothesis testing
problem. The task is to discover &quot;important&quot; features by testing whether the
model prediction is significantly different from what would be expected if the
features were replaced with randomly-sampled counterfactuals. We derive a
multiple hypothesis testing framework for finding important features that
enables control over the false discovery rate. We propose two testing methods,
as well as analogs of one-sided and two-sided tests. In simulation, the methods
have high power and compare favorably against existing interpretability
methods. When applied to vision and language models, the framework selects
features that intuitively explain model predictions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Burns_C/0/1/0/all/0/1&quot;&gt;Collin Burns&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Thomason_J/0/1/0/all/0/1&quot;&gt;Jesse Thomason&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Tansey_W/0/1/0/all/0/1&quot;&gt;Wesley Tansey&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00048">
<title>SE2Net: Siamese Edge-Enhancement Network for Salient Object Detection. (arXiv:1904.00048v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1904.00048</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep convolutional neural network significantly boosted the capability of
salient object detection in handling large variations of scenes and object
appearances. However, convolution operations seek to generate strong responses
on individual pixels, while lack the ability to maintain the spatial structure
of objects. Moreover, the down-sampling operations, such as pooling and
striding, lose spatial details of the salient objects. In this paper, we
propose a simple yet effective Siamese Edge-Enhancement Network (SE2Net) to
preserve the edge structure for salient object detection. Specifically, a novel
multi-stage siamese network is built to aggregate the low-level and high-level
features, and parallelly estimate the salient maps of edges and regions. As a
result, the predicted regions become more accurate by enhancing the responses
at edges, and the predicted edges become more semantic by suppressing the false
positives in background. After the refined salient maps of edges and regions
are produced by the SE2Net, an edge-guided inference algorithm is designed to
further improve the resulting salient masks along the predicted edges.
Extensive experiments on several benchmark datasets have been conducted, which
show that our method is superior than the state-of-the-art approaches.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_S/0/1/0/all/0/1&quot;&gt;Sanping Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1&quot;&gt;Jinjun Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_F/0/1/0/all/0/1&quot;&gt;Fei Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_D/0/1/0/all/0/1&quot;&gt;Dong Huang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00049">
<title>Cryptographic key distribution over a public network via variance-based watermarking in compressive measurements. (arXiv:1904.00049v1 [cs.CR])</title>
<link>http://arxiv.org/abs/1904.00049</link>
<description rdf:parseType="Literal">&lt;p&gt;The optical communication has an increasing need for security in public
transmission scenarios. Here we present a protocol for cryptographic key
distribution over a public network via photon-counting compressive imaging
system with watermarking, which utilizes watermarking technique to distribute
secure keys, and uses reconstructed images for simultaneous identity
authentication and tampering identification. The watermark is embedded in the
rearranged compressed measurements of the object, and then the signal is
transmitted through a public network. At the receiving terminal, the legitimate
users can easily extract the watermark as the cryptographic key by using
initial keys and the variance characteristic of random measurements. Artificial
tampering and attacks can be detected by the accurately retrieved images. The
realization of this protocol is a step forward toward the practical
applications, and will be beneficial for the broader fields of optical security
in many ways.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_W/0/1/0/all/0/1&quot;&gt;Wen-Kai Yu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00051">
<title>Solving large Minimum Vertex Cover problems on a quantum annealer. (arXiv:1904.00051v1 [quant-ph])</title>
<link>http://arxiv.org/abs/1904.00051</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider the minimum vertex cover problem having applications in e.g.
biochemistry and network security. Quantum annealers can find the optimum
solution of such NP-hard problems, given they can be embedded on the hardware.
This is often infeasible due to limitations of the hardware connectivity
structure. This paper presents a decomposition algorithm for the minimum vertex
cover problem: The algorithm recursively divides an arbitrary problem until the
generated subproblems can be embedded and solved on the annealer. To speed up
the decomposition, we propose several pruning and reduction techniques. The
performance of our algorithm is assessed in a simulation study.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Pelofske_E/0/1/0/all/0/1&quot;&gt;Elijah Pelofske&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Hahn_G/0/1/0/all/0/1&quot;&gt;Georg Hahn&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Djidjev_H/0/1/0/all/0/1&quot;&gt;Hristo N. Djidjev&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00055">
<title>Joining Sound Event Detection and Localization Through Spatial Segregation. (arXiv:1904.00055v1 [cs.SD])</title>
<link>http://arxiv.org/abs/1904.00055</link>
<description rdf:parseType="Literal">&lt;p&gt;Identification and localization of sounds are both integral parts of
computational auditory scene analysis. Although each can be solved separately,
the goal of forming coherent auditory objects and achieving a comprehensive
spatial scene understanding suggests pursuing a joint solution of the two
problems. This work presents an approach that robustly binds localization with
the detection of sound events in a binaural robotic system. Both tasks are
joined through the use of spatial stream segregation which produces
probabilistic time-frequency masks for individual sources attributable to
separate locations, enabling segregated sound event detection operating on
these streams. We use simulations of a comprehensive suite of test scenes with
multiple co-occurring sound sources, and propose performance measures for
systematic investigation of the impact of scene complexity on this segregated
detection of sound types. Analyzing the effect of head orientation, we show how
a robot can facilitate high performance through optimal head rotation.
Furthermore, we investigate the performance of segregated detection given
possible localization error as well as error in the estimation of number of
active sources. Our analysis demonstrates that the proposed approach is an
effective method to obtain joint sound event location and type information
under a wide range of conditions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Trowitzsch_I/0/1/0/all/0/1&quot;&gt;Ivo Trowitzsch&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schymura_C/0/1/0/all/0/1&quot;&gt;Christopher Schymura&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kolossa_D/0/1/0/all/0/1&quot;&gt;Dorothea Kolossa&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Obermayer_K/0/1/0/all/0/1&quot;&gt;Klaus Obermayer&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00057">
<title>PAC Learnability of nuclear masses. (arXiv:1904.00057v1 [nucl-th])</title>
<link>http://arxiv.org/abs/1904.00057</link>
<description rdf:parseType="Literal">&lt;p&gt;After more than 80 years from the seminal work of Weizs\&quot;acker and the liquid
drop model of the atomic nucleus, theoretical errors over nuclear masses
($\sim$ MeV) are order of magnitudes larger than experimental ones ($\lesssim$
keV). Predicting the mass of atomic nuclei is with precision is extremely
challenging due to the non--trivial many--body interplay of protons and
neutrons in nuclei, and the complex nature of the nuclear strong force. This
paper argues that the arduous development of nuclear physics in the passed
century is due to the exploration of a system on the limit of the
knowledgeable, defined within the statistical theory of learning.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/nucl-th/1/au:+Idini_A/0/1/0/all/0/1&quot;&gt;Andrea Idini&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00058">
<title>From DB-nets to Coloured Petri Nets with Priorities (Extended Version). (arXiv:1904.00058v1 [cs.LO])</title>
<link>http://arxiv.org/abs/1904.00058</link>
<description rdf:parseType="Literal">&lt;p&gt;The recently introduced formalism of DB-nets has brought in a new conceptual
way of modelling complex dynamic systems that equally account for the process
and data dimensions, considering local data as well as persistent,
transactional data. DB-nets combine a coloured variant of Petri nets with name
creation and management (which we call nu-CPN), with a relational database. The
integration of these two components is realized by equipping the net with
special ``view&apos;&apos; places that query the database and expose the resulting
answers to the net, with actions that allow transitions to update the content
of the database, and with special arcs capturing compensation in case of
transaction failure. In this work, we study whether this sophisticated model
can be encoded back into nu-CPNs. In particular, we show that the meaningful
fragment of DB-nets where database queries are expressed using unions of
conjunctive queries with inequalities can be faithfully encoded into $\nu$-CPNs
with transition priorities. This allows us to directly exploit state-of-the-art
technologies such as CPN Tools to simulate and analyse this relevant class of
DB-nets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Montali_M/0/1/0/all/0/1&quot;&gt;Marco Montali&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rivkin_A/0/1/0/all/0/1&quot;&gt;Andrey Rivkin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00063">
<title>Multi-Scale Time-Frequency Attention for Rare Sound Event Detection. (arXiv:1904.00063v1 [cs.SD])</title>
<link>http://arxiv.org/abs/1904.00063</link>
<description rdf:parseType="Literal">&lt;p&gt;Attention mechanism has been widely applied to various sound-related tasks.
In this work, we propose a Multi-Scale Time-Frequency Attention (MTFA) module
for sound event detection. By generating an attention heatmap, MTFA enables the
model to focus on discriminative components of the spectrogram along both time
and frequency axis. Besides, gathering information at multiple scales helps the
model adapt better to the characteristics of different categories of target
events. The proposed method is demonstrated on task 2 of Detection and
Classification of Acoustic Scenes and Events (DCASE) 2017 Challenge. To the
best of our knowledge, our method outperforms all previous methods that don&apos;t
use model ensemble on development dataset and achieves state-of-the-art on
evaluation dataset by reducing the error rate to 0.09 from 0.13. This
demonstrates the effectiveness of MTFA on retrieving discriminative
representations for sound event detection.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1&quot;&gt;Jingyang Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ding_W/0/1/0/all/0/1&quot;&gt;Wenhao Ding&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kang_J/0/1/0/all/0/1&quot;&gt;Jintao Kang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+He_L/0/1/0/all/0/1&quot;&gt;Liang He&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00068">
<title>Brain Tissue Segmentation Using NeuroNet With Different Pre-processing Techniques. (arXiv:1904.00068v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1904.00068</link>
<description rdf:parseType="Literal">&lt;p&gt;Automatic segmentation of brain Magnetic Resonance Imaging (MRI) images is
one of the vital steps for quantitative analysis of brain for further
inspection. In this paper, NeuroNet has been adopted to segment the brain
tissues (white matter (WM), grey matter (GM) and cerebrospinal fluid (CSF))
which uses Residual Network (ResNet) in encoder and Fully Convolution Network
(FCN) in the decoder. To achieve the best performance, various hyper-parameters
have been tuned, while, network parameters (kernel and bias) were initialized
using the NeuroNet pre-trained model. Different pre-processing pipelines have
also been introduced to get a robust trained model. The model has been trained
and tested on IBSR18 data-set. To validate the research outcome, performance
was measured quantitatively using Dice Similarity Coefficient (DSC) and is
reported on average as 0.84 for CSF, 0.94 for GM, and 0.94 for WM. The outcome
of the research indicates that for the IBSR18 data-set, pre-processing and
proper tuning of hyper-parameters for NeuroNet model have improvement in DSC
for the brain tissue segmentation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tushar_F/0/1/0/all/0/1&quot;&gt;Fakrul Islam Tushar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Alyafi_B/0/1/0/all/0/1&quot;&gt;Basel Alyafi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hasan_M/0/1/0/all/0/1&quot;&gt;Md. Kamrul Hasan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dahal_L/0/1/0/all/0/1&quot;&gt;Lavsen Dahal&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00069">
<title>Unpaired Point Cloud Completion on Real Scans using Adversarial Training. (arXiv:1904.00069v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1904.00069</link>
<description rdf:parseType="Literal">&lt;p&gt;As 3D scanning solutions become increasingly popular, several deep learning
setups have been developed geared towards that task of scan completion, i.e.,
plausibly filling in regions there were missed in the raw scans. These methods,
however, largely rely on supervision in the form of paired training data, i.e.,
partial scans with corresponding desired completed scans. While these methods
have been successfully demonstrated on synthetic data, the approaches cannot be
directly used on real scans in absence of suitable paired training data. We
develop a first approach that works directly on input point clouds, does not
require paired training data, and hence can directly be applied to real scans
for scan completion. We evaluate the approach qualitatively on several
real-world datasets (ScanNet, Matterport, KITTI), quantitatively on 3D-EPN
shape completion benchmark dataset, and demonstrate realistic completions under
varying levels of incompleteness.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1&quot;&gt;Xuelin Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_B/0/1/0/all/0/1&quot;&gt;Baoquan Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mitra_N/0/1/0/all/0/1&quot;&gt;Niloy J. Mitra&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00070">
<title>Data Amplification: A Unified and Competitive Approach to Property Estimation. (arXiv:1904.00070v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1904.00070</link>
<description rdf:parseType="Literal">&lt;p&gt;Estimating properties of discrete distributions is a fundamental problem in
statistical learning. We design the first unified, linear-time, competitive,
property estimator that for a wide class of properties and for all underlying
distributions uses just $2n$ samples to achieve the performance attained by the
empirical estimator with $n\sqrt{\log n}$ samples. This provides off-the-shelf,
distribution-independent, &quot;amplification&quot; of the amount of data available
relative to common-practice estimators.
&lt;/p&gt;
&lt;p&gt;We illustrate the estimator&apos;s practical advantages by comparing it to
existing estimators for a wide variety of properties and distributions. In most
cases, its performance with $n$ samples is even as good as that of the
empirical estimator with $n\log n$ samples, and for essentially all properties,
its performance is comparable to that of the best existing estimator designed
specifically for that property.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Hao_Y/0/1/0/all/0/1&quot;&gt;Yi Hao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Orlitsky_A/0/1/0/all/0/1&quot;&gt;Alon Orlitsky&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Suresh_A/0/1/0/all/0/1&quot;&gt;Ananda T. Suresh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wu_Y/0/1/0/all/0/1&quot;&gt;Yihong Wu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00071">
<title>Analysis of Distributed Congestion Control in Cellular Vehicle-to-everything Networks. (arXiv:1904.00071v1 [cs.NI])</title>
<link>http://arxiv.org/abs/1904.00071</link>
<description rdf:parseType="Literal">&lt;p&gt;Cellular Vehicle-to-everything (C-V2X) communication has been proposed in the
3rd Generation Partnership Project release 14 standard to address the latency
and reliability requirements of cooperative safety applications. Such
applications can involve highly congested vehicular scenarios where the network
experiences high data loads. Thus, a sophisticated congestion control solution
is vital in order to maintain the network performance required for
safety-related applications. With the aid of our high-fidelity link-level
network simulator, we investigate the feasibility of implementing the
distributed congestion control algorithm specified in SAE J2945/1 standard on
top of the C-V2X stack. We describe our implementation and evaluate the
performance of transmission rate and range control mechanisms using relevant
metrics. Additionally, we identify areas for potential design enhancements and
further investigation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Toghi_B/0/1/0/all/0/1&quot;&gt;Behrad Toghi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Saifuddin_M/0/1/0/all/0/1&quot;&gt;Md Saifuddin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fallah_Y/0/1/0/all/0/1&quot;&gt;Yaser P. Fallah&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mughal_M/0/1/0/all/0/1&quot;&gt;M. O. Mughal&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00073">
<title>3D Organ Shape Reconstruction from Topogram Images. (arXiv:1904.00073v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1904.00073</link>
<description rdf:parseType="Literal">&lt;p&gt;Automatic delineation and measurement of main organs such as liver is one of
the critical steps for assessment of hepatic diseases, planning and
postoperative or treatment follow-up. However, addressing this problem
typically requires performing computed tomography (CT) scanning and complicated
postprocessing of the resulting scans using slice-by-slice techniques. In this
paper, we show that 3D organ shape can be automatically predicted directly from
topogram images, which are easier to acquire and have limited exposure to
radiation during acquisition, compared to CT scans. We evaluate our approach on
the challenging task of predicting liver shape using a generative model. We
also demonstrate that our method can be combined with user annotations, such as
a 2D mask, for improved prediction accuracy. We show compelling results on 3D
liver shape reconstruction and volume estimation on 2129 CT scans.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Balashova_E/0/1/0/all/0/1&quot;&gt;Elena Balashova&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1&quot;&gt;Jiangping Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Singh_V/0/1/0/all/0/1&quot;&gt;Vivek Singh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Georgescu_B/0/1/0/all/0/1&quot;&gt;Bogdan Georgescu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Teixeira_B/0/1/0/all/0/1&quot;&gt;Brian Teixeira&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kapoor_A/0/1/0/all/0/1&quot;&gt;Ankur Kapoor&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00077">
<title>Scalable Robust Adaptive Control from the System Level Perspective. (arXiv:1904.00077v1 [cs.SY])</title>
<link>http://arxiv.org/abs/1904.00077</link>
<description rdf:parseType="Literal">&lt;p&gt;We will present a new general framework for robust and adaptive control that
allows for distributed and scalable learning and control of large systems of
interconnected linear subsystems. The control method is demonstrated for a
linear time-invariant system with bounded parameter uncertainties, disturbances
and noise. The presented scheme continuously collects measurements to reduce
the uncertainty about the system parameters and adapts dynamic robust
controllers online in a stable and performance-improving way. A key enabler for
our approach is choosing a time-varying dynamic controller implementation,
inspired by recent work on System Level Synthesis. We leverage a new robustness
result for this implementation to propose a general robust adaptive control
algorithm. In particular, the algorithm allows us to impose communication and
delay constraints on the controller implementation and is formulated as a
sequence of robust optimization problems that can be solved in a distributed
manner. The proposed control methodology performs particularly well when the
interconnection between systems is sparse and the dynamics of local regions of
subsystems depend only on a small number of parameters. As we will show on a
five-dimensional exemplary chain-system, the algorithm can utilize system
structure to efficiently learn and control the entire system while respecting
communication and implementation constraints. Moreover, although current
theoretical results require the assumption of small initial uncertainties to
guarantee robustness, we will present simulations that show good closed-loop
performance even in the case of large uncertainties, which suggests that this
assumption is not critical for the presented technique and future work will
focus on providing less conservative guarantees.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ho_D/0/1/0/all/0/1&quot;&gt;Dimitar Ho&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Doyle_J/0/1/0/all/0/1&quot;&gt;John C. Doyle&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00078">
<title>Autonomous Visual Assistance for Robot Operations Using a Tethered UAV. (arXiv:1904.00078v1 [cs.RO])</title>
<link>http://arxiv.org/abs/1904.00078</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper develops an autonomous tethered aerial visual assistant for robot
operations in unstructured or confined environments. Robotic tele-operation in
remote environments is difficult due to lack of sufficient situational
awareness, mostly caused by the stationary and limited field-of-view and lack
of depth perception from the robot&apos;s onboard camera. The emerging state of the
practice is to use two robots, a primary and a secondary that acts as a visual
assistant to overcome the perceptual limitations of the onboard sensors by
providing an external viewpoint. However, problems exist when using a
tele-operated visual assistant: extra manpower, manually chosen suboptimal
viewpoint, and extra teamwork demand between primary and secondary operators.
In this work, we use an autonomous tethered aerial visual assistant to replace
the secondary robot and operator, reducing human robot ratio from 2:2 to 1:2.
This visual assistant is able to autonomously navigate through unstructured or
confined spaces in a risk-aware manner, while continuously maintaining good
viewpoint quality to increase the primary operator&apos;s situational awareness.
With the proposed co-robots team, tele-operation missions in nuclear
operations, bomb squad, disaster robots, and other domains with novel tasks or
highly occluded environments could benefit from reduced manpower and teamwork
demand, along with improved visual assistance quality based on trustworthy
risk-aware motion in cluttered environments.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xiao_X/0/1/0/all/0/1&quot;&gt;Xuesu Xiao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dufek_J/0/1/0/all/0/1&quot;&gt;Jan Dufek&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Murphy_R/0/1/0/all/0/1&quot;&gt;Robin R. Murphy&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00079">
<title>Query the model: precomputations for efficient inference with Bayesian Networks. (arXiv:1904.00079v1 [cs.DB])</title>
<link>http://arxiv.org/abs/1904.00079</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider a setting where a Bayesian network has been built over a
relational database to represent the joint distribution of data attributes and
is used to perform approximate query processing or answer predictive queries.
We explain how careful precomputation of certain probabilistic quantities can
lead to large efficiency gains in response time and provide algorithms for
optimal precomputation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Aslay_C/0/1/0/all/0/1&quot;&gt;Cigdem Aslay&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gionis_A/0/1/0/all/0/1&quot;&gt;Aristides Gionis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mathioudakis_M/0/1/0/all/0/1&quot;&gt;Michael Mathioudakis&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00093">
<title>A Gaussian process latent force model for joint input-state estimation in linear structural systems. (arXiv:1904.00093v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1904.00093</link>
<description rdf:parseType="Literal">&lt;p&gt;The problem of combined state and input estimation of linear structural
systems based on measured responses and a priori knowledge of structural model
is considered. A novel methodology using Gaussian process latent force models
is proposed to tackle the problem in a stochastic setting. Gaussian process
latent force models (GPLFMs) are hybrid models that combine differential
equations representing a physical system with data-driven non-parametric
Gaussian process models. In this work, the unknown input forces acting on a
structure are modelled as Gaussian processes with some chosen covariance
functions which are combined with the mechanistic differential equation
representing the structure to construct a GPLFM. The GPLFM is then conveniently
formulated as an augmented stochastic state-space model with additional states
representing the latent force components, and the joint input and state
inference of the resulting model is implemented using Kalman filter. The
augmented state-space model of GPLFM is shown as a generalization of the class
of input-augmented state-space models, is proven observable, and is robust
compared to conventional augmented formulations in terms of numerical
stability. The hyperparameters governing the covariance functions are estimated
using maximum likelihood optimization based on the observed data, thus
overcoming the need for manual tuning of the hyperparameters by
trial-and-error. To assess the performance of the proposed GPLFM method,
several cases of state and input estimation are demonstrated using numerical
simulations on a 10-dof shear building and a 76-storey ASCE benchmark office
tower. Results obtained indicate the superior performance of the proposed
approach over conventional Kalman filter based approaches.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nayek_R/0/1/0/all/0/1&quot;&gt;Rajdip Nayek&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chakraborty_S/0/1/0/all/0/1&quot;&gt;Souvik Chakraborty&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Narasimhany_S/0/1/0/all/0/1&quot;&gt;Sriram Narasimhany&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00101">
<title>Stabilizer Circuits, Quadratic Forms, and Computing Matrix Rank. (arXiv:1904.00101v1 [cs.CC])</title>
<link>http://arxiv.org/abs/1904.00101</link>
<description rdf:parseType="Literal">&lt;p&gt;We show that a form of strong simulation for $n$-qubit quantum stabilizer
circuits $C$ is computable in $O(s + n^\omega)$ time, where $\omega$ is the
exponent of matrix multiplication. Solution counting for quadratic forms over
$\mathbb{F}_2$ is also placed into $O(n^\omega)$ time. This improves previous
$O(n^3)$ bounds. Our methods in fact show an $O(n^2)$-time reduction from
matrix rank over $\mathbb{F}_2$ to computing $p = |\langle \; 0^n \;|\; C \;|\;
0^n \;\rangle|^2$ (hence also to solution counting) and a converse reduction
that is $O(s + n^2)$ except for matrix multiplications used to decide whether
$p &amp;gt; 0$. The current best-known worst-case time for matrix rank is
$O(n^{\omega})$ over $\mathbb{F}_2$, indeed over any field, while $\omega$ is
currently upper-bounded by $2.3728\dots$ Our methods draw on properties of
classical quadratic forms over $\mathbb{Z}_4$. We study possible distributions
of Feynman paths in the circuits and prove that the differences in $+1$ vs.
$-1$ counts and $+i$ vs. $-i$ counts are always $0$ or a power of $2$. Further
properties of quantum graph states and connections to graph theory are
discussed.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guan_C/0/1/0/all/0/1&quot;&gt;Chaowen Guan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Regan_K/0/1/0/all/0/1&quot;&gt;Kenneth W. Regan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00103">
<title>How to Estimate the Ability of a Metaheuristic Algorithm to Guide Heuristics During Optimization. (arXiv:1904.00103v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1904.00103</link>
<description rdf:parseType="Literal">&lt;p&gt;Metaheuristics are general methods that guide application of concrete
heuristic(s) to problems that are too hard to solve using exact algorithms.
However, even though a growing body of literature has been devoted to their
statistical evaluation, the approaches proposed so far are able to assess only
coupled effects of metaheuristics and heuristics. They do not reveal us
anything about how efficient the examined metaheuristic is at guiding its
subordinate heuristic(s), nor do they provide us information about how much the
heuristic component of the combined algorithm contributes to the overall
performance. In this paper, we propose a simple yet effective methodology of
doing so by deriving a naive, placebo metaheuristic from the one being studied
and comparing the distributions of chosen performance metrics for the two
methods. We propose three measures of difference between the two distributions.
Those measures, which we call BER values (benefit, equivalence, risk) are based
on a preselected threshold of practical significance which represents the
minimal difference between two performance scores required for them to be
considered practically different. We illustrate usefulness of our methodology
on the example of Simulated Annealing, Boolean Satisfiability Problem, and the
Flip heuristic.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Simic_M/0/1/0/all/0/1&quot;&gt;Milo&amp;#x161; Simi&amp;#x107;&lt;/a&gt; (University of Belgrade, Belgrade, Serbia)</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00107">
<title>Group-centered framework towards a positive design of digital collaboration in global settings. (arXiv:1904.00107v1 [cs.HC])</title>
<link>http://arxiv.org/abs/1904.00107</link>
<description rdf:parseType="Literal">&lt;p&gt;Globally distributed groups require collaborative systems to support their
work. Besides being able to support the teamwork, these systems also should
promote well-being and maximize the human potential that leads to an engaging
system and joyful experience. Designing such system is a significant challenge
and requires a thorough understanding of group work. We used the field theory
as a lens to view the essential aspects of group motivation and then utilized
collaboration personas to analyze the elements of group work. We integrated
well-being determinants as engagement factors to develop a group-centered
framework for digital collaboration in a global setting. Based on the outcomes,
we proposed a conceptual framework to design an engaging collaborative system
and recommend system values that can be used to evaluate the system further
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nurhas_I/0/1/0/all/0/1&quot;&gt;Irawan Nurhas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pawlowski_J/0/1/0/all/0/1&quot;&gt;Jan Pawlowski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Geisler_S/0/1/0/all/0/1&quot;&gt;Stefan Geisler&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kovtunenko_M/0/1/0/all/0/1&quot;&gt;Maria Kovtunenko&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Aditya_B/0/1/0/all/0/1&quot;&gt;Bayu Rima Aditya&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00110">
<title>Keyphrase Generation: A Text Summarization Struggle. (arXiv:1904.00110v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1904.00110</link>
<description rdf:parseType="Literal">&lt;p&gt;Authors&apos; keyphrases assigned to scientific articles are essential for
recognizing content and topic aspects. Most of the proposed supervised and
unsupervised methods for keyphrase generation are unable to produce terms that
are valuable but do not appear in the text. In this paper, we explore the
possibility of considering the keyphrase string as an abstractive summary of
the title and the abstract. First, we collect, process and release a large
dataset of scientific paper metadata that contains 2.2 million records. Then we
experiment with popular text summarization neural architectures. Despite using
advanced deep learning models, large quantities of data and many days of
computation, our systematic evaluation on four test datasets reveals that the
explored text summarization methods could not produce better keyphrases than
the simpler unsupervised methods, or the existing supervised ones.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cano_E/0/1/0/all/0/1&quot;&gt;Erion &amp;#xc7;ano&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bojar_O/0/1/0/all/0/1&quot;&gt;Ond&amp;#x159;ej Bojar&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00112">
<title>Enabling decentral collaborative innovation processes - a web based real time collaboration platform. (arXiv:1904.00112v1 [cs.CY])</title>
<link>http://arxiv.org/abs/1904.00112</link>
<description rdf:parseType="Literal">&lt;p&gt;The main goal of this paper is to define a collaborative innovation process
as well as a supporting tool. It is motivated through the increasing
competition on global markets and the resultant propagation of decentralized
projects with a high demand of innovative collaboration in global contexts. It
bases on a project accomplished by the author group. A detailed literature
review and the action design research methodology of the project led to an
enhanced process model for decentral collaborative innovation processes and a
basic realization of a browser based real time tool to enable these processes.
The initial evaluation in a practical distributed setting has shown that the
created tool is a useful way to support collaborative innovation processes.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Joiko_M/0/1/0/all/0/1&quot;&gt;Matthias Joiko&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kohnen_F/0/1/0/all/0/1&quot;&gt;Florian Kohnen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lapinski_K/0/1/0/all/0/1&quot;&gt;Kevin Lapinski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Moudrik_H/0/1/0/all/0/1&quot;&gt;Houda Moudrik&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nurhas_I/0/1/0/all/0/1&quot;&gt;Irawan Nurhas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Paproth_F/0/1/0/all/0/1&quot;&gt;Florian Paproth&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pawlowski_J/0/1/0/all/0/1&quot;&gt;Jan M. Pawlowski&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00118">
<title>Structured Minimally Supervised Learning for Neural Relation Extraction. (arXiv:1904.00118v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1904.00118</link>
<description rdf:parseType="Literal">&lt;p&gt;We present an approach to minimally supervised relation extraction that
combines the benefits of learned representations and structured learning, and
accurately predicts sentence-level relation mentions given only
proposition-level supervision from a KB. By explicitly reasoning about missing
data during learning, our approach enables large-scale training of 1D
convolutional neural networks while mitigating the issue of label noise
inherent in distant supervision. Our approach achieves state-of-the-art results
on minimally supervised sentential relation extraction, outperforming a number
of baselines, including a competitive approach that uses the attention layer of
a purely neural model.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bai_F/0/1/0/all/0/1&quot;&gt;Fan Bai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ritter_A/0/1/0/all/0/1&quot;&gt;Alan Ritter&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00124">
<title>Detectability and Observer Design for Switched Differential Algebraic Equations. (arXiv:1904.00124v1 [math.OC])</title>
<link>http://arxiv.org/abs/1904.00124</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper studies detectability for switched linear differential-algebraic
equations (DAEs) and its application to the synthesis of observers, which
generate asymptotically converging state estimates. Equating detectability to
asymptotic stability of zero-output-constrained state trajectories, and
building on our work on interval-wise observability, we propose the notion of
interval-wise detectability: If the output of the system is constrained to be
identically zero over an interval, then the norm of the corresponding state
trajectories scales down by a certain factor at the end of that interval.
Conditions are provided under which the interval-wise detectability leads to
asymptotic stability of zero-output-constrained state trajectories. An
application is demonstrated in designing state estimators. Decomposing the
state into observable and unobservable components, we show that if the
observable component of the system is reset appropriately and persistently,
then the estimation error converges to zero asymptotically under the
interval-wise detectability assumption.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Tanwani_A/0/1/0/all/0/1&quot;&gt;Aneel Tanwani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Trenn_S/0/1/0/all/0/1&quot;&gt;Stephan Trenn&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00129">
<title>Dance Dance Generation: Motion Transfer for Internet Videos. (arXiv:1904.00129v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1904.00129</link>
<description rdf:parseType="Literal">&lt;p&gt;This work presents computational methods for transferring body movements from
one person to another with videos collected in the wild. Specifically, we train
a personalized model on a single video from the Internet which can generate
videos of this target person driven by the motions of other people. Our model
is built on two generative networks: a human (foreground) synthesis net which
generates photo-realistic imagery of the target person in a novel pose, and a
fusion net which combines the generated foreground with the scene (background),
adding shadows or reflections as needed to enhance realism. We validate the the
efficacy of our proposed models over baselines with qualitative and
quantitative evaluations as well as a subjective test.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1&quot;&gt;Yipin Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1&quot;&gt;Zhaowen Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fang_C/0/1/0/all/0/1&quot;&gt;Chen Fang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bui_T/0/1/0/all/0/1&quot;&gt;Trung Bui&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Berg_T/0/1/0/all/0/1&quot;&gt;Tamara L. Berg&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00132">
<title>ANA at SemEval-2019 Task 3: Contextual Emotion detection in Conversations through hierarchical LSTMs and BERT. (arXiv:1904.00132v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1904.00132</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper describes the system submitted by ANA Team for the SemEval-2019
Task 3: EmoContext. We propose a novel Hierarchical LSTMs for Contextual
Emotion Detection (HRLCE) model. It classifies the emotion of an utterance
given its conversational context. The results show that, in this task, our
HRCLE outperforms the most recent state-of-the-art text classification
framework: BERT. We combine the results generated by BERT and HRCLE to achieve
an overall score of 0.7709 which ranked 5th on the final leader board of the
competition among 165 Teams.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_C/0/1/0/all/0/1&quot;&gt;Chenyang Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Trabelsi_A/0/1/0/all/0/1&quot;&gt;Amine Trabelsi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zaiane_O/0/1/0/all/0/1&quot;&gt;Osmar R. Za&amp;#xef;ane&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00138">
<title>On Arrhythmia Detection by Deep Learning and Multidimensional Representation. (arXiv:1904.00138v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1904.00138</link>
<description rdf:parseType="Literal">&lt;p&gt;ECG is a time-series signal that is represented by 1-D data. Higher
dimensional representation contains more information that is accessible for
feature extraction. Hidden variables such as frequency relation and morphology
of segment is not directly accessible in the time domain. In this paper, 1-D
time series data is converted into multi-dimensional representation in the form
of multichannel 2-D images. Following that, deep learning was used to train a
deep neural network based classifier to detect arrhythmias. The validation is
performed by comparing the output of deep learning with the annotation that was
annotated by committees that consist of several certified cardiologists.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Rajput_K/0/1/0/all/0/1&quot;&gt;K.S. Rajput&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wibowo_S/0/1/0/all/0/1&quot;&gt;S. Wibowo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Hao_C/0/1/0/all/0/1&quot;&gt;C. Hao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Majmudar_M/0/1/0/all/0/1&quot;&gt;M. Majmudar&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00141">
<title>A Roadmap for Discretely Energy-Stable Schemes for Dissipative Systems Based on a Generalized Auxiliary Variable with Guaranteed Positivity. (arXiv:1904.00141v1 [physics.comp-ph])</title>
<link>http://arxiv.org/abs/1904.00141</link>
<description rdf:parseType="Literal">&lt;p&gt;We present a framework for devising discretely energy-stable schemes for
general dissipative systems based on a generalized auxiliary variable. The
auxiliary variable, a scalar number, can be defined in terms of the energy
functional by a general class of functions, not limited to the square root
function adopted in previous approaches. The current method has another
remarkable property: the computed values for the generalized auxiliary variable
are guaranteed to be positive on the discrete level, regardless of the time
step sizes or the external forces. This property of guaranteed positivity is
not available in previous approaches. A unified procedure for treating the
dissipative governing equations and the generalized auxiliary variable on the
discrete level has been presented. The discrete energy stability of the
proposed numerical scheme and the positivity of the computed auxiliary variable
have been proved for general dissipative systems. The current method, termed
gPAV (generalized Positive Auxiliary Variable), requires only the solution of
linear algebraic equations within a time step. With appropriate choice of the
operator in the algorithm, the resultant linear algebraic systems upon
discretization involve only constant and time-independent coefficient matrices,
which only need to be computed once and can be pre-computed. Several specific
dissipative systems are studied in relative detail using the gPAV framework.
Ample numerical experiments are presented to demonstrate the performance of the
method, and the robustness of the scheme at large time step sizes.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Yang_Z/0/1/0/all/0/1&quot;&gt;Zhiguo Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Dong_S/0/1/0/all/0/1&quot;&gt;Suchuan Dong&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00143">
<title>Distant Supervision Relation Extraction with Intra-Bag and Inter-Bag Attentions. (arXiv:1904.00143v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1904.00143</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper presents a neural relation extraction method to deal with the
noisy training data generated by distant supervision. Previous studies mainly
focus on sentence-level de-noising by designing neural networks with intra-bag
attentions. In this paper, both intra-bag and inter-bag attentions are
considered in order to deal with the noise at sentence-level and bag-level
respectively. First, relation-aware bag representations are calculated by
weighting sentence embeddings using intra-bag attentions. Here, each possible
relation is utilized as the query for attention calculation instead of only
using the target relation in conventional methods. Furthermore, the
representation of a group of bags in the training set which share the same
relation label is calculated by weighting bag representations using a
similarity-based inter-bag attention module. Finally, a bag group is utilized
as a training sample when building our relation extractor. Experimental results
on the New York Times dataset demonstrate the effectiveness of our proposed
intra-bag and inter-bag attention modules. Our method also achieves better
relation extraction accuracy than state-of-the-art methods on this dataset.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ye_Z/0/1/0/all/0/1&quot;&gt;Zhi-Xiu Ye&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ling_Z/0/1/0/all/0/1&quot;&gt;Zhen-Hua Ling&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00150">
<title>Learning Affective Correspondence between Music and Image. (arXiv:1904.00150v1 [cs.MM])</title>
<link>http://arxiv.org/abs/1904.00150</link>
<description rdf:parseType="Literal">&lt;p&gt;We introduce the problem of learning affective correspondence between audio
(music) and visual data (images). For this task, a music clip and an image are
considered similar (having true correspondence) if they have similar emotion
content. In order to estimate this crossmodal, emotion-centric similarity, we
propose a deep neural network architecture that learns to project the data from
the two modalities to a common representation space, and performs a binary
classification task of predicting the affective correspondence (true or false).
To facilitate the current study, we construct a large scale database containing
more than $3,500$ music clips and $85,000$ images with three emotion classes
(positive, neutral, negative). The proposed approach achieves $61.67\%$
accuracy for the affective correspondence prediction task on this database,
outperforming two relevant and competitive baselines. We also demonstrate that
our network learns modality-specific representations of emotion (without
explicitly being trained with emotion labels), which are useful for emotion
recognition in individual modalities.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Verma_G/0/1/0/all/0/1&quot;&gt;Gaurav Verma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dhekane_E/0/1/0/all/0/1&quot;&gt;Eeshan Gunesh Dhekane&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guha_T/0/1/0/all/0/1&quot;&gt;Tanaya Guha&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00152">
<title>Robust Subspace Recovery Layer for Unsupervised Anomaly Detection. (arXiv:1904.00152v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1904.00152</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a neural network for unsupervised anomaly detection with a novel
robust subspace recovery layer (RSR layer). This layer seeks to extract the
underlying subspace from a latent representation of the given data and remove
outliers that lie away from this subspace. It is used together with an encoder
and a decoder. The encoder maps the data into the latent space, from which the
RSR layer extracts the subspace. The decoder then smoothly maps back the
underlying subspace to a ``manifold&quot; close to the original data. We illustrate
algorithmic choices and performance for artificial data with corrupted manifold
structure. We also demonstrate competitive precision and recall for image
datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lai_C/0/1/0/all/0/1&quot;&gt;Chieh-Hsin Lai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zou_D/0/1/0/all/0/1&quot;&gt;Dongmian Zou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lerman_G/0/1/0/all/0/1&quot;&gt;Gilad Lerman&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00156">
<title>Viewpoint | Personal Data and the Internet of Things: It is time to care about digital provenance. (arXiv:1904.00156v1 [cs.CY])</title>
<link>http://arxiv.org/abs/1904.00156</link>
<description rdf:parseType="Literal">&lt;p&gt;The Internet of Things promises a connected environment reacting to and
addressing our every need, but based on the assumption that all of our
movements and words can be recorded and analysed to achieve this end.
Ubiquitous surveillance is also a precondition for most dystopian societies,
both real and fictional. How our personal data is processed and consumed in an
ever more connected world must imperatively be made transparent, and more
effective technical solutions than those currently on offer, to manage personal
data must urgently be investigated.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pasquier_T/0/1/0/all/0/1&quot;&gt;Thomas Pasquier&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Eyers_D/0/1/0/all/0/1&quot;&gt;David Eyers&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bacon_J/0/1/0/all/0/1&quot;&gt;Jean Bacon&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00157">
<title>Linguistic generalization and compositionality in modern artificial neural networks. (arXiv:1904.00157v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1904.00157</link>
<description rdf:parseType="Literal">&lt;p&gt;In the last decade, deep artificial neural networks have achieved astounding
performance in many natural language processing tasks. Given the high
productivity of language, these models must possess effective generalization
abilities. It is widely assumed that humans handle linguistic productivity by
means of algebraic compositional rules: Are deep networks similarly
compositional? After reviewing the main innovations characterizing current deep
language processing networks, I discuss a set of studies suggesting that deep
networks are capable of subtle grammar-dependent generalizations, but also that
they do not rely on systematic compositional rules. I argue that the intriguing
behaviour of these devices (still awaiting a full understanding) should be of
interest to linguists and cognitive scientists, as it offers a new perspective
on possible computational strategies to deal with linguistic productivity
beyond rule-based compositionality, and it might lead to new insights into the
less systematic generalization patterns that also appear in natural language.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Baroni_M/0/1/0/all/0/1&quot;&gt;Marco Baroni&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00158">
<title>UVA: A Universal Variational Framework for Continuous Age Analysis. (arXiv:1904.00158v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1904.00158</link>
<description rdf:parseType="Literal">&lt;p&gt;Conventional methods for facial age analysis tend to utilize accurate age
labels in a supervised way. However, existing age datasets lies in a limited
range of ages, leading to a long-tailed distribution. To alleviate the problem,
this paper proposes a Universal Variational Aging (UVA) framework to formulate
facial age priors in a disentangling manner. Benefiting from the variational
evidence lower bound, the facial images are encoded and disentangled into an
age-irrelevant distribution and an age-related distribution in the latent
space. A conditional introspective adversarial learning mechanism is introduced
to boost the image quality. In this way, when manipulating the age-related
distribution, UVA can achieve age translation with arbitrary ages. Further, by
sampling noise from the age-irrelevant distribution, we can generate
photorealistic facial images with a specific age. Moreover, given an input face
image, the mean value of age-related distribution can be treated as an age
estimator. These indicate that UVA can efficiently and accurately estimate the
age-related distribution by a disentangling manner, even if the training
dataset performs a long-tailed age distribution. UVA is the first attempt to
achieve facial age analysis tasks, including age translation, age generation
and age estimation, in a universal framework. The qualitative and quantitative
experiments demonstrate the superiority of UVA on five popular datasets,
including CACD2000, Morph, UTKFace, MegaAge-Asian and FG-NET.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_P/0/1/0/all/0/1&quot;&gt;Peipei Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_H/0/1/0/all/0/1&quot;&gt;Huaibo Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hu_Y/0/1/0/all/0/1&quot;&gt;Yibo Hu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1&quot;&gt;Xiang Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+He_R/0/1/0/all/0/1&quot;&gt;Ran He&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_Z/0/1/0/all/0/1&quot;&gt;Zhenan Sun&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00160">
<title>Machine translation considering context information using Encoder-Decoder model. (arXiv:1904.00160v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1904.00160</link>
<description rdf:parseType="Literal">&lt;p&gt;In the task of machine translation, context information is one of the
important factor. But considering the context information model dose not
proposed. The paper propose a new model which can integrate context information
and make translation. In this paper, we create a new model based Encoder
Decoder model. When translating current sentence, the model integrates output
from preceding encoder with current encoder. The model can consider context
information and the result score is higher than existing model.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Takano_T/0/1/0/all/0/1&quot;&gt;Tetsuto Takano&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yamane_S/0/1/0/all/0/1&quot;&gt;Satoshi Yamane&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00167">
<title>Exposing GAN-synthesized Faces Using Landmark Locations. (arXiv:1904.00167v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1904.00167</link>
<description rdf:parseType="Literal">&lt;p&gt;Generative adversary networks (GANs) have recently led to highly realistic
image synthesis results. In this work, we describe a new method to expose
GAN-synthesized images using the locations of the facial landmark points. Our
method is based on the observations that the facial parts configuration
generated by GAN models are different from those of the real faces, due to the
lack of global constraints. We perform experiments demonstrating this
phenomenon, and show that an SVM classifier trained using the locations of
facial landmark points is sufficient to achieve good classification performance
for GAN-synthesized faces.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1&quot;&gt;Xin Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1&quot;&gt;Yuezun Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qi_H/0/1/0/all/0/1&quot;&gt;Honggang Qi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lyu_S/0/1/0/all/0/1&quot;&gt;Siwei Lyu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00168">
<title>M2FPA: A Multi-Yaw Multi-Pitch High-Quality Database and Benchmark for Facial Pose Analysis. (arXiv:1904.00168v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1904.00168</link>
<description rdf:parseType="Literal">&lt;p&gt;Facial images in surveillance or mobile scenarios often have large view-point
variations in terms of pitch and yaw angles. These jointly occurred angle
variations make face recognition challenging. Current public face databases
mainly consider the case of yaw variations. In this paper, a new large-scale
Multi-yaw Multi-pitch high-quality database is proposed for Facial Pose
Analysis (M2FPA), including face frontalization, face rotation, facial pose
estimation and pose-invariant face recognition. It contains 397,544 images of
229 subjects with yaw, pitch, attribute, illumination and accessory. M2FPA is
the most comprehensive multi-view face database for facial pose analysis.
Further, we provide an effective benchmark for face frontalization and
pose-invariant face recognition on M2FPA with several state-of-the-art methods,
including DR-GAN, TP-GAN and CAPG-GAN. We believe that the new database and
benchmark can significantly push forward the advance of facial pose analysis in
real-world applications. Moreover, a simple yet effective parsing guided
discriminator is introduced to capture the local consistency during GAN
optimization. Extensive quantitative and qualitative results on M2FPA and
Multi-PIE demonstrate the superiority of our face frontalization method.
Baseline results for both face synthesis and face recognition from
state-of-theart methods demonstrate the challenge offered by this new database.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_P/0/1/0/all/0/1&quot;&gt;Peipei Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1&quot;&gt;Xiang Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hu_Y/0/1/0/all/0/1&quot;&gt;Yibo Hu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+He_R/0/1/0/all/0/1&quot;&gt;Ran He&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_Z/0/1/0/all/0/1&quot;&gt;Zhenan Sun&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00170">
<title>Adaptive Adjustment with Semantic Feature Space for Zero-Shot Recognition. (arXiv:1904.00170v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1904.00170</link>
<description rdf:parseType="Literal">&lt;p&gt;In most recent years, zero-shot recognition (ZSR) has gained increasing
attention in machine learning and image processing fields. It aims at
recognizing unseen class instances with knowledge transferred from seen
classes. This is typically achieved by exploiting a pre-defined semantic
feature space (FS), i.e., semantic attributes or word vectors, as a bridge to
transfer knowledge between seen and unseen classes. However, due to the absence
of unseen classes during training, the conventional ZSR easily suffers from
domain shift and hubness problems. In this paper, we propose a novel ZSR
learning framework that can handle these two issues well by adaptively
adjusting semantic FS. To the best of our knowledge, our work is the first to
consider the adaptive adjustment of semantic FS in ZSR. Moreover, our solution
can be formulated to a more efficient framework that significantly boosts the
training. Extensive experiments show the remarkable performance improvement of
our model compared with other existing methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guo_J/0/1/0/all/0/1&quot;&gt;Jingcai Guo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guo_S/0/1/0/all/0/1&quot;&gt;Song Guo&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00172">
<title>EE-AE: An Exclusivity Enhanced Unsupervised Feature Learning Approach. (arXiv:1904.00172v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1904.00172</link>
<description rdf:parseType="Literal">&lt;p&gt;Unsupervised learning is becoming more and more important recently. As one of
its key components, the autoencoder (AE) aims to learn a latent feature
representation of data which is more robust and discriminative. However, most
AE based methods only focus on the reconstruction within the encoder-decoder
phase, which ignores the inherent relation of data, i.e., statistical and
geometrical dependence, and easily causes overfitting. In order to deal with
this issue, we propose an Exclusivity Enhanced (EE) unsupervised feature
learning approach to improve the conventional AE. To the best of our knowledge,
our research is the first to utilize such exclusivity concept to cooperate with
feature extraction within AE. Moreover, in this paper we also make some
improvements to the stacked AE structure especially for the connection of
different layers from decoders, this could be regarded as a weight
initialization trial. The experimental results show that our proposed approach
can achieve remarkable performance compared with other related methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guo_J/0/1/0/all/0/1&quot;&gt;Jingcai Guo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guo_S/0/1/0/all/0/1&quot;&gt;Song Guo&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00173">
<title>Asymptotic nonparametric statistical analysis of stationary time series. (arXiv:1904.00173v1 [math.ST])</title>
<link>http://arxiv.org/abs/1904.00173</link>
<description rdf:parseType="Literal">&lt;p&gt;Stationarity is a very general, qualitative assumption, that can be assessed
on the basis of application specifics. It is thus a rather attractive
assumption to base statistical analysis on, especially for problems for which
less general qualitative assumptions, such as independence or finite memory,
clearly fail. However, it has long been considered too general to allow for
statistical inference to be made. One of the reasons for this is that rates of
convergence, even of frequencies to the mean, are not available under this
assumption alone. Recently, it has been shown that, while some natural and
simple problems such as homogeneity, are indeed provably impossible to solve if
one only assumes that the data is stationary (or stationary ergodic), many
others can be solved using rather simple and intuitive algorithms. The latter
problems include clustering and change point estimation. In this volume I
summarize these results. The emphasis is on asymptotic consistency, since this
the strongest property one can obtain assuming stationarity alone. While for
most of the problems for which a solution is found this solution is
algorithmically realizable, the main objective in this area of research, the
objective which is only partially attained, is to understand what is possible
and what is not possible to do for stationary time series. The considered
problems include homogeneity testing, clustering with respect to distribution,
clustering with respect to independence, change-point estimation, identity
testing, and the general question of composite hypotheses testing. For the
latter problem, a topological criterion for the existence of a consistent test
is presented. In addition, several open questions are discussed.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Ryabko_D/0/1/0/all/0/1&quot;&gt;Daniil Ryabko&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00176">
<title>Nonparametric Density Estimation for High-Dimensional Data - Algorithms and Applications. (arXiv:1904.00176v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1904.00176</link>
<description rdf:parseType="Literal">&lt;p&gt;Density Estimation is one of the central areas of statistics whose purpose is
to estimate the probability density function underlying the observed data. It
serves as a building block for many tasks in statistical inference,
visualization, and machine learning. Density Estimation is widely adopted in
the domain of unsupervised learning especially for the application of
clustering. As big data become pervasive in almost every area of data sciences,
analyzing high-dimensional data that have many features and variables appears
to be a major focus in both academia and industry. High-dimensional data pose
challenges not only from the theoretical aspects of statistical inference, but
also from the algorithmic/computational considerations of machine learning and
data analytics. This paper reviews a collection of selected nonparametric
density estimation algorithms for high-dimensional data, some of them are
recently published and provide interesting mathematical insights. The important
application domain of nonparametric density estimation, such as { modal
clustering}, are also included in this paper. Several research directions
related to density estimation and high-dimensional data analysis are suggested
by the authors.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wang_Z/0/1/0/all/0/1&quot;&gt;Zhipeng Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Scott_D/0/1/0/all/0/1&quot;&gt;David W. Scott&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00182">
<title>A &quot;poor man&apos;s&quot; approach for high-resolution three-dimensional topology optimization of natural convection problems. (arXiv:1904.00182v1 [cs.CE])</title>
<link>http://arxiv.org/abs/1904.00182</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper treats topology optimization of natural convection problems. A
simplified model is suggested to describe the flow of an incompressible fluid
in steady state conditions, similar to Darcy&apos;s law for fluid flow in porous
media. The equations for the fluid flow are coupled to the thermal
convection-diffusion equation through the Boussinesq approximation. The coupled
non-linear system of equations is discretized with stabilized finite elements
and solved in a parallel framework that allows for the optimization of high
resolution three-dimensional problems. A density-based topology optimization
approach is used, where a two-material interpolation scheme is applied to both
the permeability and conductivity of the distributed material. Due to the
simplified model, the proposed methodology allows for a significant reduction
of the computational effort required in the optimization. At the same time, it
is significantly more accurate than even simpler models that rely on convection
boundary conditions based on Newton&apos;s law of cooling. The methodology discussed
herein is applied to the optimization-based design of three-dimensional heat
sinks. The final designs are formally compared with results of previous work
obtained from solving the full set of Navier-Stokes equations. The results are
compared in terms of performance of the optimized designs and computational
cost. The computational time is shown to be decreased to around 5-20% in terms
of core-hours, allowing for the possibility of generating an optimized design
during the workday on a small computational cluster and overnight on a high-end
desktop.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pollini_N/0/1/0/all/0/1&quot;&gt;Nicolo Pollini&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sigmund_O/0/1/0/all/0/1&quot;&gt;Ole Sigmund&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Andreasen_C/0/1/0/all/0/1&quot;&gt;Casper Schousboe Andreasen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Alexandersen_J/0/1/0/all/0/1&quot;&gt;Joe Alexandersen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00184">
<title>NEWSTRADCOIN: A Blockchain Based Privacy Preserving Secure NEWS Trading Network. (arXiv:1904.00184v1 [cs.NI])</title>
<link>http://arxiv.org/abs/1904.00184</link>
<description rdf:parseType="Literal">&lt;p&gt;In order to stay up to date with world issues and cutting-edge technol-ogies,
the newspaper plays a crucial role. However, collecting news is not a very easy
task. Currently, news publishers are collecting news from their correspond-ents
through social networks, email, phone call, fax etc. and sometimes they buy
news from the agencies. However, the existing news sharing networks may not
provide security for data integrity and any third party may obstruct the
regular flow of news sharing. Moreover, the existing news schemes are very
vulnerable in case of disclosing the identity. Therefore, a universal platform
is needed in the era of globalization where anyone can share and trade news
from anywhere in the world securely, without the interference of third-party,
and without disclosing the identity of an individual. Recently, blockchain has
gained popularity because of its security mechanism over data, identity, etc.
Blockchain enables a distrib-uted way of managing transactions where each
participant of the network holds the same copy of the transactions. Therefore,
with the help of pseudonymity, fault-tolerance, immutability and the
distributed structure of blockchain, a scheme (termed as NEWSTRADCOIN) is
presented in this paper in which not only news can be shared securely but also
anyone can earn money by selling news. The proposed NEWSTRADCOIN can provide a
universal platform where publishers can directly obtain news from
news-gatherers in a secure way by main-taining data integrity, without
experiencing the interference of a third-party, and without disclosing the
identity of the news gatherer and publishers.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Islam_A/0/1/0/all/0/1&quot;&gt;Anik Islam&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kader_M/0/1/0/all/0/1&quot;&gt;Md. Fazlul Kader&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Islam%5D_M/0/1/0/all/0/1&quot;&gt;Md Mofijul Islam]&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shin_S/0/1/0/all/0/1&quot;&gt;Soo Young Shin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00187">
<title>A Convolution-Free LBP-HOG Descriptor For Mammogram Classification. (arXiv:1904.00187v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1904.00187</link>
<description rdf:parseType="Literal">&lt;p&gt;In image based feature descriptor design, an iterative scanning process
utilizing the convolution operation is often adopted to extract local
information of the image pixels. In this paper, we propose a convolution-free
Local Binary Pattern (CF-LBP) and a convolution-free Histogram of Oriented
Gradients (CF-HOG) descriptors in matrix form for mammogram classification. An
integrated form of CF-LBP and CF-HOG, CF-LBP-HOG, is subsequently constructed
in a single matrix formulation. The proposed descriptors are evaluated using a
publicly available mammogram database. The results show promising performance
in terms of classification accuracy and computational efficiency.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Alhakeem_Z/0/1/0/all/0/1&quot;&gt;Zainab Alhakeem&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jang_S/0/1/0/all/0/1&quot;&gt;Se-In Jang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00188">
<title>PILOT: Password and PIN Information Leakage from Obfuscated Typing Videos. (arXiv:1904.00188v1 [cs.CR])</title>
<link>http://arxiv.org/abs/1904.00188</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper studies leakage of user passwords and PINs based on observations
of typing feedback on screens or from projectors in the form of masked
characters that indicate keystrokes. To this end, we developed an attack called
Password and Pin Information Leakage from Obfuscated Typing Videos (PILOT). Our
attack extracts inter-keystroke timing information from videos of password
masking characters displayed when users type their password on a computer, or
their PIN at an ATM. We conducted several experiments in various attack
scenarios. Results indicate that, while in some cases leakage is minor, it is
quite substantial in others. By leveraging inter-keystroke timings, PILOT
recovers 8-character alphanumeric passwords in as little as 19 attempts. When
guessing PINs, PILOT significantly improved on both random guessing and the
attack strategy adopted in our prior work [4]. In particular, we were able to
guess about 3% of the PINs within 10 attempts. This corresponds to a 26-fold
improvement compared to random guessing. Our results strongly indicate that
secure password masking GUIs must consider the information leakage identified
in this paper.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Balagani_K/0/1/0/all/0/1&quot;&gt;Kiran Balagani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cardaioli_M/0/1/0/all/0/1&quot;&gt;Matteo Cardaioli&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Conti_M/0/1/0/all/0/1&quot;&gt;Mauro Conti&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gasti_P/0/1/0/all/0/1&quot;&gt;Paolo Gasti&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Georgiev_M/0/1/0/all/0/1&quot;&gt;Martin Georgiev&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gurtler_T/0/1/0/all/0/1&quot;&gt;Tristan Gurtler&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lain_D/0/1/0/all/0/1&quot;&gt;Daniele Lain&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Miller_C/0/1/0/all/0/1&quot;&gt;Charissa Miller&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Molas_K/0/1/0/all/0/1&quot;&gt;Kendall Molas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Samarin_N/0/1/0/all/0/1&quot;&gt;Nikita Samarin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Saraci_E/0/1/0/all/0/1&quot;&gt;Eugen Saraci&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tsudik_G/0/1/0/all/0/1&quot;&gt;Gene Tsudik&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_L/0/1/0/all/0/1&quot;&gt;Lynn Wu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00189">
<title>FO = FO3 for linear orders with monotone binary relations. (arXiv:1904.00189v1 [cs.LO])</title>
<link>http://arxiv.org/abs/1904.00189</link>
<description rdf:parseType="Literal">&lt;p&gt;We show that over the class of linear orders with additional binary relations
satisfying some monotonicity conditions, monadic first-order logic has the
three-variable property. This generalizes (and gives a new proof of) several
known results, including the fact that monadic first-order logic has the
three-variable property over linear orders, as well as over (R,&amp;lt;,+1), and
answers some open questions mentioned in a paper from Antonopoulos, Hunter,
Raza and Worrell [FoSSaCS 2015]. Our proof is based on a translation of monadic
first-order logic formulas into formulas of a star-free variant of
Propositional Dynamic Logic, which are in turn easily expressible in monadic
first-order logic with three variables.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fortin_M/0/1/0/all/0/1&quot;&gt;Marie Fortin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00195">
<title>Ontology Focusing: Knowledge-enriched Databases on Demand. (arXiv:1904.00195v1 [cs.LO])</title>
<link>http://arxiv.org/abs/1904.00195</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a novel framework to facilitate the on-demand design of
data-centric systems by exploiting domain knowledge from an existing ontology.
Its key ingredient is a process that we call focusing, which allows to obtain a
schema for a (possibly knowledge-enriched) database semi-automatically, given
an ontology and a specification of the scope of the desired system. We
formalize the inputs and outputs of focusing, and identify relevant
computational problems: finding a schema via focusing, testing its consistency,
and answering queries in the knowledge-enriched databases it produces. These
definitions are fully independent of the ontology language. We then instantiate
the framework using selected description logics as ontology languages, and
popular classes of queries for specifying the scope of the system. For several
representative combinations, we study the decidability and complexity of the
identified computational problems. As a by-product, we isolate (and solve)
variants of classical decision problems in description logics, that are
interesting in their own right.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gogacz_T/0/1/0/all/0/1&quot;&gt;Tomasz Gogacz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gutierrez_Basulto_V/0/1/0/all/0/1&quot;&gt;V&amp;#xed;ctor Guti&amp;#xe9;rrez-Basulto&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ibanez_Garcia_Y/0/1/0/all/0/1&quot;&gt;Yazm&amp;#xed;n A. Ib&amp;#xe1;&amp;#xf1;ez-Garc&amp;#xed;a&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Murlak_F/0/1/0/all/0/1&quot;&gt;Filip Murlak&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ortiz_M/0/1/0/all/0/1&quot;&gt;Magdalena Ortiz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Simkus_M/0/1/0/all/0/1&quot;&gt;Mantas &amp;#x160;imkus&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00197">
<title>Exploiting SIFT Descriptor for Rotation Invariant Convolutional Neural Network. (arXiv:1904.00197v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1904.00197</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper presents a novel approach to exploit the distinctive invariant
features in convolutional neural network. The proposed CNN model uses Scale
Invariant Feature Transform (SIFT) descriptor instead of the max-pooling layer.
Max-pooling layer discards the pose, i.e., translational and rotational
relationship between the low-level features, and hence unable to capture the
spatial hierarchies between low and high level features. The SIFT descriptor
layer captures the orientation and the spatial relationship of the features
extracted by convolutional layer. The proposed SIFT Descriptor CNN therefore
combines the feature extraction capabilities of CNN model and rotation
invariance of SIFT descriptor. Experimental results on the MNIST and
fashionMNIST datasets indicates reasonable improvements over conventional
methods available in literature.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kumar_A/0/1/0/all/0/1&quot;&gt;Abhay Kumar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jain_N/0/1/0/all/0/1&quot;&gt;Nishant Jain&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Singh_C/0/1/0/all/0/1&quot;&gt;Chirag Singh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tripathi_S/0/1/0/all/0/1&quot;&gt;Suraj Tripathi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00198">
<title>Boundary Aware Multi-Focus Image Fusion Using Deep Neural Network. (arXiv:1904.00198v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1904.00198</link>
<description rdf:parseType="Literal">&lt;p&gt;Since it is usually difficult to capture an all-in-focus image of a 3D scene
directly, various multi-focus image fusion methods are employed to generate it
from several images focusing at different depths. However, the performance of
existing methods is barely satisfactory and often degrades for areas near the
focused/defocused boundary (FDB). In this paper, a boundary aware method using
deep neural network is proposed to overcome this problem. (1) Aiming to acquire
improved fusion images, a 2-channel deep network is proposed to better extract
the relative defocus information of the two source images. (2) After analyzing
the different situations for patches far away from and near the FDB, we use two
networks to handle them respectively. (3) To simulate the reality more
precisely, a new approach of dataset generation is designed. Experiments
demonstrate that the proposed method outperforms the state-of-the-art methods,
both qualitatively and quantitatively.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ma_H/0/1/0/all/0/1&quot;&gt;Haoyu Ma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1&quot;&gt;Juncheng Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1&quot;&gt;Shaojun Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liao_Q/0/1/0/all/0/1&quot;&gt;Qingmin Liao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00200">
<title>A Note on Hardness Frameworks and Computational Complexity of Xiangqi and Janggi. (arXiv:1904.00200v1 [cs.CC])</title>
<link>http://arxiv.org/abs/1904.00200</link>
<description rdf:parseType="Literal">&lt;p&gt;We review NP-hardness framework and PSPACE-hardness framework for a type of
2D platform games. We introduce a EXPTIME-hardness framework by defining some
new gadgets. We use these hardness frameworks to analyse computational
complexity of Xiangqi (Chinese Chess) and Janggi (Korean Chess). We construct
all gadgets of the hardness frameworks in Xiangqi and Janggi. In conclusion, we
prove that Xiangqi and Janggi are both EXPTIME-complete.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1&quot;&gt;Zhujun Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00202">
<title>Static Visual Spatial Priors for DoA Estimation. (arXiv:1904.00202v1 [cs.SD])</title>
<link>http://arxiv.org/abs/1904.00202</link>
<description rdf:parseType="Literal">&lt;p&gt;As we interact with the world, for example when we communicate with our
colleagues in a large open space or meeting room, we continuously analyse the
surrounding environment and, in particular, localise and recognise acoustic
events. While we largely take such abilities for granted, they represent a
challenging problem for current robots or smart voice assistants as they can be
easily fooled by high degree of sound interference in acoustically complex
environments. Preventing such failures when using solely audio data is
challenging, if not impossible since the algorithms need to take into account
wider context and often understand the scene on a semantic level. In this
paper, we propose what to our knowledge is the first multi-modal direction of
arrival (DoA) of sound, which uses static visual spatial prior providing an
auxiliary information about the environment to suppress some of the false DoA
detections. We validate our approach on a newly collected real-world dataset,
and show that our approach consistently improves over classic DoA baselines
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Swietojanski_P/0/1/0/all/0/1&quot;&gt;Pawel Swietojanski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Miksik_O/0/1/0/all/0/1&quot;&gt;Ondrej Miksik&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00205">
<title>A HVS-inspired Attention Map to Improve CNN-based Perceptual Losses for Image Restoration. (arXiv:1904.00205v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1904.00205</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep Convolutional Neural Network (CNN) features have been demonstrated to be
effective perceptual quality features. The perceptual loss, based on feature
maps of pre-trained CNN&apos;s has proven to be remarkably effective for CNN based
perceptual image restoration problems. In this work, taking inspiration from
the the Human Visual System (HVS) and our visual perception, we propose a
spatial attention mechanism based on the dependency human contrast sensitivity
on spatial frequency. We identify regions in input images, based on underlying
spatial frequency where the visual system might be most sensitive to
distortions. Based on this prior, we design an attention map that is applied to
feature maps in the perceptual loss, helping it to identify regions that are of
more perceptual importance. The results will demonstrate that the proposed
technique helps improving the correlation of the perceptual loss with human
subjective assessment of perceptual quality and also results in a loss which
delivers a better perception-distortion trade-off compared to the widely used
perceptual loss in CNN based image restoration problems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tariq_T/0/1/0/all/0/1&quot;&gt;Taimoor Tariq&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gonzalez_J/0/1/0/all/0/1&quot;&gt;Juan Luis Gonzalez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_M/0/1/0/all/0/1&quot;&gt;Munchurl Kim&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00224">
<title>Medical Imaging Device Security: An Exploratory Study. (arXiv:1904.00224v1 [cs.CR])</title>
<link>http://arxiv.org/abs/1904.00224</link>
<description rdf:parseType="Literal">&lt;p&gt;Recent years have witnessed a boom of connected medical devices, which brings
security issues in the meantime. As an essential category of medical devices,
from our observation, medical imaging devices are under enormous potential
security risk. To address it, many works have been done, and effective methods
were proposed in the past decades. However, it remains to review current
medical imaging devices and evaluate the security and privacy of these devices.
We first investigate 15 devices (such as X-Ray, DSA, CT, etc.) which vary in
manufacturers and functions to have an overview of medical imaging devices,
hacking techniques, their protection mechanisms and the threat model. We
further analyse them and have confirmed that all of them have more or fewer
security defects, some of which can be attacked by a well-trained hacker. Then,
we design a list of criteria and define a multi-level hierarchy for both
vendors and government agencies to rate the products. At last, some actionable
recommendations are given to help developers to protect these devices.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ma_P/0/1/0/all/0/1&quot;&gt;Pingchuan Ma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1&quot;&gt;Zhiqiang Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zou_X/0/1/0/all/0/1&quot;&gt;Xiaoxiang Zou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1&quot;&gt;Jianyi Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1&quot;&gt;Qixu Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lyu_X/0/1/0/all/0/1&quot;&gt;Xin Lyu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1&quot;&gt;Wentao Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00226">
<title>IoT-Fog: A Communication Framework using Blockchain in the Internet of Things. (arXiv:1904.00226v1 [cs.NI])</title>
<link>http://arxiv.org/abs/1904.00226</link>
<description rdf:parseType="Literal">&lt;p&gt;In big cloud structures or large data structures, fog computing could be
interpreted, referring critically to the growing issues and problems in
accessing the information among the Internet of things (IoT) devices. Fog
computing can be used to compute, store, control and connect smart devices to
each other. IoT is an architecture of uniquely identified interrelated physical
things, these physical things are able to communicate with each other and can
transmit and receive information. This research presents a framework of the
combination of the Internet of Things (IoT) and Fog computing. The blockchain
is also the emerging technology that provides a hyper, distributed, public,
authentic ledger to record the transactions. Blockchains technology is a secure
technology that can be a great benefit to the next generation computing. The
confluence of fog, blockchains, and IoT in this area introduces a new
incentive. In this research work, the author mentions the convergence of
blockchain, fog and IoT technological innovations to present an effective
communication framework. The framework is implemented and tested using
different scenarios.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Alam_T/0/1/0/all/0/1&quot;&gt;Tanweer Alam&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00227">
<title>RefineLoc: Iterative Refinement for Weakly-Supervised Action Localization. (arXiv:1904.00227v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1904.00227</link>
<description rdf:parseType="Literal">&lt;p&gt;Video action detectors are usually trained using video datasets with fully
supervised temporal annotations. Building such video datasets is a heavily
expensive task. To alleviate this problem, recent algorithms leverage weak
labelling where videos are untrimmed and only a video-level label is available.
In this paper, we propose RefineLoc, a new method for weakly-supervised
temporal action localization. RefineLoc uses an iterative refinement approach
by estimating and training on snippet-level pseudo ground truth at every
iteration. We show the benefit of using such an iterative approach and present
an extensive analysis of different pseudo ground truth generators. We show the
effectiveness of our model on two standard action datasets, ActivityNet v1.2
and THUMOS14. RefineLoc equipped with a segment prediction-based pseudo ground
truth generator improves the state-of-the-art in weakly-supervised temporal
localization on the challenging and large-scale ActivityNet dataset by 4.2% and
achieves comparable performance with state-of-the-art on THUMOS14.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Alwassel_H/0/1/0/all/0/1&quot;&gt;Humam Alwassel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Heilbron_F/0/1/0/all/0/1&quot;&gt;Fabian Caba Heilbron&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Thabet_A/0/1/0/all/0/1&quot;&gt;Ali Thabet&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ghanem_B/0/1/0/all/0/1&quot;&gt;Bernard Ghanem&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00229">
<title>USIP: Unsupervised Stable Interest Point Detection from 3D Point Clouds. (arXiv:1904.00229v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1904.00229</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we propose the USIP detector: an Unsupervised Stable Interest
Point detector that can detect highly repeatable and accurately localized
keypoints from 3D point clouds under arbitrary transformations without the need
for any ground truth training data. Our USIP detector consists of a feature
proposal network that learns stable keypoints from input 3D point clouds and
their respective transformed pairs from randomly generated transformations. We
provide degeneracy analysis of our USIP detector and suggest solutions to
prevent it. We encourage high repeatability and accurate localization of the
keypoints with a probabilistic chamfer loss that minimizes the distances
between the detected keypoints from the training point cloud pairs. Extensive
experimental results of repeatability tests on several simulated and real-world
3D point cloud datasets from Lidar, RGB-D and CAD models show that our USIP
detector significantly outperforms existing hand-crafted and deep
learning-based 3D keypoint detectors. Our code is available at the project
website. https://github.com/lijx10/USIP
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1&quot;&gt;Jiaxin Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_G/0/1/0/all/0/1&quot;&gt;Gim Hee Lee&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00230">
<title>MortonNet: Self-Supervised Learning of Local Features in 3D Point Clouds. (arXiv:1904.00230v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1904.00230</link>
<description rdf:parseType="Literal">&lt;p&gt;We present a self-supervised task on point clouds, in order to learn
meaningful point-wise features that encode local structure around each point.
Our self-supervised network, named MortonNet, operates directly on
unstructured/unordered point clouds. Using a multi-layer RNN, MortonNet
predicts the next point in a point sequence created by a popular and fast Space
Filling Curve, the Morton-order curve. The final RNN state (coined Morton
feature) is versatile and can be used in generic 3D tasks on point clouds. In
fact, we show how Morton features can be used to significantly improve
performance (+3% for 2 popular semantic segmentation algorithms) in the task of
semantic segmentation of point clouds on the challenging and large-scale S3DIS
dataset. We also show how MortonNet trained on S3DIS transfers well to another
large-scale dataset, vKITTI, leading to an improvement over state-of-the-art of
3.8%. Finally, we use Morton features to train a much simpler and more stable
model for part segmentation in ShapeNet. Our results show how our
self-supervised task results in features that are useful for 3D segmentation
tasks, and generalize well to other datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Thabet_A/0/1/0/all/0/1&quot;&gt;Ali Thabet&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Alwassel_H/0/1/0/all/0/1&quot;&gt;Humam Alwassel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ghanem_B/0/1/0/all/0/1&quot;&gt;Bernard Ghanem&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00231">
<title>Lane Change Decision-making through Deep Reinforcement Learning with Rule-based Constraints. (arXiv:1904.00231v1 [cs.RO])</title>
<link>http://arxiv.org/abs/1904.00231</link>
<description rdf:parseType="Literal">&lt;p&gt;Autonomous driving decision-making is a great challenge due to the complexity
and uncertainty of the traffic environment. Combined with the rule-based
constraints, a Deep Q-Network (DQN) based method is applied for autonomous
driving lane change decision-making task in this study. Through the combination
of high-level lateral decision-making and low-level rule-based trajectory
modification, a safe and efficient lane change behavior can be achieved. With
the setting of our state representation and reward function, the trained agent
is able to take appropriate actions in a real-world-like simulator. The
generated policy is evaluated on the simulator for 10 times, and the results
demonstrate that the proposed rule-based DQN method outperforms the rule-based
approach and the DQN method.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1&quot;&gt;Junjie Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1&quot;&gt;Qichao Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_D/0/1/0/all/0/1&quot;&gt;Dongbin Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1&quot;&gt;Yaran Chen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00234">
<title>Uncertainty Annotated Databases - A Lightweight Approach for Approximating Certain Answers (extended version). (arXiv:1904.00234v1 [cs.DB])</title>
<link>http://arxiv.org/abs/1904.00234</link>
<description rdf:parseType="Literal">&lt;p&gt;Certain answers are a principled method for coping with uncertainty that
arises in many practical data management tasks. Unfortunately, this method is
expensive and may exclude useful (if uncertain) answers. Thus, users frequently
resort to less principled approaches to resolve the uncertainty. In this paper,
we propose Uncertainty Annotated Databases (UA-DBs), which combine an under-
and over-approximation of certain answers to achieve the reliability of certain
answers, with the performance of a classical database system. Furthermore, in
contrast to prior work on certain answers, UA-DBs achieve a higher utility by
including some (explicitly marked) answers that are not certain. UA-DBs are
based on incomplete K-relations, which we introduce to generalize the classical
set-based notions of incomplete databases and certain answers to a much larger
class of data models. Using an implementation of our approach, we demonstrate
experimentally that it efficiently produces tight approximations of certain
answers that are of high utility.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Feng_S/0/1/0/all/0/1&quot;&gt;Su Feng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huber_A/0/1/0/all/0/1&quot;&gt;Aaron Huber&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Glavic_B/0/1/0/all/0/1&quot;&gt;Boris Glavic&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kennedy_O/0/1/0/all/0/1&quot;&gt;Oliver Kennedy&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00237">
<title>A decentralized method for making sensor measurements tamper-proof to support open science applications. (arXiv:1904.00237v1 [cs.CY])</title>
<link>http://arxiv.org/abs/1904.00237</link>
<description rdf:parseType="Literal">&lt;p&gt;Open science has become a synonym for modern, digital and inclusive science.
Inclusion does not stop at open access. Inclusion also requires transparency
through open datasets and the right and ability to take part in the knowledge
creation process. This implies new challenges for digital libraries. Citizens
should be able to contribute data in a curatable form to advance science. At
the same time, this data should be verifiable and attributable to its owner.
Our research project focusses on securing and attributing incoming data streams
from sensors. Our contribution is twofold. First, we analyze the promises of
open science measurement data and point out how Blockchain technology changed
the circumstances for data measurement in science projects using sensors.
Second, we present an open hardware project capable of securing the integrity
of data directly from the source using cryptographic methods. By using
inexpensive modular components and open source software, we lower the barrier
for participation in open science projects. We show how time series of
measurement values using sensors, e.g., temperature, current, and vibration
measurements, can be verifiably and immutably stored. The approach we propose
enables time series data to be stored in a tamper-proof manner and securely
timestamped on a blockchain to prevent any subsequent modification.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wortner_P/0/1/0/all/0/1&quot;&gt;Patrick Wortner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schubotz_M/0/1/0/all/0/1&quot;&gt;Moritz Schubotz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Breitinger_C/0/1/0/all/0/1&quot;&gt;Corinna Breitinger&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Leible_S/0/1/0/all/0/1&quot;&gt;Stephan Leible&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gipp_B/0/1/0/all/0/1&quot;&gt;Bela Gipp&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00240">
<title>OSVNet: Convolutional Siamese Network for Writer Independent Online Signature Verification. (arXiv:1904.00240v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1904.00240</link>
<description rdf:parseType="Literal">&lt;p&gt;Online signature verification (OSV) is one of the most challenging tasks in
writer identification and digital forensics. Owing to the large
intra-individual variability, there is a critical requirement to accurately
learn the intra-personal variations of the signature to achieve higher
classification accuracy. To achieve this, in this paper, we propose an OSV
framework based on deep convolutional Siamese network (DCSN). DCSN
automatically extracts robust feature descriptions based on metric-based loss
function which decreases intra-writer variability (Genuine-Genuine) and
increases inter-individual variability (Genuine-Forgery) and directs the DCSN
for effective discriminative representation learning for online signatures and
extend it for one shot learning framework. Comprehensive experimentation
conducted on three widely accepted benchmark datasets MCYT-100 (DB1), MCYT-330
(DB2) and SVC-2004-Task2 demonstrate the capability of our framework to
distinguish the genuine and forgery samples. Experimental results confirm the
efficiency of deep convolutional Siamese network based OSV by achieving a lower
error rate as compared to many recent and state-of-the art OSV techniques.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sekhar_C/0/1/0/all/0/1&quot;&gt;Chandra Sekhar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mukherjee_P/0/1/0/all/0/1&quot;&gt;Prerana Mukherjee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guru_D/0/1/0/all/0/1&quot;&gt;Devanur S Guru&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pulabaigari_V/0/1/0/all/0/1&quot;&gt;Viswanath Pulabaigari&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00242">
<title>Nearly Minimax-Optimal Regret for Linearly Parameterized Bandits. (arXiv:1904.00242v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1904.00242</link>
<description rdf:parseType="Literal">&lt;p&gt;We study the linear contextual bandit problem with finite action sets. When
the problem dimension is $d$, the time horizon is $T$, and there are $n \leq
2^{d/2}$ candidate actions per time period, we (1) show that the minimax
expected regret is $\Omega(\sqrt{dT \log T \log n})$ for every algorithm, and
(2) introduce a Variable-Confidence-Level (VCL) SupLinUCB algorithm whose
regret matches the lower bound up to iterated logarithmic factors. Our
algorithmic result saves two $\sqrt{\log T}$ factors from previous analysis,
and our information-theoretical lower bound also improves previous results by
one $\sqrt{\log T}$ factor, revealing a regret scaling quite different from
classical multi-armed bandits in which no logarithmic $T$ term is present in
minimax regret. Our proof techniques include variable confidence levels and a
careful analysis of layer sizes of SupLinUCB on the upper bound side, and
delicately constructed adversarial sequences showing the tightness of
elliptical potential lemmas on the lower bound side.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Li_Y/0/1/0/all/0/1&quot;&gt;Yingkai Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yining Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zhou_Y/0/1/0/all/0/1&quot;&gt;Yuan Zhou&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00243">
<title>Symmetry-Based Disentangled Representation Learning requires Interaction with Environments. (arXiv:1904.00243v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1904.00243</link>
<description rdf:parseType="Literal">&lt;p&gt;Finding a generally accepted formal definition of a disentangled
representation in the context of an agent behaving in an environment is an
important challenge towards the construction of data-efficient autonomous
agents. Higgins et al. recently proposed Symmetry-Based Disentangled
Representation Learning, a definition based on a characterization of symmetries
in the environment using group theory. We build on their work and make
observations, theoretical and empirical, that lead us to argue that
Symmetry-Based Disentangled Representation Learning cannot only be based on
fixed data samples. Agents should interact with the environment to discover its
symmetries. All of our experiments can be reproduced on Colab:
&lt;a href=&quot;http://bit.do/eKpqv.&quot;&gt;this http URL&lt;/a&gt;
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Caselles_Dupre_H/0/1/0/all/0/1&quot;&gt;Hugo Caselles-Dupr&amp;#xe9;&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Garcia_Ortiz_M/0/1/0/all/0/1&quot;&gt;Michael Garcia-Ortiz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Filliat_D/0/1/0/all/0/1&quot;&gt;David Filliat&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00244">
<title>Person Re-identification with Bias-controlled Adversarial Training. (arXiv:1904.00244v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1904.00244</link>
<description rdf:parseType="Literal">&lt;p&gt;Inspired by the effectiveness of adversarial training in the area of
Generative Adversarial Networks we present a new approach for learning feature
representations in person re-identification. We investigate different types of
bias that typically occur in re-ID scenarios, i.e., pose, body part and camera
view, and propose a general approach to address them. We introduce an
adversarial strategy for controlling bias, named Bias-controlled Adversarial
framework (BCA), with two complementary branches to reduce or to enhance
bias-related features. The results and comparison to the state of the art on
different benchmarks show that our framework is an effective strategy for
person re-identification. The performance improvements are in both full and
partial views of persons.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Iodice_S/0/1/0/all/0/1&quot;&gt;Sara Iodice&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mikolajczyk_K/0/1/0/all/0/1&quot;&gt;Krystian Mikolajczyk&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00247">
<title>Classification of Motorcycles using Extracted Images of Traffic Monitoring Videos. (arXiv:1904.00247v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1904.00247</link>
<description rdf:parseType="Literal">&lt;p&gt;Due to the great growth of motorcycles in the urban fleet and the growth of
the study on its behavior and of how this vehicle affects the flow of traffic
becomes necessary the development of tools and techniques different from the
conventional ones to identify its presence in the traffic flow and be able to
extract your information. The article in question attempts to contribute to the
study on this type of vehicle by generating a motorcycle image bank and
developing and calibrating a motorcycle classifier by combining the LBP
techniques to create the characteristic vectors and the classification
technique LinearSVC to perform the predictions. In this way the classifier of
vehicles of the type motorcycle developed in this research can classify the
images of vehicles extracted of videos of monitoring between two classes
motorcycles and non-motorcycles with a precision and an accuracy superior to
0,9.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cunha_A/0/1/0/all/0/1&quot;&gt;Adriano Belletti Felicio e Andr&amp;#xe9; Luiz Cunha&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00248">
<title>On the longest common subsequence of Thue-Morse words. (arXiv:1904.00248v1 [cs.DM])</title>
<link>http://arxiv.org/abs/1904.00248</link>
<description rdf:parseType="Literal">&lt;p&gt;The length $a(n)$ of the longest common subsequence of the $n$&apos;th Thue-Morse
word and its bitwise complement is studied. An open problem suggested by Jean
Berstel in 2006 is to find a formula for $a(n)$. In this paper we prove new
lower bounds on $a(n)$ by explicitly constructing a common subsequence between
the Thue-Morse words and their bitwise complement. We obtain the lower bound
$a(n) = 2^{n}(1-o(1))$, saying that when $n$ grows large, the fraction of
omitted symbols in the longest common subsequence of the $n$&apos;th Thue-Morse word
and its bitwise complement goes to $0$. We further generalize to any prefix of
the Thue-Morse sequence, where we prove similar lower bounds.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Blikstad_J/0/1/0/all/0/1&quot;&gt;Joakim Blikstad&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00249">
<title>Knowledge Transfer Between Robots with Similar Dynamics for High-Accuracy Impromptu Trajectory Tracking. (arXiv:1904.00249v1 [cs.RO])</title>
<link>http://arxiv.org/abs/1904.00249</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we propose an online learning approach that enables the
inverse dynamics model learned for a source robot to be transferred to a target
robot (e.g., from one quadrotor to another quadrotor with different mass or
aerodynamic properties). The goal is to leverage knowledge from the source
robot such that the target robot achieves high-accuracy trajectory tracking on
arbitrary trajectories from the first attempt with minimal data recollection
and training. Most existing approaches for multi-robot knowledge transfer are
based on post-analysis of datasets collected from both robots. In this work, we
study the feasibility of impromptu transfer of models across robots by learning
an error prediction module online. In particular, we analytically derive the
form of the mapping to be learned by the online module for exact tracking,
propose an approach for characterizing similarity between robots, and use these
results to analyze the stability of the overall system. The proposed approach
is illustrated in simulation and verified experimentally on two different
quadrotors performing impromptu trajectory tracking tasks, where the quadrotors
are required to accurately track arbitrary hand-drawn trajectories from the
first attempt.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_S/0/1/0/all/0/1&quot;&gt;Siqi Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sarabakha_A/0/1/0/all/0/1&quot;&gt;Andriy Sarabakha&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kayacan_E/0/1/0/all/0/1&quot;&gt;Erdal Kayacan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Helwa_M/0/1/0/all/0/1&quot;&gt;Mohamed K. Helwa&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schoellig_A/0/1/0/all/0/1&quot;&gt;Angela P. Schoellig&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00264">
<title>A New Biometric Template Protection using Random Orthonormal Projection and Fuzzy Commitment. (arXiv:1904.00264v1 [cs.CR])</title>
<link>http://arxiv.org/abs/1904.00264</link>
<description rdf:parseType="Literal">&lt;p&gt;Biometric template protection is one of most essential parts in putting a
biometric-based authentication system into practice. There have been many
researches proposing different solutions to secure biometric templates of
users. They can be categorized into two approaches: feature transformation and
biometric cryptosystem. However, no one single template protection approach can
satisfy all the requirements of a secure biometric-based authentication system.
In this work, we will propose a novel hybrid biometric template protection
which takes benefits of both approaches while preventing their limitations. The
experiments demonstrate that the performance of the system can be maintained
with the support of a new random orthonormal project technique, which reduces
the computational complexity while preserving the accuracy. Meanwhile, the
security of biometric templates is guaranteed by employing fuzzy commitment
protocol.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nguyen_T/0/1/0/all/0/1&quot;&gt;Thi Ai Thao Nguyen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dang_T/0/1/0/all/0/1&quot;&gt;Tran Khanh Dang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nguyen_D/0/1/0/all/0/1&quot;&gt;Dinh Thanh Nguyen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00275">
<title>Prediction Model for Semitransparent Watercolor Pigment Mixtures Using Deep Learning with a Dataset of Transmittance and Reflectance. (arXiv:1904.00275v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1904.00275</link>
<description rdf:parseType="Literal">&lt;p&gt;Learning color mixing is difficult for novice painters. In order to support
novice painters in learning color mixing, we propose a prediction model for
semitransparent pigment mixtures and use its prediction results to create a
Smart Palette system. Such a system is constructed by first building a
watercolor dataset with two types of color mixing data, indicated by
transmittance and reflectance: incrementation of the same primary pigment and a
mixture of two different pigments. Next, we apply the collected data to a deep
neural network to train a model for predicting the results of semitransparent
pigment mixtures. Finally, we constructed a Smart Palette that provides
easily-followable instructions on mixing a target color with two primary
pigments in real life: when users pick a pixel, an RGB color, from an image,
the system returns its mixing recipe which indicates the two primary pigments
being used and their quantities.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1&quot;&gt;Mei-Yun Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1&quot;&gt;Ya-Bo Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chang_S/0/1/0/all/0/1&quot;&gt;Sheng-Ping Chang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ouhyoung_M/0/1/0/all/0/1&quot;&gt;Ming Ouhyoung&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00276">
<title>Person-in-WiFi: Fine-grained Person Perception using WiFi. (arXiv:1904.00276v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1904.00276</link>
<description rdf:parseType="Literal">&lt;p&gt;Fine-grained person perception such as body segmentation and pose estimation
has been achieved with many 2D and 3D sensors such as RGB/depth cameras, radars
(e.g., RF-Pose) and LiDARs. These sensors capture 2D pixels or 3D point clouds
of person bodies with high spatial resolution, such that the existing
Convolutional Neural Networks can be directly applied for perception. In this
paper, we take one step forward to show that fine-grained person perception is
possible even with 1D sensors: WiFi antennas. To our knowledge, this is the
first work to perceive persons with pervasive WiFi devices, which is cheaper
and power efficient than radars and LiDARs, invariant to illumination, and has
little privacy concern comparing to cameras. We used two sets of off-the-shelf
WiFi antennas to acquire signals, i.e., one transmitter set and one receiver
set. Each set contains three antennas lined-up as a regular household WiFi
router. The WiFi signal generated by a transmitter antenna, penetrates through
and reflects on human bodies, furniture and walls, and then superposes at a
receiver antenna as a 1D signal sample (instead of 2D pixels or 3D point
clouds). We developed a deep learning approach that uses annotations on 2D
images, takes the received 1D WiFi signals as inputs, and performs body
segmentation and pose estimation in an end-to-end manner. Experimental results
on over 100000 frames under 16 indoor scenes demonstrate that Person-in-WiFi
achieved person perception comparable to approaches using 2D images.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_F/0/1/0/all/0/1&quot;&gt;Fei Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_S/0/1/0/all/0/1&quot;&gt;Sanping Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Panev_S/0/1/0/all/0/1&quot;&gt;Stanislav Panev&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Han_J/0/1/0/all/0/1&quot;&gt;Jinsong Han&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_D/0/1/0/all/0/1&quot;&gt;Dong Huang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00277">
<title>Can WiFi Estimate Person Pose?. (arXiv:1904.00277v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1904.00277</link>
<description rdf:parseType="Literal">&lt;p&gt;WiFi human sensing has achieved great progress in indoor localization,
activity classification, etc. Retracing the development of these work, we have
a natural question: can WiFi devices work like cameras for vision applications?
In this paper We try to answer this question by exploring the ability of WiFi
on estimating single person pose. We use a 3-antenna WiFi sender and a
3-antenna receiver to generate WiFi data. Meanwhile, we use a synchronized
camera to capture person videos for corresponding keypoint annotations. We
further propose a fully convolutional network (FCN), termed WiSPPN, to estimate
single person pose from the collected data and annotations. Evaluation on over
80k images (16 sites and 8 persons) replies aforesaid question with a positive
answer. Codes have been made publicly available at
https://github.com/geekfeiw/WiSPPN.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_F/0/1/0/all/0/1&quot;&gt;Fei Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Panev_S/0/1/0/all/0/1&quot;&gt;Stanislav Panev&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dai_Z/0/1/0/all/0/1&quot;&gt;Ziyi Dai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Han_J/0/1/0/all/0/1&quot;&gt;Jinsong Han&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_D/0/1/0/all/0/1&quot;&gt;Dong Huang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00284">
<title>COCO-GAN: Generation by Parts via Conditional Coordinating. (arXiv:1904.00284v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1904.00284</link>
<description rdf:parseType="Literal">&lt;p&gt;Humans can only interact with part of the surrounding environment due to
biological restrictions. Therefore, we learn to reason the spatial
relationships across a series of observations to piece together the surrounding
environment. Inspired by such behavior and the fact that machines also have
computational constraints, we propose \underline{CO}nditional
\underline{CO}ordinate GAN (COCO-GAN) of which the generator generates images
by parts based on their spatial coordinates as the condition. On the other
hand, the discriminator learns to justify realism across multiple assembled
patches by global coherence, local appearance, and edge-crossing continuity.
Despite the full images are never generated during training, we show that
COCO-GAN can produce \textbf{state-of-the-art-quality} full images during
inference. We further demonstrate a variety of novel applications enabled by
teaching the network to be aware of coordinates. First, we perform
extrapolation to the learned coordinate manifold and generate off-the-boundary
patches. Combining with the originally generated full image, COCO-GAN can
produce images that are larger than training samples, which we called
&quot;beyond-boundary generation&quot;. We then showcase panorama generation within a
cylindrical coordinate system that inherently preserves horizontally cyclic
topology. On the computation side, COCO-GAN has a built-in divide-and-conquer
paradigm that reduces memory requisition during training and inference,
provides high-parallelism, and can generate parts of images on-demand.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_C/0/1/0/all/0/1&quot;&gt;Chieh Hubert Lin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chang_C/0/1/0/all/0/1&quot;&gt;Chia-Che Chang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1&quot;&gt;Yu-Sheng Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Juan_D/0/1/0/all/0/1&quot;&gt;Da-Cheng Juan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wei_W/0/1/0/all/0/1&quot;&gt;Wei Wei&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1&quot;&gt;Hwann-Tzong Chen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00285">
<title>Evaluating CNNs on the Gestalt Principle of Closure. (arXiv:1904.00285v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1904.00285</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep convolutional neural networks (CNNs) are widely known for their
outstanding performance in classification and regression tasks over
high-dimensional data. This made them a popular and powerful tool for a large
variety of applications in industry and academia. Recent publications show that
seemingly easy classifaction tasks (for humans) can be very challenging for
state of the art CNNs. An attempt to describe how humans perceive visual
elements is given by the Gestalt principles. In this paper we evaluate AlexNet
and GoogLeNet regarding their performance on classifying the correctness of the
well known Kanizsa triangles, which heavily rely on the Gestalt principle of
closure. Therefore we created various datasets containing valid as well as
invalid variants of the Kanizsa triangle. Our findings suggest that perceiving
objects by utilizing the principle of closure is very challenging for the
applied network architectures but they appear to adapt to the effect of
closure.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ehrensperger_G/0/1/0/all/0/1&quot;&gt;Gregor Ehrensperger&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Stabinger_S/0/1/0/all/0/1&quot;&gt;Sebastian Stabinger&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sanchez_A/0/1/0/all/0/1&quot;&gt;Antonio Rodr&amp;#xed;guez S&amp;#xe1;nchez&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00287">
<title>Convex Stochastic Dominance in Bayesian Estimation and Controlled Sensing POMDPs. (arXiv:1904.00287v1 [cs.SY])</title>
<link>http://arxiv.org/abs/1904.00287</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper provides conditions on the observation probability distribution in
Bayesian localization and optimal filtering so that the conditional mean
estimate satisfies convex stochastic dominance. This convex dominance result
allows us to compare the mean square error of optimal Bayesian estimators. The
result is then used to give sufficient conditions so that the optimal policy of
a controlled sensing two-state partially observed Markov decision process
(POMDP) is lower bounded by a myopic policy. Numerical examples are presented
where the Shannon capacity of the observation distribution using one action
dominates that of another, and convex dominance holds but Blackwell dominance
does not hold, thereby illustrating the usefulness of the main result in
localization, filtering and controlled sensing applications.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Krishnamurthy_V/0/1/0/all/0/1&quot;&gt;Vikram Krishnamurthy&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00289">
<title>On the Estimation and Use of Statistical Modelling in Information Retrieval. (arXiv:1904.00289v1 [cs.IR])</title>
<link>http://arxiv.org/abs/1904.00289</link>
<description rdf:parseType="Literal">&lt;p&gt;Several tasks in information retrieval (IR) rely on assumptions regarding the
distribution of some property (such as term frequency) in the data being
processed. This thesis argues that such distributional assumptions can lead to
incorrect conclusions and proposes a statistically principled method for
determining the &quot;true&quot; distribution. This thesis further applies this method to
derive a new family of ranking models that adapt their computations to the
statistics of the data being processed. Experimental evaluation shows results
on par or better than multiple strong baselines on several TREC collections.
Overall, this thesis concludes that distributional assumptions can be replaced
with an effective, efficient and principled method for determining the &quot;true&quot;
distribution and that using the &quot;true&quot; distribution can lead to improved
retrieval performance.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Petersen_C/0/1/0/all/0/1&quot;&gt;Casper Petersen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00291">
<title>Two-phase flow regime prediction using LSTM based deep recurrent neural network. (arXiv:1904.00291v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1904.00291</link>
<description rdf:parseType="Literal">&lt;p&gt;Long short-term memory (LSTM) and recurrent neural network (RNN) has achieved
great successes on time-series prediction. In this paper, a methodology of
using LSTM-based deep-RNN for two-phase flow regime prediction is proposed,
motivated by previous research on constructing deep RNN. The method is featured
with fast response and accuracy. The built RNN networks are trained and tested
with time-series void fraction data collected using impedance void meter. The
result shows that the prediction accuracy depends on the depth of network and
the number of layer cells. However, deeper and larger network consumes more
time in predicting.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dang_Z/0/1/0/all/0/1&quot;&gt;Zhuoran Dang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ishii_M/0/1/0/all/0/1&quot;&gt;Mamoru Ishii&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00296">
<title>Using Scratch to Teach Undergraduate Students&apos; Skills on Artificial Intelligence. (arXiv:1904.00296v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1904.00296</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper presents a educational workshop in Scratch that is proposed for
the active participation of undergraduate students in contexts of Artificial
Intelligence. The main objective of the activity is to demystify the complexity
of Artificial Intelligence and its algorithms. For this purpose, students must
realize simple exercises of clustering and two neural networks, in Scratch. The
detailed methodology to get that is presented in the article.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Estevez_J/0/1/0/all/0/1&quot;&gt;Julian Estevez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Garate_G/0/1/0/all/0/1&quot;&gt;Gorka Garate&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guede_J/0/1/0/all/0/1&quot;&gt;JM Lopez Guede&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Grana_M/0/1/0/all/0/1&quot;&gt;Manuel Gra&amp;#xf1;a&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00303">
<title>Learning Semantic Embedding Spaces for Slicing Vegetables. (arXiv:1904.00303v1 [cs.RO])</title>
<link>http://arxiv.org/abs/1904.00303</link>
<description rdf:parseType="Literal">&lt;p&gt;In this work, we present an interaction-based approach to learn semantically
rich representations for the task of slicing vegetables. Unlike previous
approaches, we focus on object-centric representations and use auxiliary tasks
to learn rich representations using a two-step process. First, we use simple
auxiliary tasks, such as predicting the thickness of a cut slice, to learn an
embedding space which captures object properties that are important for the
task of slicing vegetables. In the second step, we use these learned latent
embeddings to learn a forward model. Learning a forward model affords us to
plan online in the latent embedding space and forces our model to improve its
representations while performing the slicing task. To show the efficacy of our
approach we perform experiments on two different vegetables: cucumbers and
tomatoes. Our experimental evaluation shows that our method is able to capture
important semantic properties for the slicing task, such as the thickness of
the vegetable being cut. We further show that by using our learned forward
model, we can plan for the task of vegetable slicing.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sharma_M/0/1/0/all/0/1&quot;&gt;Mohit Sharma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_K/0/1/0/all/0/1&quot;&gt;Kevin Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kroemer_O/0/1/0/all/0/1&quot;&gt;Oliver Kroemer&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00306">
<title>Decomposition and Modeling in the Non-Manifold domain. (arXiv:1904.00306v1 [cs.GR])</title>
<link>http://arxiv.org/abs/1904.00306</link>
<description rdf:parseType="Literal">&lt;p&gt;The problem of decomposing non-manifold object has already been studied in
solid modeling. However, the few proposed solutions are limited to the problem
of decomposing solids described through their boundaries. In this thesis we
study the problem of decomposing an arbitrary non-manifold simplicial complex
into more regular components. A formal notion of decomposition is developed
using combinatorial topology. The proposed decomposition is unique, for a given
complex, and is computable for complexes of any dimension. A decomposition
algorithm is proposed that is linear w.r.t. the size of the input. In three or
higher dimensions a decomposition into manifold parts is not always possible.
Thus, in higher dimensions, we decompose a non-manifold into a decidable super
class of manifolds, that we call, Initial-Quasi-Manifolds. We also defined a
two-layered data structure, the Extended Winged data structure. This data
structure is a dimension independent data structure conceived to model
non-manifolds through their decomposition into initial-quasi-manifold parts.
Our two layered data structure describes the structure of the decomposition and
each component separately. In the second layer we encode the connectivity
structure of the decomposition. We analyze the space requirements of the
Extended Winged data structure and give algorithms to build and navigate it.
Finally, we discuss time requirements for the computation of topological
relations and show that, for surfaces and tetrahedralizations, embedded in real
3D space, all topological relations can be extracted in optimal time. This
approach offers a compact, dimension independent, representation for
non-manifolds that can be useful whenever the modeled object has few
non-manifold singularities.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Morando_F/0/1/0/all/0/1&quot;&gt;Franco Morando&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00310">
<title>Learn to Grow: A Continual Structure Learning Framework for Overcoming Catastrophic Forgetting. (arXiv:1904.00310v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1904.00310</link>
<description rdf:parseType="Literal">&lt;p&gt;Addressing catastrophic forgetting is one of the key challenges in continual
learning where machine learning systems are trained with sequential or
streaming tasks. Despite recent remarkable progress in state-of-the-art deep
learning, deep neural networks (DNNs) are still plagued with the catastrophic
forgetting problem. This paper presents a conceptually simple yet general and
effective framework for handling catastrophic forgetting in continual learning
with DNNs. The proposed method consists of two components: a neural structure
optimization component and a parameter learning and/or fine-tuning component.
The former learns the best neural structure for the current task on top of the
current DNN trained with previous tasks. It learns whether to reuse or adapt
building blocks in the current DNN, or to create new ones if needed under the
differentiable neural architecture search framework. The latter estimates
parameters for newly introduced structures, and fine-tunes the old ones if
preferred. By separating the explicit neural structure learning and the
parameter estimation, not only is the proposed method capable of evolving
neural structures in an intuitively meaningful way, but also shows strong
capabilities of alleviating catastrophic forgetting in experiments.
Furthermore, the proposed method outperforms all other baselines on the
permuted MNIST dataset, the split CIFAR100 dataset and the Visual Domain
Decathlon dataset in continual learning setting.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1&quot;&gt;Xilai Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1&quot;&gt;Yingbo Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_T/0/1/0/all/0/1&quot;&gt;Tianfu Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Socher_R/0/1/0/all/0/1&quot;&gt;Richard Socher&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xiong_C/0/1/0/all/0/1&quot;&gt;Caiming Xiong&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00313">
<title>Modeling Drug-Disease Relations with Linguistic and Knowledge Graph Constraints. (arXiv:1904.00313v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1904.00313</link>
<description rdf:parseType="Literal">&lt;p&gt;FDA drug labels are rich sources of information about drugs and drug-disease
relations, but their complexity makes them challenging texts to analyze in
isolation. To overcome this, we situate these labels in two health knowledge
graphs: one built from precise structured information about drugs and diseases,
and another built entirely from a database of clinical narrative texts using
simple heuristic methods. We show that Probabilistic Soft Logic models defined
over these graphs are superior to text-only and relation-only variants, and
that the clinical narratives graph delivers exceptional results with little
manual effort. Finally, we release a new dataset of drug labels with
annotations for five distinct drug-disease relations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Godefroy_B/0/1/0/all/0/1&quot;&gt;Bruno Godefroy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Potts_C/0/1/0/all/0/1&quot;&gt;Christopher Potts&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00314">
<title>Molecular geometry prediction using a deep generative graph neural network. (arXiv:1904.00314v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1904.00314</link>
<description rdf:parseType="Literal">&lt;p&gt;A molecule&apos;s geometry, also known as conformation, is one of a molecule&apos;s
most important properties, determining the reactions it participates in, the
bonds it forms, and the interactions it has with other molecules. Conventional
conformation generation methods minimize hand-designed molecular force field
energy functions that are not well correlated with the true energy function of
a molecule observed in nature. They generate geometrically diverse sets of
conformations, some of which are very similar to the ground-truth conformations
and others of which are very different. In this paper we propose a conditional
deep generative graph neural network that learns an energy function from data
by directly learning to generate molecular conformations given a molecular
graph. On three large scale small molecule datasets, we show that our method
generates a set of conformations that on average is far more likely to be close
to the corresponding reference conformations than are those obtained from
conventional force field methods. Our method maintains geometrical diversity by
generating conformations that are not too similar to each other, and is also
computationally faster. We also show that our method can be used to provide
initial coordinates for conventional force field methods. On one of the
evaluated datasets we show that this combination allows us to combine the best
of both methods, yielding generated conformations that are on average close to
ground-truth conformations with some very similar to ground-truth
conformations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mansimov_E/0/1/0/all/0/1&quot;&gt;Elman Mansimov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mahmood_O/0/1/0/all/0/1&quot;&gt;Omar Mahmood&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kang_S/0/1/0/all/0/1&quot;&gt;Seokho Kang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cho_K/0/1/0/all/0/1&quot;&gt;Kyunghyun Cho&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00315">
<title>A Blockchain-based Educational Record Repository. (arXiv:1904.00315v1 [cs.OH])</title>
<link>http://arxiv.org/abs/1904.00315</link>
<description rdf:parseType="Literal">&lt;p&gt;The Blockchain technology was initially adopted to implement various
cryptocurrencies. Currently, Blockchain is foreseen as a general purpose
technology with a huge potential in many areas. Blockchain-based applications
have inherent characteristics like authenticity, immutability and consensus.
Beyond that, records stored on Blockchain ledger can be accessed any time and
from any location. Blockchain has a great potential for managing and
maintaining educational records. This paper presents a Blockchain-based
Educational Record Repository (BcER2) that manages and distributes educational
assets for academic and industry professionals. The BcER2 system allows
educational records like e-diplomas and e-certificates to be securely and
seamless transferred, shared and distributed by parties.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bessa_E/0/1/0/all/0/1&quot;&gt;Emanuel E. Bessa&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Martins_J/0/1/0/all/0/1&quot;&gt;Joberto S. B. Martins&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00317">
<title>A New Expert Questioning Approach to More Efficient Fault Localization in Ontologies. (arXiv:1904.00317v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1904.00317</link>
<description rdf:parseType="Literal">&lt;p&gt;When ontologies reach a certain size and complexity, faults such as
inconsistencies, unsatisfiable classes or wrong entailments are hardly
avoidable. Locating the incorrect axioms that cause these faults is a hard and
time-consuming task. Addressing this issue, several techniques for
semi-automatic fault localization in ontologies have been proposed. Often,
these approaches involve a human expert who provides answers to
system-generated questions about the intended (correct) ontology in order to
reduce the possible fault locations. To suggest as informative questions as
possible, existing methods draw on various algorithmic optimizations as well as
heuristics. However, these computations are often based on certain assumptions
about the interacting user.
&lt;/p&gt;
&lt;p&gt;In this work, we characterize and discuss different user types and show that
existing approaches do not achieve optimal efficiency for all of them. As a
remedy, we suggest a new type of expert question which aims at fitting the
answering behavior of all analyzed experts. Moreover, we present an algorithm
to optimize this new query type which is fully compatible with the (tried and
tested) heuristics used in the field. Experiments on faulty real-world
ontologies show the potential of the new querying method for minimizing the
expert consultation time, independent of the expert type. Besides, the gained
insights can inform the design of interactive debugging tools towards better
meeting their users&apos; needs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rodler_P/0/1/0/all/0/1&quot;&gt;Patrick Rodler&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Eichholzer_M/0/1/0/all/0/1&quot;&gt;Michael Eichholzer&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00318">
<title>Optimal Detection of UAV&apos;s Transmission with Beam Sweeping in Wireless Networks. (arXiv:1904.00318v1 [cs.IT])</title>
<link>http://arxiv.org/abs/1904.00318</link>
<description rdf:parseType="Literal">&lt;p&gt;In this work, an detection strategy based on multiple antennas with beam
sweeping is developed to detect UAV&apos;s potential transmission in wireless
networks. Specifically, suspicious angle range where the UAV may present is
divided into different sectors to potentially increase detection accuracy by
using beamforming gain. We then develop the optimal detector and derive its
detection error probability in a closed-form expression. We also utilize the
Pinsker&apos;s inequality and Kullback-Leibler divergence to yield low-complex
approximation for the detection error probability, based on which we obtain
some significant insights on the detection performance. Our examination shows
that there exists an optimal number of sectors that can minimize the detection
error probability in some scenarios (e.g., when the number of measurements is
limited). Intuitively, this can be explained by the fact that there exists an
optimal accuracy of the telescope used to find an object in the sky within
limited time period.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hu_J/0/1/0/all/0/1&quot;&gt;Jinsong Hu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1&quot;&gt;Yongpeng Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_R/0/1/0/all/0/1&quot;&gt;Riqing Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shu_F/0/1/0/all/0/1&quot;&gt;Feng Shu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1&quot;&gt;Jiangzhou Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00319">
<title>Discrete Rotation Equivariance for Point Cloud Recognition. (arXiv:1904.00319v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1904.00319</link>
<description rdf:parseType="Literal">&lt;p&gt;Despite the recent active research on processing point clouds with deep
networks, few attention has been on the sensitivity of the networks to
rotations. In this paper, we propose a deep learning architecture that achieves
discrete $\mathbf{SO}(2)$/$\mathbf{SO}(3)$ rotation equivariance for point
cloud recognition. Specifically, the rotation of an input point cloud with
elements of a rotation group is similar to shuffling the feature vectors
generated by our approach. The equivariance is easily reduced to invariance by
eliminating the permutation with operations such as maximum or average. Our
method can be directly applied to any existing point cloud based networks,
resulting in significant improvements in their performance for rotated inputs.
We show state-of-the-art results in the classification tasks with various
datasets under both $\mathbf{SO}(2)$ and $\mathbf{SO}(3)$ rotations. In
addition, we further analyze the necessary conditions of applying our approach
to PointNet based networks. Source codes at
https://github.com/lijx10/rot-equ-net
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1&quot;&gt;Jiaxin Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bi_Y/0/1/0/all/0/1&quot;&gt;Yingcai Bi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_G/0/1/0/all/0/1&quot;&gt;Gim Hee Lee&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00320">
<title>NM-Net: Mining Reliable Neighbors for Robust Feature Correspondences. (arXiv:1904.00320v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1904.00320</link>
<description rdf:parseType="Literal">&lt;p&gt;Feature correspondence selection is pivotal to many feature-matching based
tasks in computer vision. Searching for spatially k-nearest neighbors is a
common strategy for extracting local information in many previous works.
However, there is no guarantee that the spatially k-nearest neighbors of
correspondences are consistent because the spatial distribution of false
correspondences is often irregular. To address this issue, we present a
compatibility-specific mining method to search for consistent neighbors.
Moreover, in order to extract and aggregate more reliable features from
neighbors, we propose a hierarchical network named NM-Net with a series of
convolution layers taking the generated graph as input, which is insensitive to
the order of correspondences. Our experimental results have shown the proposed
method achieves the state-of-the-art performance on four datasets with various
inlier ratios and varying numbers of feature consistencies.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_C/0/1/0/all/0/1&quot;&gt;Chen Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cao_Z/0/1/0/all/0/1&quot;&gt;Zhiguo Cao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1&quot;&gt;Chi Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1&quot;&gt;Xin Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1&quot;&gt;Jiaqi Yang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00324">
<title>SysML&apos;19 demo: customizable and reusable Collective Knowledge pipelines to automate and reproduce machine learning experiments. (arXiv:1904.00324v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1904.00324</link>
<description rdf:parseType="Literal">&lt;p&gt;Reproducing, comparing and reusing results from machine learning and systems
papers is a very tedious, ad hoc and time-consuming process. I will demonstrate
how to automate this process using open-source, portable, customizable and
CLI-based Collective Knowledge workflows and pipelines developed by the
community. I will help participants run several real-world non-virtualized CK
workflows from the SysML&apos;19 conference, companies (General Motors, Arm) and
MLPerf benchmark to automate benchmarking and co-design of efficient
software/hardware stacks for machine learning workloads. I hope that our
approach will help authors reduce their effort when sharing reusable and
extensible research artifacts while enabling artifact evaluators to
automatically validate experimental results from published papers in a standard
and portable way.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fursin_G/0/1/0/all/0/1&quot;&gt;Grigori Fursin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00325">
<title>ImageGCN: Multi-Relational Image Graph Convolutional Networks for Disease Identification with Chest X-rays. (arXiv:1904.00325v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1904.00325</link>
<description rdf:parseType="Literal">&lt;p&gt;Image representation is a fundamental task in computer vision. However, most
of the existing approaches for image representation ignore the relations
between images and consider each input image independently. Intuitively,
relations between images can help to understand the images and maintain model
consistency over related images. In this paper, we consider modeling the
image-level relations to generate more informative image representations, and
propose ImageGCN, an end-to-end graph convolutional network framework for
multi-relational image modeling. We also apply ImageGCN to chest X-ray (CXR)
images where rich relational information is available for disease
identification. Unlike previous image representation models, ImageGCN learns
the representation of an image using both its original pixel features and the
features of related images. Besides learning informative representations for
images, ImageGCN can also be used for object detection in a weakly supervised
manner. The Experimental results on ChestX-ray14 dataset demonstrate that
ImageGCN can outperform respective baselines in both disease identification and
localization tasks and can achieve comparable and often better results than the
state-of-the-art methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mao_C/0/1/0/all/0/1&quot;&gt;Chengsheng Mao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yao_L/0/1/0/all/0/1&quot;&gt;Liang Yao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Luo_Y/0/1/0/all/0/1&quot;&gt;Yuan Luo&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00326">
<title>MedGCN: Graph Convolutional Networks for Multiple Medical Tasks. (arXiv:1904.00326v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1904.00326</link>
<description rdf:parseType="Literal">&lt;p&gt;Laboratory testing and medication prescription are two of the most important
routines in daily clinical practice. Developing an artificial intelligence
system that can automatically make lab test imputations and medication
recommendations can save cost on potentially redundant lab tests and inform
physicians in more effective prescription. We present an intelligent model that
can automatically recommend the patients&apos; medications based on their incomplete
lab tests, and can even accurately estimate the lab values that have not been
taken. We model the complex relations between multiple types of medical
entities with their inherent features in a heterogeneous graph. Then we learn a
distributed representation for each entity in the graph based on graph
convolutional networks to make the representations integrate information from
multiple types of entities. Since the entity representations incorporate
multiple types of medical information, they can be used for multiple medical
tasks. In our experiments, we construct a graph to associate patients,
encounters, lab tests and medications, and conduct the two tasks: medication
recommendation and lab test imputation. The experimental results demonstrate
that our model can outperform the state-of-the-art models in both tasks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mao_C/0/1/0/all/0/1&quot;&gt;Chengsheng Mao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yao_L/0/1/0/all/0/1&quot;&gt;Liang Yao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Luo_Y/0/1/0/all/0/1&quot;&gt;Yuan Luo&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00327">
<title>Power Control for Wireless VBR Video Streaming: From Optimization to Reinforcement Learning. (arXiv:1904.00327v1 [cs.IT])</title>
<link>http://arxiv.org/abs/1904.00327</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we investigate the problem of power control for streaming
variable bit rate (VBR) videos over wireless links. A system model involving a
transmitter (e.g., a base station) that sends VBR video data to a receiver
(e.g., a mobile user) equipped with a playout buffer is adopted, as used in
dynamic adaptive streaming video applications. In this setting, we analyze
power control policies considering the following two objectives: 1) the
minimization of the transmit power consumption, and 2) the minimization of the
transmission completion time of the communication session. In order to play the
video without interruptions, the power control policy should also satisfy the
requirement that the VBR video data is delivered to the mobile user without
causing playout buffer underflow or overflows. A directional water-filling
algorithm, which provides a simple and concise interpretation of the necessary
optimality conditions, is identified as the optimal offline policy. Following
this, two online policies are proposed for power control based on channel side
information (CSI) prediction within a short time window. Dynamic programming is
employed to implement the optimal offline and the initial online power control
policies that minimize the transmit power consumption in the communication
session. Subsequently, reinforcement learning (RL) based approach is employed
for the second online power control policy. Via simulation results, we show
that the optimal offline power control policy that minimizes the overall power
consumption leads to substantial energy savings compared to the strategy of
minimizing the time duration of video streaming. We also demonstrate that the
RL algorithm performs better than the dynamic programming based online grouped
water-filling (GWF) strategy unless the channel is highly correlated.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ye_C/0/1/0/all/0/1&quot;&gt;Chuang Ye&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gursoy_M/0/1/0/all/0/1&quot;&gt;M. Cenk Gursoy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Velipasalar_S/0/1/0/all/0/1&quot;&gt;Senem Velipasalar&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00328">
<title>An Efficient Approach for Cell Segmentation in Phase Contrast Microscopy Images. (arXiv:1904.00328v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1904.00328</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we propose a new model to segment cells in phase contrast
microscopy images. Cell images collected from the similar scenario share a
similar background. Inspired by this, we separate cells from the background in
images by formulating the problem as a low-rank and structured sparse matrix
decomposition problem. Then, we propose the inverse diffraction pattern
filtering method to further segment individual cells in the images. This is a
deconvolution process that has a much lower computational complexity when
compared to the other restoration methods. Experiments demonstrate the
effectiveness of the proposed model when it is compared with recent works.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1&quot;&gt;Lin Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00335">
<title>Robust Extended Kalman Filtering for Systems with Measurement Outliers. (arXiv:1904.00335v1 [cs.SY])</title>
<link>http://arxiv.org/abs/1904.00335</link>
<description rdf:parseType="Literal">&lt;p&gt;Outliers can contaminate the measurement process of many nonlinear systems,
which can be caused by sensor errors, model uncertainties, change in ambient
environment, data loss or malicious cyber attacks. When the extended Kalman
filter (EKF) is applied to such systems for state estimation, the outliers can
seriously reduce the estimation accuracy. This paper proposes an innovation
saturation mechanism to modify the EKF toward building robustness against
outliers. This mechanism applies a saturation function to the innovation
process that the EKF leverages to correct the state estimation. As such, when
an outlier occurs, the distorting innovation is saturated and thus prevented
from damaging the state estimation. The mechanism features an adaptive
adjustment of the saturation bound. The design leads to the development robust
EKF approaches for continuous- and discrete-time systems. They are proven to be
capable of generating bounded-error estimation in the presence of bounded
outlier disturbances. An application study about mobile robot localization is
presented, with the numerical simulation showing the efficacy of the proposed
design. Compared to existing methods, the proposed approaches can effectively
reject outliers of various magnitudes, types and durations, at significant
computational efficiency and without requiring measurement redundancy.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fang_H/0/1/0/all/0/1&quot;&gt;Huazhen Fang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Haile_M/0/1/0/all/0/1&quot;&gt;Mulugeta A. Haile&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yebin Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00338">
<title>Observer-Based Distributed Leader-Follower Tracking Control: A New Perspective and Results. (arXiv:1904.00338v1 [cs.SY])</title>
<link>http://arxiv.org/abs/1904.00338</link>
<description rdf:parseType="Literal">&lt;p&gt;Leader-follower tracking control design has received significant attention in
recent years due to its important and wide applications. Considering a
multi-agent system composed of a leader and multiple followers, this paper
proposes and investigates a new perspective into this problem: can we enable a
follower to estimate the leader&apos;s driving input and leverage this idea to
develop new observer-based tracking control approaches? With this motivation,
we develop an input-observer-based leader-follower tracking control framework,
which features distributed input observers that allow a follower to locally
estimate the leader&apos;s input toward enhancing tracking control. This work first
studies the first-order tracking problem. It then extends to the more
sophisticated case of second-order tracking and considers a challenging
situation when the leader&apos;s and followers&apos; velocities are not measured. The
proposed approaches exhibit interesting and useful advantages as revealed by a
comparison with the literature. Convergence properties of the proposed
approaches are rigorously analyzed. Simulation results further illustrate the
efficacy of the proposed perspective, framework and approaches.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yan_C/0/1/0/all/0/1&quot;&gt;Chuan Yan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fang_H/0/1/0/all/0/1&quot;&gt;Huazhen Fang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00344">
<title>BlackMarks: Blackbox Multibit Watermarking for Deep Neural Networks. (arXiv:1904.00344v1 [cs.MM])</title>
<link>http://arxiv.org/abs/1904.00344</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep Neural Networks have created a paradigm shift in our ability to
comprehend raw data in various important fields ranging from computer vision
and natural language processing to intelligence warfare and healthcare. While
DNNs are increasingly deployed either in a white-box setting where the model
internal is publicly known, or a black-box setting where only the model outputs
are known, a practical concern is protecting the models against Intellectual
Property (IP) infringement. We propose BlackMarks, the first end-to-end
multi-bit watermarking framework that is applicable in the black-box scenario.
BlackMarks takes the pre-trained unmarked model and the owner&apos;s binary
signature as inputs and outputs the corresponding marked model with a set of
watermark keys. To do so, BlackMarks first designs a model-dependent encoding
scheme that maps all possible classes in the task to bit &apos;0&apos; and bit &apos;1&apos; by
clustering the output activations into two groups. Given the owner&apos;s watermark
signature (a binary string), a set of key image and label pairs are designed
using targeted adversarial attacks. The watermark (WM) is then embedded in the
prediction behavior of the target DNN by fine-tuning the model with generated
WM key set. To extract the WM, the remote model is queried by the WM key images
and the owner&apos;s signature is decoded from the corresponding predictions
according to the designed encoding scheme. We perform a comprehensive
evaluation of BlackMarks&apos;s performance on MNIST, CIFAR10, ImageNet datasets and
corroborate its effectiveness and robustness. BlackMarks preserves the
functionality of the original DNN and incurs negligible WM embedding runtime
overhead as low as 2.054%.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1&quot;&gt;Huili Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rouhani_B/0/1/0/all/0/1&quot;&gt;Bita Darvish Rouhani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Koushanfar_F/0/1/0/all/0/1&quot;&gt;Farinaz Koushanfar&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00346">
<title>Fully Learnable Group Convolution for Acceleration of Deep Neural Networks. (arXiv:1904.00346v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1904.00346</link>
<description rdf:parseType="Literal">&lt;p&gt;Benefitted from its great success on many tasks, deep learning is
increasingly used on low-computational-cost devices, e.g. smartphone, embedded
devices, etc. To reduce the high computational and memory cost, in this work,
we propose a fully learnable group convolution module (FLGC for short) which is
quite efficient and can be embedded into any deep neural networks for
acceleration. Specifically, our proposed method automatically learns the group
structure in the training stage in a fully end-to-end manner, leading to a
better structure than the existing pre-defined, two-steps, or iterative
strategies. Moreover, our method can be further combined with depthwise
separable convolution, resulting in 5 times acceleration than the vanilla
Resnet50 on single CPU. An additional advantage is that in our FLGC the number
of groups can be set as any value, but not necessarily 2^k as in most existing
methods, meaning better tradeoff between accuracy and speed. As evaluated in
our experiments, our method achieves better performance than existing learnable
group convolution and standard group convolution when using the same number of
groups.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1&quot;&gt;Xijun Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kan_M/0/1/0/all/0/1&quot;&gt;Meina Kan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shan_S/0/1/0/all/0/1&quot;&gt;Shiguang Shan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1&quot;&gt;Xilin Chen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00349">
<title>Efficient and error-tolerant schemes for non-adaptive complex group testing and its application in complex disease genetics. (arXiv:1904.00349v1 [cs.IT])</title>
<link>http://arxiv.org/abs/1904.00349</link>
<description rdf:parseType="Literal">&lt;p&gt;The goal of combinatorial group testing is to efficiently identify up to $d$
defective items in a large population of $n$ items, where $d \ll n$. Defective
items satisfy certain properties while the remaining items in the population do
not. To efficiently identify defective items, a subset of items is pooled and
then tested. In this work, we consider complex group testing (CmplxGT) in which
a set of defective items consists of subsets of positive items (called
\textit{positive complexes}). CmplxGT is classified into two categories:
classical CmplxGT (CCmplxGT) and generalized CmplxGT (GCmplxGT). In CCmplxGT,
the outcome of a test on a subset of items is positive if the subset contains
at least one positive complex, and negative otherwise. In GCmplxGT, the outcome
of a test on a subset of items is positive if the subset has a certain number
of items of some positive complex, and negative otherwise.
&lt;/p&gt;
&lt;p&gt;For CCmplxGT, we present a scheme that efficiently identifies all positive
complexes in time $t \times \mathrm{poly}(d, \ln{n})$ in the presence of
erroneous outcomes, where $t$ is a predefined parameter. As $d \ll n$, this is
significantly better than the currently best time of $\mathrm{poly}(t) \times
O(n \ln{n})$. Moreover, in specific cases, the number of tests in our proposed
scheme is smaller than previous work. For GCmplxGT, we present a scheme that
efficiently identifies all positive complexes. These schemes are directly
applicable in various areas such as complex disease genetics, molecular
biology, and learning a hidden graph.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bui_T/0/1/0/all/0/1&quot;&gt;Thach V. Bui&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kuribayashi_M/0/1/0/all/0/1&quot;&gt;Minoru Kuribayashi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cheraghchi_M/0/1/0/all/0/1&quot;&gt;Mahdi Cheraghchi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Echizen_I/0/1/0/all/0/1&quot;&gt;Isao Echizen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00350">
<title>Conversation Model Fine-Tuning for Classifying Client Utterances in Counseling Dialogues. (arXiv:1904.00350v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1904.00350</link>
<description rdf:parseType="Literal">&lt;p&gt;The recent surge of text-based online counseling applications enables us to
collect and analyze interactions between counselors and clients. A dataset of
those interactions can be used to learn to automatically classify the client
utterances into categories that help counselors in diagnosing client status and
predicting counseling outcome. With proper anonymization, we collect
counselor-client dialogues, define meaningful categories of client utterances
with professional counselors, and develop a novel neural network model for
classifying the client utterances. The central idea of our model, ConvMFiT, is
a pre-trained conversation model which consists of a general language model
built from an out-of-domain corpus and two role-specific language models built
from unlabeled in-domain dialogues. The classification result shows that
ConvMFiT outperforms state-of-the-art comparison models. Further, the attention
weights in the learned model confirm that the model finds expected linguistic
patterns for each category.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Park_S/0/1/0/all/0/1&quot;&gt;Sungjoon Park&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_D/0/1/0/all/0/1&quot;&gt;Donghyun Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Oh_A/0/1/0/all/0/1&quot;&gt;Alice Oh&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00352">
<title>Fast and Full-Resolution Light Field Deblurring using a Deep Neural Network. (arXiv:1904.00352v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1904.00352</link>
<description rdf:parseType="Literal">&lt;p&gt;Restoring a sharp light field image from its blurry input has become
essential due to the increasing popularity of parallax-based image processing.
State-of-the-art blind light field deblurring methods suffer from several
issues such as slow processing, reduced spatial size, and a limited motion blur
model. In this work, we address these challenging problems by generating a
complex blurry light field dataset and proposing a learning-based deblurring
approach. In particular, we model the full 6-degree of freedom (6-DOF) light
field camera motion, which is used to create the blurry dataset using a
combination of real light fields captured with a Lytro Illum camera, and
synthetic light field renderings of 3D scenes. Furthermore, we propose a light
field deblurring network that is built with the capability of large receptive
fields. We also introduce a simple strategy of angular sampling to train on the
large-scale blurry light field effectively. We evaluate our method through both
quantitative and qualitative measurements and demonstrate superior performance
compared to the state-of-the-art method with a massive speedup in execution
time. Our method is about 16K times faster than Srinivasan et. al. [22] and can
deblur a full-resolution light field in less than 2 seconds.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lumentut_J/0/1/0/all/0/1&quot;&gt;Jonathan Samuel Lumentut&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_T/0/1/0/all/0/1&quot;&gt;Tae Hyun Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ramamoorthi_R/0/1/0/all/0/1&quot;&gt;Ravi Ramamoorthi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Park_I/0/1/0/all/0/1&quot;&gt;In Kyu Park&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00355">
<title>Pedestrian re-identification based on Tree branch network with local and global learning. (arXiv:1904.00355v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1904.00355</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep part-based methods in recent literature have revealed the great
potential of learning local part-level representation for pedestrian image in
the task of person re-identification. However, global features that capture
discriminative holistic information of human body are usually ignored or not
well exploited. This motivates us to investigate joint learning global and
local features from pedestrian images. Specifically, in this work, we propose a
novel framework termed tree branch network (TBN) for person re-identification.
Given a pedestrain image, the feature maps generated by the backbone CNN, are
partitioned recursively into several pieces, each of which is followed by a
bottleneck structure that learns finer-grained features for each level in the
hierarchical tree-like framework. In this way, representations are learned in a
coarse-to-fine manner and finally assembled to produce more discriminative
image descriptions. Experimental results demonstrate the effectiveness of the
global and local feature learning method in the proposed TBN framework. We also
show significant improvement in performance over state-of-the-art methods on
three public benchmarks: Market-1501, CUHK-03 and DukeMTMC.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1&quot;&gt;Hui Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_M/0/1/0/all/0/1&quot;&gt;Meng Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lai_Z/0/1/0/all/0/1&quot;&gt;Zhihui Lai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zheng_W/0/1/0/all/0/1&quot;&gt;Weishi Zheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_Z/0/1/0/all/0/1&quot;&gt;Zitong Yu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00357">
<title>Low Rank Parity Check Codes: New Decoding Algorithms and Applications to Cryptography. (arXiv:1904.00357v1 [cs.IT])</title>
<link>http://arxiv.org/abs/1904.00357</link>
<description rdf:parseType="Literal">&lt;p&gt;We introduce a new family of rank metric codes: Low Rank Parity Check codes
(LRPC), for which we propose an efficient probabilistic decoding algorithm.
This family of codes can be seen as the equivalent of classical LDPC codes for
the rank metric. We then use these codes to design cryptosystems \`a la
McEliece: more precisely we propose two schemes for key encapsulation mechanism
(KEM) and public key encryption (PKE). Unlike rank metric codes used in
&lt;/p&gt;
&lt;p&gt;previous encryption algorithms -notably Gabidulin codes - LRPC codes have a
very weak algebraic structure. Our cryptosystems can be seen as an equivalent
of the NTRU cryptosystem (and also to the more recent MDPC \cite{MTSB12}
cryptosystem) in a rank metric context. The present paper is an extended
version of the article introducing LRPC codes, with important new
contributions. We have improved the decoder thanks to a new approach which
allows for decoding of errors of higher rank weight, namely up to
$\frac{2}{3}(n-k)$ when the previous decoding algorithm only decodes up to
$\frac{n-k}{2}$ errors. Our codes therefore outperform the classical Gabidulin
code decoder which deals with weights up to $\frac{n-k}{2}$. This comes at the
expense of probabilistic decoding, but the decoding error probability can be
made arbitrarily small. The new approach can also be used to decrease the
decoding error probability of previous schemes, which is especially useful for
cryptography. Finally, we introduce ideal rank codes, which generalize
double-circulant rank codes and allow us to avoid known structural attacks
based on folding. To conclude, we propose different parameter sizes for our
schemes and we obtain a public key of 3337 bits for key exchange and 5893 bits
for public key encryption, both for 128 bits of security.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Aragon_N/0/1/0/all/0/1&quot;&gt;Nicolas Aragon&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gaborit_P/0/1/0/all/0/1&quot;&gt;Philippe Gaborit&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hauteville_A/0/1/0/all/0/1&quot;&gt;Adrien Hauteville&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ruatta_O/0/1/0/all/0/1&quot;&gt;Olivier Ruatta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zemor_G/0/1/0/all/0/1&quot;&gt;Gilles Z&amp;#xe9;mor&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00358">
<title>Achieving Greater Concurrency in Execution of Smart Contracts using Object Semantics. (arXiv:1904.00358v1 [cs.DC])</title>
<link>http://arxiv.org/abs/1904.00358</link>
<description rdf:parseType="Literal">&lt;p&gt;Popular blockchain such as Ethereum and several others execute complex
transactions in blocks through user defined scripts known as smart contracts.
Normally, a block of the chain consists of multiple transactions of smart
contracts which are added by a miner. To append a correct block into
blockchain, miners execute these smart contract transactions (SCT)
sequentially. Later the validators serially re-execute the SCT of the block. In
the current era of multi-core processors, by employing serial execution of the
transactions, the miners and validators fail to utilize the cores properly and
as a result have poor throughput. By adding concurrency using object semantics
to smart contracts execution, we can achieve the better efficiency and higher
throughput. Some authors have used read-write STMs (RWSTMs) for the concurrent
execution of SCT. Working with higher level operations provide greater
concurrency, better throughput and reduces the number of aborts than RWSTMs. In
this paper, we develop an efficient framework to execute the SCT concurrently
by miner using optimistic Object-Based Software Transactional Memory systems
(OSTMs) and Multi-Version OSTMs (MV-OSTM). A proposed block includes SCT, final
states of the shared data-items, hash of the previous block and a block graph
(BG). BG captures the conflicting relations among the transactions. Later, the
validators re-execute the same SCT concurrently and deterministically with the
help of BG given by miner to verify the final state. If the validation is
successful then proposed block appended into the blockchain and miner gets
incentive otherwise discard the proposed block. MV-OSTM and OSTM miner performs
4.5x and 3.86x average speedups over serial miner. Along with, MV-OSTM and OSTM
validator outperforms average 32.81x and 29.76x than serial validator.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Anjana_P/0/1/0/all/0/1&quot;&gt;Parwat Singh Anjana&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kumari_S/0/1/0/all/0/1&quot;&gt;Sweta Kumari&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Peri_S/0/1/0/all/0/1&quot;&gt;Sathya Peri&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Somani_A/0/1/0/all/0/1&quot;&gt;Archit Somani&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00365">
<title>SART - Similarity, Analogies, and Relatedness for Tatar Language: New Benchmark Datasets for Word Embeddings Evaluation. (arXiv:1904.00365v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1904.00365</link>
<description rdf:parseType="Literal">&lt;p&gt;There is a huge imbalance between languages currently spoken and
corresponding resources to study them. Most of the attention naturally goes to
the &quot;big&quot; languages: those which have the largest presence in terms of media
and number of speakers. Other less represented languages sometimes do not even
have a good quality corpus to study them. In this paper, we tackle this
imbalance by presenting a new set of evaluation resources for Tatar, a language
of the Turkic language family which is mainly spoken in Tatarstan Republic,
Russia.
&lt;/p&gt;
&lt;p&gt;We present three datasets: Similarity and Relatedness datasets that consist
of human scored word pairs and can be used to evaluate semantic models; and
Analogies dataset that comprises analogy questions and allows to explore
semantic, syntactic, and morphological aspects of language modeling. All three
datasets build upon existing datasets for the English language and follow the
same structure. However, they are not mere translations. They take into account
specifics of the Tatar language and expand beyond the original datasets. We
evaluate state-of-the-art word embedding models for two languages using our
proposed datasets for Tatar and the original datasets for English and report
our findings on performance comparison.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khusainova_A/0/1/0/all/0/1&quot;&gt;Albina Khusainova&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khan_A/0/1/0/all/0/1&quot;&gt;Adil Khan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rivera_A/0/1/0/all/0/1&quot;&gt;Ad&amp;#xed;n Ram&amp;#xed;rez Rivera&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00368">
<title>Fourier Transform Approach to Machine Learning. (arXiv:1904.00368v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1904.00368</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a supervised learning algorithm for machine learning applications.
Contrary to the model developing in the classical methods, which treat
training, validation, and test as separate steps, in the presented approach,
there is a unified training and evaluating procedure based on an iterative band
filtering by the use of a fast Fourier transform. The presented approach does
not apply the method of least squares, thus, basically typical ill-conditioned
matrices do not occur at all. The optimal model results from the convergence of
the performance metric, which automatically prevents the usual underfitting and
overfitting problems. The algorithm capability is investigated for noisy data,
and the obtained result demonstrates a reliable and powerful machine learning
approach beyond the typical limits of the classical methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mehrabkhani_S/0/1/0/all/0/1&quot;&gt;Soheil Mehrabkhani&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00370">
<title>Variational Adversarial Active Learning. (arXiv:1904.00370v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1904.00370</link>
<description rdf:parseType="Literal">&lt;p&gt;Active learning aims to develop label-efficient algorithms by sampling the
most representative queries to be labeled by an oracle. We describe a
pool-based semi-supervised active learning algorithm that implicitly learns
this sampling mechanism in an adversarial manner. Our method learns a latent
space using a variational autoencoder (VAE) and an adversarial network trained
to discriminate between unlabeled and labeled data. The mini-max game between
the VAE and the adversarial network is played such that while the VAE tries to
trick the adversarial network into predicting that all data points are from the
labeled pool, the adversarial network learns how to discriminate between
dissimilarities in the latent space. We extensively evaluate our method on
various image classification and semantic segmentation benchmark datasets and
establish a new state of the art on $\text{CIFAR10/100}$, $\text{Caltech-256}$,
$\text{ImageNet}$, $\text{Cityscapes}$, and $\text{BDD100K}$. Our results
demonstrate that our adversarial approach learns an effective low dimensional
latent space in large-scale settings and provides for a computationally
efficient sampling method.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sinha_S/0/1/0/all/0/1&quot;&gt;Samarth Sinha&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ebrahimi_S/0/1/0/all/0/1&quot;&gt;Sayna Ebrahimi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Darrell_T/0/1/0/all/0/1&quot;&gt;Trevor Darrell&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00373">
<title>Cyclic Shift Code for SAC-OCDMA Using Fiber Bragg-Grating. (arXiv:1904.00373v1 [cs.IT])</title>
<link>http://arxiv.org/abs/1904.00373</link>
<description rdf:parseType="Literal">&lt;p&gt;We proposed a novel code called cyclic shift (CS) code to overcome the
drawbacks exists in traditional Spectral Amplitude Coding- Optical Code
Division Multiple Access (SAC-OCDMA) codes that have been presented in the past
few years. The proposed cyclic shift code has simple construction and large
cardinality in selecting the code weight and the number of users. It also has
zero cross correlation which allows it to suppress both Multiple Access
Interference (MAI) and Phase Induced Intensity Noise (PIIN). Moreover, the
frequency bins of the proposed code exist beside each other which reduce the
number of filters needed to encode and decode the data. Therefore, the receiver
design becomes simple and cost efficient. We compared the performance of our
proposed code to the traditional codes and show that our proposed code gives
better performance than the traditional SAC-OCDMA codes. A mathematical
analysis of CS code has been derived. Simulation analysis for CS code has been
carried out using optisystem ver.13.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mostafa_S/0/1/0/all/0/1&quot;&gt;Salwa Mostafa&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mohamed_A/0/1/0/all/0/1&quot;&gt;Abd El-Naser A. Mohamed&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+El_Samie_F/0/1/0/all/0/1&quot;&gt;Fathi E. Abd El-Samie&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rashed_A/0/1/0/all/0/1&quot;&gt;Ahmed Nabih Zaki Rashed&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00374">
<title>Clique pooling for graph classification. (arXiv:1904.00374v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1904.00374</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a novel graph pooling operation using cliques as the unit pool. As
this approach is purely topological, rather than featural, it is more readily
interpretable, a better analogue to image coarsening than filtering or pruning
techniques, and entirely nonparametric. The operation is implemented within
graph convolution network (GCN) and GraphSAGE architectures and tested against
standard graph classification benchmarks. In addition, we explore the backwards
compatibility of the pooling to regular graphs, demonstrating competitive
performance when replacing two-by-two pooling in standard convolutional neural
networks (CNNs) with our mechanism.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Luzhnica_E/0/1/0/all/0/1&quot;&gt;Enxhell Luzhnica&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Day_B/0/1/0/all/0/1&quot;&gt;Ben Day&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lio_P/0/1/0/all/0/1&quot;&gt;Pietro Lio&amp;#x27;&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00375">
<title>LightChain: A DHT-based Blockchain for Resource Constrained Environments. (arXiv:1904.00375v1 [cs.DC])</title>
<link>http://arxiv.org/abs/1904.00375</link>
<description rdf:parseType="Literal">&lt;p&gt;As an append-only distributed database, blockchain is utilized in a vast
variety of applications including the cryptocurrency and Internet-of-Things
(IoT). The existing blockchain solutions have downsides in communication and
storage efficiency, convergence to centralization, and consistency problems. In
this paper, we propose LightChain, which is the first blockchain architecture
that operates over a Distributed Hash Table (DHT) of participating peers.
LightChain is a permissionless blockchain that provides addressable blocks and
transactions within the network, which makes them efficiently accessible by all
the peers. Each block and transaction is replicated within the DHT of peers and
is retrieved in an on-demand manner. Hence, peers in LightChain are not
required to retrieve or keep the entire blockchain. LightChain is fair as all
of the participating peers have a uniform chance of being involved in the
consensus regardless of their influence such as hashing power or stake.
LightChain provides a deterministic fork-resolving strategy as well as a
blacklisting mechanism, and it is secure against colluding adversarial peers
attacking the availability and integrity of the system. We provide mathematical
analysis and experimental results on scenarios involving 10K nodes to
demonstrate the security and fairness of LightChain.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hassanzadeh_Nazarabadi_Y/0/1/0/all/0/1&quot;&gt;Yahya Hassanzadeh-Nazarabadi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kupcu_A/0/1/0/all/0/1&quot;&gt;Alptekin K&amp;#xfc;p&amp;#xe7;&amp;#xfc;&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ozkasap_O/0/1/0/all/0/1&quot;&gt;&amp;#xd6;znur &amp;#xd6;zkasap&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00377">
<title>A Theoretical Analysis of Deep Neural Networks and Parametric PDEs. (arXiv:1904.00377v1 [math.NA])</title>
<link>http://arxiv.org/abs/1904.00377</link>
<description rdf:parseType="Literal">&lt;p&gt;We derive upper bounds on the complexity of ReLU neural networks
approximating the solution maps of parametric partial differential equations.
In particular, without any knowledge of its concrete shape, we use the inherent
low-dimensionality of the solution manifold to obtain approximation rates which
are significantly superior to those provided by classical approximation
results. We use this low dimensionality to guarantee the existence of a reduced
basis. Then, for a large variety of parametric partial differential equations,
we construct neural networks that yield approximations of the parametric maps
not suffering from a curse of dimension and essentially only depending on the
size of the reduced basis.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Kutyniok_G/0/1/0/all/0/1&quot;&gt;Gitta Kutyniok&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Petersen_P/0/1/0/all/0/1&quot;&gt;Philipp Petersen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Raslan_M/0/1/0/all/0/1&quot;&gt;Mones Raslan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Schneider_R/0/1/0/all/0/1&quot;&gt;Reinhold Schneider&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00378">
<title>MAT-Fly: an educational platform for simulating Unmanned Aerial Vehicles aimed to detect and track moving objects. (arXiv:1904.00378v1 [cs.RO])</title>
<link>http://arxiv.org/abs/1904.00378</link>
<description rdf:parseType="Literal">&lt;p&gt;The main motivation of this work is to propose a simulation approach for a
specific task within the UAV (Unmanned Aerial Vehicle) field, i.e., the visual
detection and tracking of arbitrary moving objects. In particular, it is
described MAT-Fly, a numerical simulation platform for multi-rotors aircrafts
characterized by ease of use and control development. The platform is based on
Matlab and the MathWorks Virtual Reality (VR) and Computer Vision System (CVS)
toolboxes that work together to simulate the behavior of a drone in a 3D
environment while tracking a car that moves along a non trivial path. The VR
toolbox has been chosen due to the familiarity that students have with Matlab
and because it allows to move the attention to the classifier, the tracker, the
reference generator and the trajectory tracking control thanks to its simple
structure. The overall architecture is quite modular so that each block can be
easily replaced with others by simplifying the development phase and by
allowing to add even more functionalities.
&lt;/p&gt;
&lt;p&gt;The numerical simulator makes easy and quick to insert and to remove flight
control system components, testing and comparing different plans, both for
indoor and outdoor scenarios, when computer vision algorithms are in the loop.
In an automatic way, the simulator is able to acquire frames from the virtual
world, to search for one or more objects on which it has been trained during
the learning phase, and to track the target position applying a trajectory
control, addressing in that way the image-based visual servoing problems.
&lt;/p&gt;
&lt;p&gt;Some simple testbeds have been presented in order to show the effectiveness
and robustness of the approach as well as the platform works. We released the
software as open-source, making it available for educational activities.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Silano_G/0/1/0/all/0/1&quot;&gt;Giuseppe Silano&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00381">
<title>Exploring the Effectiveness of Service Decomposition in Fog Computing Architecture for the Internet of Things. (arXiv:1904.00381v1 [cs.NI])</title>
<link>http://arxiv.org/abs/1904.00381</link>
<description rdf:parseType="Literal">&lt;p&gt;The Internet of Things (IoT) aims to connect everyday physical objects to the
internet. These objects will produce a significant amount of data. The
traditional cloud computing architecture aims to process data in the cloud. As
a result, a significant amount of data needs to be communicated to the cloud.
This creates a number of challenges, such as high communication latency between
the devices and the cloud, increased energy consumption of devices during
frequent data upload to the cloud, high bandwidth consumption, while making the
network busy by sending the data continuously, and less privacy because of less
control on the transmitted data to the server. Fog computing has been proposed
to counter these weaknesses. Fog computing aims to process data at the edge and
substantially eliminate the necessity of sending data to the cloud. However,
combining the Service Oriented Architecture (SOA) with the fog computing
architecture is still an open challenge. In this paper, we propose to decompose
services to create linked-microservices (LMS). Linked-microservices are
services that run on multiple nodes but closely linked to their
linked-partners. Linked-microservices allow distributing the computation across
different computing nodes in the IoT architecture. Using four different types
of architectures namely cloud, fog, hybrid and fog+cloud, we explore and
demonstrate the effectiveness of service decomposition by applying four
experiments to three different type of datasets. Evaluation of the four
architectures shows that decomposing services into nodes reduce the data
consumption over the network by 10% - 70%. Overall, these results indicate that
the importance of decomposing services in the context of fog computing for
enhancing the quality of service.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Alturki_B/0/1/0/all/0/1&quot;&gt;Badraddin Alturki&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Reiff_Marganiec_S/0/1/0/all/0/1&quot;&gt;Stephan Reiff-Marganiec&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Perera_C/0/1/0/all/0/1&quot;&gt;Charith Perera&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+De_S/0/1/0/all/0/1&quot;&gt;Suparna De&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00386">
<title>PyramidBox++: High Performance Detector for Finding Tiny Face. (arXiv:1904.00386v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1904.00386</link>
<description rdf:parseType="Literal">&lt;p&gt;With the rapid development of deep convolutional neural network, face
detection has made great progress in recent years. WIDER FACE dataset, as a
main benchmark, contributes greatly to this area. A large amount of methods
have been put forward where PyramidBox designs an effective data augmentation
strategy (Data-anchor-sampling) and context-based module for face detector. In
this report, we improve each part to further boost the performance, including
Balanced-data-anchor-sampling, Dual-PyramidAnchors and Dense Context Module.
Specifically, Balanced-data-anchor-sampling obtains more uniform sampling of
faces with different sizes. Dual-PyramidAnchors facilitate feature learning by
introducing progressive anchor loss. Dense Context Module with dense connection
not only enlarges receptive filed, but also passes information efficiently.
Integrating these techniques, PyramidBox++ is constructed and achieves
state-of-the-art performance in hard set.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1&quot;&gt;Zhihang Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tang_X/0/1/0/all/0/1&quot;&gt;Xu Tang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Han_J/0/1/0/all/0/1&quot;&gt;Junyu Han&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1&quot;&gt;Jingtuo Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+He_R/0/1/0/all/0/1&quot;&gt;Ran He&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00388">
<title>Multi-vision Attention Networks for On-line Red Jujube Grading. (arXiv:1904.00388v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1904.00388</link>
<description rdf:parseType="Literal">&lt;p&gt;To solve the red jujube classification problem, this paper designs a
convolutional neural network model with low computational cost and high
classification accuracy. The architecture of the model is inspired by the
multi-visual mechanism of the organism and DenseNet. To further improve our
model, we add the attention mechanism of SE-Net. We also construct a dataset
which contains 23,735 red jujube images captured by a jujube grading system.
According to the appearance of the jujube and the characteristics of the
grading system, the dataset is divided into four classes: invalid, rotten,
wizened and normal. The numerical experiments show that the classification
accuracy of our model reaches to 91.89%, which is comparable to DenseNet-121,
InceptionV3, InceptionV4, and Inception-ResNet v2. However, our model has
real-time performance.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_X/0/1/0/all/0/1&quot;&gt;Xiaoye Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ma_L/0/1/0/all/0/1&quot;&gt;Liyan Ma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_G/0/1/0/all/0/1&quot;&gt;Gongyan Li&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00389">
<title>How to Authenticate MQTT Sessions Without Channel- and Broker Security. (arXiv:1904.00389v1 [cs.NI])</title>
<link>http://arxiv.org/abs/1904.00389</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper describes a new but state-of-the-art approach to provide
authenticity in mqtt sessions using the means of zero-knowledge-proofs. This
approach completely voids session hijacking for the mqtt protocol and provides
authenticity without the need for any network-security nor channel-security nor
broker-based predefined ACLs. The presented approach does not require the
broker to keep any secrets for session handling, what so ever. Moreover, it
allows the clientID, which represents the identification for a session, to be
publicly known. The presented approach allows completely anonymous but
authentic sessions, hence the broker does not need any a priori knowledge of
the client-party. As it is especially targeted for applications within the
world of IoT, the presented approach is tuned to require only the minimum in
extra power in terms of energy and space. The approach does not introduce any
new concept, but simply fusions a state-of-the-art cryptographic zero knowledge
proof of identity with the existing MQTT-5 specification. Thus no protocol
extension is required in order to provide the targeted security properties. The
described approach is completely agnostic to the application layer at the
client side and is only required during mqtt-session establishment.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Koenig_R/0/1/0/all/0/1&quot;&gt;Reto E. Koenig&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00392">
<title>Impact of Distributed Processing on Power Consumption for IoT Based Surveillance Applications. (arXiv:1904.00392v1 [cs.NI])</title>
<link>http://arxiv.org/abs/1904.00392</link>
<description rdf:parseType="Literal">&lt;p&gt;With the rapid proliferation of connected devices in the Internet of Things
(IoT), the centralized cloud solution faces several challenges, out of which,
there is an overwhelming consensus to put energy efficiency at the top of the
research agenda. In this paper, we evaluate the impact of demand splitting over
heterogeneous processing resources in an IoT platform, supported by Fog and
Cloud infrastructure. We develop a Mixed Integer Linear Programming (MILP)
model to study the gains of splitting resource intensive demands among IoT
nodes, Fog devices and Cloud servers. A surveillance application is considered,
which consists of multiple smart cameras capable of capturing and analyzing
real-time video streams. The PON access network aggregates IoT layer demands
for processing in the Fog, or the Cloud which is accessed through the IP/WDM
network. For typical video analysis workloads, the results show that splitting
medium demand sizes among IoT and Fog resources yields a total power
consumption saving of up to 32%, even if they can host only 10% of the total
workload and this can reach 93% for lower number of demands, compared to the
centralized cloud solution. However, the gains in power savings from splitting
decreases as the number of splits increases. Keywords: IoT surveillance, PON,
energy efficiency, fog, distributed processing.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yosuf_B/0/1/0/all/0/1&quot;&gt;Barzan A. Yosuf&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Musa_M/0/1/0/all/0/1&quot;&gt;Mohamed. Musa&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Elgorashi_T/0/1/0/all/0/1&quot;&gt;Taisir Elgorashi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Elmirghani_J/0/1/0/all/0/1&quot;&gt;J. M. H. Elmirghani&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00396">
<title>Proceedings Programming Language Approaches to Concurrency- and Communication-cEntric Software. (arXiv:1904.00396v1 [cs.PL])</title>
<link>http://arxiv.org/abs/1904.00396</link>
<description rdf:parseType="Literal">&lt;p&gt;Modern hardware platforms, from the very small to the very large,
increasingly provide parallel and distributed computing resources for
applications to maximise performance. Many applications therefore need to make
effective use of tens, hundreds, and even thousands of compute nodes.
Computation in such systems is thus inherently concurrent and communication
centric. Effectively programming such applications is challenging; performance,
correctness, and scalability are difficult to achieve.
&lt;/p&gt;
&lt;p&gt;The development of effective programming methodologies for this increasingly
parallel landscape therefore demands exploration and understanding of a wide
variety of foundational and practical ideas. The International Workshop on
Programming Language Approaches to Concurrency- and Communication-cEntric
Software (PLACES) is dedicated to work in this area. The workshop offers a
forum for researchers from different fields to exchange new ideas about these
challenges to modern and future programming, where concurrency and distribution
are the norm rather than a marginal concern.
&lt;/p&gt;
&lt;p&gt;This proceedings covers the 11th edition of PLACES, which was co-located with
ETAPS 2019 in Prague, Czech Republic.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Martins_F/0/1/0/all/0/1&quot;&gt;Francisco Martins&lt;/a&gt; (University of the Azores), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Orchard_D/0/1/0/all/0/1&quot;&gt;Dominic Orchard&lt;/a&gt; (University of Kent)</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00402">
<title>Pebble Exchange Group of Graphs. (arXiv:1904.00402v1 [cs.DM])</title>
<link>http://arxiv.org/abs/1904.00402</link>
<description rdf:parseType="Literal">&lt;p&gt;A graph puzzle ${\rm Puz}(G)$ of a graph $G$ is defined as follows. A
configuration of ${\rm Puz}(G)$ is a bijection from the set of vertices of a
board graph $G$ to the set of vertices of a pebble graph $G$. A move of pebbles
is defined as exchanging two pebbles which are adjacent on both a board graph
and a pebble graph. For a pair of configurations $f$ and $g$, we say that $f$
is equivalent to $g$ if $f$ can be transformed into $g$ by a sequence of finite
moves.
&lt;/p&gt;
&lt;p&gt;Let ${\rm Aut}(G)$ be the automorphism group of $G$, and let ${\rm 1}_G$ be
the unit element of ${\rm Aut}(G)$. The pebble exchange group of $G$, denoted
by ${\rm Peb}(G)$, is defined as the set of all automorphisms $f$ of $G$ such
that ${\rm 1}_G$ and $f$ are equivalent to each other.
&lt;/p&gt;
&lt;p&gt;In this paper, some basic properties of ${\rm Peb}(G)$ are studied. Among
other results, it is shown that for any connected graph $G$, all automorphisms
of $G$ are contained in ${\rm Peb}(G^2)$, where $G^2$ is a square graph of $G$.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kato_T/0/1/0/all/0/1&quot;&gt;Tatsuoki Kato&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nakamigawa_T/0/1/0/all/0/1&quot;&gt;Tomoki Nakamigawa&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sakuma_T/0/1/0/all/0/1&quot;&gt;Tadashi Sakuma&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00403">
<title>On the Decomposition of Multivariate Nonstationary Multicomponent Signals. (arXiv:1904.00403v1 [cs.IT])</title>
<link>http://arxiv.org/abs/1904.00403</link>
<description rdf:parseType="Literal">&lt;p&gt;With their ability to handle an increased amount of information, multivariate
and multichannel signals can be used to solve problems normally not solvable
with signals obtained from a single source. One such problem is the
decomposition signals with several components whose domains of support
significantly overlap in both the time and the frequency domain, including the
joint time-frequency domain. Initially, we proposed a solution to this problem
based on the Wigner distribution of multivariate signals, which requires the
attenuation of the cross-terms. In this paper, an advanced solution based on an
eigenvalue analysis of the multivariate signal autocorrelation matrix, followed
by their time-frequency concentration measure minimization, is presented. This
analysis provides less restrictive conditions for the signal decomposition than
in the case of Wigner distribution. The algorithm for the components separation
is based on the concentration measures of the eigenvector time-frequency
representation, that are linear combinations of the overlapping signal
components. With an increased number of sensors/channels, the robustness of the
decomposition process to additive noise is also achieved. The theory is
supported by numerical examples. The required channel dissimilarity is
statistically investigated as well.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Stankovic_L/0/1/0/all/0/1&quot;&gt;Ljubisa Stankovic&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Brajovic_M/0/1/0/all/0/1&quot;&gt;Milos Brajovic&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dakovic_M/0/1/0/all/0/1&quot;&gt;Milos Dakovic&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mandic_D/0/1/0/all/0/1&quot;&gt;Danilo Mandic&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00411">
<title>KloakDB: A Platform for Analyzing Sensitive Data with $K$-anonymous Query Processing. (arXiv:1904.00411v1 [cs.DB])</title>
<link>http://arxiv.org/abs/1904.00411</link>
<description rdf:parseType="Literal">&lt;p&gt;A private data federation enables data owners to pool their information for
querying without disclosing their secret tuples to one another. Here, a client
queries the union of the records of all data owners. The data owners work
together to answer the query using privacy-preserving algorithms that prevent
them from learning unauthorized information about the inputs of their peers.
Only the client, and a federation coordinator, learn the query&apos;s output.
KloakDB is a private data federation that uses trusted hardware to process SQL
queries over the inputs of two or more parties. Currently private data
federations compute their queries fully-obliviously, guaranteeing that no
information is revealed about the sensitive inputs of a data owner to their
peers by observing the query&apos;s instruction traces and memory access patterns.
Oblivious querying almost always exacts multiple orders of magnitude slowdown
in query runtimes compared to plaintext execution, making it impractical for
many applications. KloakDB offers a semi-oblivious computing framework,
$k$-anonymous query processing. We make the query&apos;s observable transcript
$k$-anonymous because it is a popular standard for data release in many domains
including medicine, educational research, and government data. KloakDB&apos;s
queries run such that each data owner may deduce information about no fewer
than $k$ individuals in the data of their peers. In addition, stakeholders set
$k$, creating a novel trade-off between privacy and performance. Our results
show that KloakDB enjoys speedups of up to $117$X using k-anonymous query
processing over full-oblivious evaluation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Suresh_M/0/1/0/all/0/1&quot;&gt;Madhav Suresh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+She_Z/0/1/0/all/0/1&quot;&gt;Zuohao She&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wallace_W/0/1/0/all/0/1&quot;&gt;William Wallace&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lahlou_A/0/1/0/all/0/1&quot;&gt;Adel Lahlou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rogers_J/0/1/0/all/0/1&quot;&gt;Jennie Rogers&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00415">
<title>Self Supervised Occupancy Grid Learning from Sparse Radar for Autonomous Driving. (arXiv:1904.00415v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1904.00415</link>
<description rdf:parseType="Literal">&lt;p&gt;Occupancy grid mapping is an important component of autonomous vehicle
perception. It encapsulates information of the drivable area, road obstacles
and enables safe autonomous driving. To this end, radars are becoming widely
used due to their long range sensing, low cost, and robustness to severe
weather conditions. Despite recent advances in deep learning technology,
occupancy grid mapping from radar data is still mostly done using classical
filtering approaches. In this work, we propose a data driven approach for
learning an inverse sensor model used for occupancy grid mapping from clustered
radar data. This task is very challenging due to data sparsity and noise
characteristics of the radar sensor. The problem is formulated as a semantic
segmentation task and we show how it can be learned in a self-supervised manner
using lidar data for generating ground truth. We show both qualitatively and
quantitatively that our learned occupancy net outperforms classic methods by a
large margin using the recently released NuScenes real-world driving data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sless_L/0/1/0/all/0/1&quot;&gt;Liat Sless&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cohen_G/0/1/0/all/0/1&quot;&gt;Gilad Cohen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shlomo_B/0/1/0/all/0/1&quot;&gt;Bat El Shlomo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Oron_S/0/1/0/all/0/1&quot;&gt;Shaul Oron&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00420">
<title>Single Path One-Shot Neural Architecture Search with Uniform Sampling. (arXiv:1904.00420v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1904.00420</link>
<description rdf:parseType="Literal">&lt;p&gt;One-shot method is a powerful Neural Architecture Search (NAS) framework, but
its training is non-trivial and it is difficult to achieve competitive results
on large scale datasets like ImageNet. In this work, we propose a Single Path
One-Shot model to address its main challenge in the training. Our central idea
is to construct a simplified supernet, Single Path Supernet, which is trained
by an uniform path sampling method. All underlying architectures (and their
weights) get trained fully and equally. Once we have a trained supernet, we
apply an evolutionary algorithm to efficiently search the best-performing
architectures without any fine tuning. Comprehensive experiments verify that
our approach is flexible and effective. It is easy to train and fast to search.
It effortlessly supports complex search spaces (e.g., building blocks, channel,
mixed-precision quantization) and different search constraints (e.g., FLOPs,
latency). It is thus convenient to use for various needs. It achieves
start-of-the-art performance on the large dataset ImageNet.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guo_Z/0/1/0/all/0/1&quot;&gt;Zichao Guo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1&quot;&gt;Xiangyu Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mu_H/0/1/0/all/0/1&quot;&gt;Haoyuan Mu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Heng_W/0/1/0/all/0/1&quot;&gt;Wen Heng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1&quot;&gt;Zechun Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wei_Y/0/1/0/all/0/1&quot;&gt;Yichen Wei&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_J/0/1/0/all/0/1&quot;&gt;Jian Sun&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00421">
<title>Spin-Orbit Torque Devices for Hardware Security: From Deterministic to Probabilistic Regime. (arXiv:1904.00421v1 [cs.ET])</title>
<link>http://arxiv.org/abs/1904.00421</link>
<description rdf:parseType="Literal">&lt;p&gt;Protecting intellectual property (IP) has become a serious challenge for chip
designers. Most countermeasures are tailored for CMOS integration and tend to
incur excessive overheads, resulting from additional circuitry or device-level
modifications. On the other hand, power density is a critical concern for
sub-50 nm nodes, necessitating alternate design concepts. Although initially
tailored for error-tolerant applications, imprecise computing has gained
traction as a general-purpose design technique. Emerging devices are currently
being explored to implement ultra-low-power circuits for inexact computing
applications. In this paper, we quantify the security threats of imprecise
computing using emerging devices. More specifically, we leverage the innate
polymorphism and tunable stochastic behavior of spin-orbit torque (SOT)
devices, particularly, the giant spin-Hall effect (GSHE) switch. We enable IP
protection (by means of logic locking and camouflaging) simultaneously for
deterministic and probabilistic computing, directly at the GSHE device level.
We conduct a comprehensive security analysis using state-of-the-art Boolean
satisfiability (SAT) attacks; this study demonstrates the superior resilience
of our GSHE primitive when tailored for deterministic computing. We also
demonstrate how probabilistic computing can thwart most, if not all, existing
SAT attacks. Based on this finding, we propose an attack scheme called
probabilistic SAT (PSAT) which can bypass the defense offered by logic locking
and camouflaging for imprecise computing schemes. Further, we illustrate how
careful application of our GSHE primitive can remain secure even on the
application of the PSAT attack. Finally, we also discuss side-channel attacks
and invasive monitoring, which are arguably even more concerning threats than
SAT attacks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Patnaik_S/0/1/0/all/0/1&quot;&gt;Satwik Patnaik&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rangarajan_N/0/1/0/all/0/1&quot;&gt;Nikhil Rangarajan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Knechtel_J/0/1/0/all/0/1&quot;&gt;Johann Knechtel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sinanoglu_O/0/1/0/all/0/1&quot;&gt;Ozgur Sinanoglu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rakheja_S/0/1/0/all/0/1&quot;&gt;Shaloo Rakheja&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00424">
<title>An Embodied, Platform-invariant Architecture for Connecting High-level Spatial Commands to Platform Articulation. (arXiv:1904.00424v1 [cs.RO])</title>
<link>http://arxiv.org/abs/1904.00424</link>
<description rdf:parseType="Literal">&lt;p&gt;In contexts such as teleoperation, robot reprogramming,
human-robot-interaction, and neural prosthetics, conveying movement commands to
a robotic platform is often a limiting factor. Currently, many applications
rely on joint-angle-by-joint-angle prescriptions. This inherently requires a
large number of parameters to be specified by the user that scales with the
number of degrees of freedom on a platform, creating high bandwidth
requirements for interfaces. This paper presents an efficient representation of
high-level, spatial commands that specifies many joint angles with relatively
few parameters based on a spatial architecture that is judged favorably by
human viewers. In particular, a general method for labeling connected platform
linkages, generating a databank of user-specified poses, and mapping between
high-level spatial commands and specific platform static configurations are
presented. Thus, this architecture is ``platform-invariant&apos;&apos; where the same
high-level, spatial command can be executed on any platform. This has the
advantage that our commands have meaning for human movers as well. In order to
achieve this, we draw inspiration from Laban/Bartenieff Movement Studies, an
embodied taxonomy for movement description. The architecture is demonstrated
through implementation on 26 spatial directions for a Rethink Robotics Baxter,
an Aldebaran NAO, and a KUKA youBot. User studies are conducted to validate the
claims of the proposed framework.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sher_A/0/1/0/all/0/1&quot;&gt;A. Jang Sher&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huzaifa_U/0/1/0/all/0/1&quot;&gt;U. Huzaifa&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1&quot;&gt;J. Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jain_V/0/1/0/all/0/1&quot;&gt;V. Jain&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zurawski_A/0/1/0/all/0/1&quot;&gt;A. Zurawski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+LaViers_A/0/1/0/all/0/1&quot;&gt;A. LaViers&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00433">
<title>Tensor Decomposition based Adaptive Model Reduction for Power System Simulation. (arXiv:1904.00433v1 [cs.SY])</title>
<link>http://arxiv.org/abs/1904.00433</link>
<description rdf:parseType="Literal">&lt;p&gt;The letter proposes an adaptive model reduction approach based on tensor
decomposition to speed up time-domain power system simulation. Taylor series
expansion of a power system dynamic model is calculated around multiple
equilibria corresponding to different load levels. The terms of Taylor
expansion are converted to the tensor format and reduced into smaller-size
matrices with the help of tensor decomposition. The approach adaptively changes
the complexity of a power system model based on the size of a disturbance to
maintain the compromise between high simulation speed and high accuracy of the
reduced model. The proposed approach is compared with a traditional linear
model reduction approach on the 140-bus 48-machine Northeast Power Coordinating
Council system.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Osipov_D/0/1/0/all/0/1&quot;&gt;Denis Osipov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_K/0/1/0/all/0/1&quot;&gt;Kai Sun&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00435">
<title>Robust Tensor Recovery using Low-Rank Tensor Ring. (arXiv:1904.00435v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1904.00435</link>
<description rdf:parseType="Literal">&lt;p&gt;Robust tensor completion recoveries the low-rank and sparse parts from its
partially observed entries. In this paper, we propose the robust tensor ring
completion (RTRC) model and rigorously analyze its exact recovery guarantee via
TR-unfolding scheme, and the result is consistent with that of matrix case. We
propose the algorithms for tensor ring robust principle component analysis
(TRRPCA) and RTCR using the alternating direction method of multipliers (ADMM).
The numerical experiment demonstrates that the proposed method outperforms the
state-of-the-art ones in terms of recovery accuracy.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_H/0/1/0/all/0/1&quot;&gt;Huyan Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1&quot;&gt;Yipeng Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_C/0/1/0/all/0/1&quot;&gt;Ce Zhu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00438">
<title>Understanding Neural Architecture Search Techniques. (arXiv:1904.00438v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1904.00438</link>
<description rdf:parseType="Literal">&lt;p&gt;Automatic methods for generating state-of-the-art neural network
architectures without human experts have generated significant attention
recently. This is because of the potential to remove human experts from the
design loop which can reduce costs and decrease time to model deployment.
Neural architecture search (NAS) techniques have improved significantly in
their computational efficiency since the original NAS was proposed. This
reduction in computation is enabled via weight sharing such as in Efficient
Neural Architecture Search (ENAS). However, recently a body of work confirms
our discovery that ENAS does not do significantly better than random search
with weight sharing, contradicting the initial claims of the authors.
&lt;/p&gt;
&lt;p&gt;We provide an explanation for this phenomenon by investigating the
interpretability of the ENAS controller&apos;s hidden state. We are interested in
seeing if the controller embeddings are predictive of any properties of the
final architecture - for example, graph properties like the number of
connections, or validation performance. We find models sampled from identical
controller hidden states have no correlation in various graph similarity
metrics. This failure mode implies the RNN controller does not condition on
past architecture choices. Importantly, we may need to condition on past
choices if certain connection patterns prevent vanishing or exploding
gradients.
&lt;/p&gt;
&lt;p&gt;Lastly, we propose a solution to this failure mode by forcing the
controller&apos;s hidden state to encode pasts decisions by training it with a
memory buffer of previously sampled architectures. Doing this improves hidden
state interpretability by increasing the correlation controller hidden states
and graph similarity metrics.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Adam_G/0/1/0/all/0/1&quot;&gt;George Adam&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lorraine_J/0/1/0/all/0/1&quot;&gt;Jonathan Lorraine&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00441">
<title>Cooperative Multi-Agent Reinforcement Learning Framework for Scalping Trading. (arXiv:1904.00441v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1904.00441</link>
<description rdf:parseType="Literal">&lt;p&gt;We explore deep Reinforcement Learning(RL) algorithms for scalping trading
and knew that there is no appropriate trading gym and agent examples. Thus we
propose gym and agent like Open AI gym in finance. Not only that, we introduce
new RL framework based on our hybrid algorithm which leverages between
supervised learning and RL algorithm and uses meaningful observations such
order book and settlement data from experience watching scalpers trading. That
is very crucial information for traders behavior to be decided. To feed these
data into our model, we use spatio-temporal convolution layer, called Conv3D
for order book data and temporal CNN, called Conv1D for settlement data. Those
are preprocessed by episode filter we developed. Agent consists of four sub
agents divided to clarify their own goal to make best decision. Also, we
adopted value and policy based algorithm to our framework. With these features,
we could make agent mimic scalpers as much as possible. In many fields, RL
algorithm has already begun to transcend human capabilities in many domains.
This approach could be a starting point to beat human in the financial stock
market, too and be a good reference for anyone who wants to design RL algorithm
in real world domain. Finally, weexperiment our framework and gave you
experiment progress.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jo_U/0/1/0/all/0/1&quot;&gt;Uk Jo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jo_T/0/1/0/all/0/1&quot;&gt;Taehyun Jo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_W/0/1/0/all/0/1&quot;&gt;Wanjun Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yoon_I/0/1/0/all/0/1&quot;&gt;Iljoo Yoon&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_D/0/1/0/all/0/1&quot;&gt;Dongseok Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1&quot;&gt;Seungho Lee&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00442">
<title>SpaMHMM: Sparse Mixture of Hidden Markov Models for Graph Connected Entities. (arXiv:1904.00442v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1904.00442</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a framework to model the distribution of sequential data coming
from a set of entities connected in a graph with a known topology. The method
is based on a mixture of shared hidden Markov models (HMMs), which are jointly
trained in order to exploit the knowledge of the graph structure and in such a
way that the obtained mixtures tend to be sparse. Experiments in different
application domains demonstrate the effectiveness and versatility of the
method.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pernes_D/0/1/0/all/0/1&quot;&gt;Diogo Pernes&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cardoso_J/0/1/0/all/0/1&quot;&gt;Jaime S. Cardoso&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00445">
<title>The KiTS19 Challenge Data: 300 Kidney Tumor Cases with Clinical Context, CT Semantic Segmentations, and Surgical Outcomes. (arXiv:1904.00445v1 [q-bio.QM])</title>
<link>http://arxiv.org/abs/1904.00445</link>
<description rdf:parseType="Literal">&lt;p&gt;The morphometry of a kidney tumor revealed by contrast-enhanced Computed
Tomography (CT) imaging is an important factor in clinical decision making
surrounding the lesion&apos;s diagnosis and treatment. Quantitative study of the
relationship between kidney tumor morphology and clinical outcomes is difficult
due to data scarcity and the laborious nature of manually quantifying imaging
predictors. Automatic semantic segmentation of kidneys and kidney tumors is a
promising tool towards automatically quantifying a wide array of morphometric
features, but no sizeable annotated dataset is currently available to train
models for this task. We present the KiTS19 challenge dataset: A collection of
multi-phase CT imaging, segmentation masks, and comprehensive clinical outcomes
for 300 patients who underwent nephrectomy for kidney tumors at our center
between 2010 and 2018. 210 (70%) of these patients were selected at random as
the training set for the 2019 MICCAI KiTS Kidney Tumor Segmentation Challenge
and have been released publicly. With the presence of clinical context and
surgical outcomes, this data can serve not only for benchmarking semantic
segmentation models, but also for developing and studying biomarkers which make
use of the imaging and semantic segmentation masks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Heller_N/0/1/0/all/0/1&quot;&gt;Nicholas Heller&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Sathianathen_N/0/1/0/all/0/1&quot;&gt;Niranjan Sathianathen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Kalapara_A/0/1/0/all/0/1&quot;&gt;Arveen Kalapara&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Walczak_E/0/1/0/all/0/1&quot;&gt;Edward Walczak&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Moore_K/0/1/0/all/0/1&quot;&gt;Keenan Moore&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Kaluzniak_H/0/1/0/all/0/1&quot;&gt;Heather Kaluzniak&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Rosenberg_J/0/1/0/all/0/1&quot;&gt;Joel Rosenberg&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Blake_P/0/1/0/all/0/1&quot;&gt;Paul Blake&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Rengel_Z/0/1/0/all/0/1&quot;&gt;Zachary Rengel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Oestreich_M/0/1/0/all/0/1&quot;&gt;Makinna Oestreich&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Dean_J/0/1/0/all/0/1&quot;&gt;Joshua Dean&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Tradewell_M/0/1/0/all/0/1&quot;&gt;Michael Tradewell&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Shah_A/0/1/0/all/0/1&quot;&gt;Aneri Shah&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Tejpaul_R/0/1/0/all/0/1&quot;&gt;Resha Tejpaul&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Edgerton_Z/0/1/0/all/0/1&quot;&gt;Zachary Edgerton&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Peterson_M/0/1/0/all/0/1&quot;&gt;Matthew Peterson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Raza_S/0/1/0/all/0/1&quot;&gt;Shaneabbas Raza&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Regmi_S/0/1/0/all/0/1&quot;&gt;Subodh Regmi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Papanikolopoulos_N/0/1/0/all/0/1&quot;&gt;Nikolaos Papanikolopoulos&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Weight_C/0/1/0/all/0/1&quot;&gt;Christopher Weight&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00447">
<title>The Power of d Choices in Scheduling for Data Centers with Heterogeneous Servers. (arXiv:1904.00447v1 [cs.PF])</title>
<link>http://arxiv.org/abs/1904.00447</link>
<description rdf:parseType="Literal">&lt;p&gt;MapReduce framework is the de facto in big data and its applications where a
big data-set is split into small data chunks that are replicated on different
servers among thousands of servers. The heterogeneous server structure of the
system makes the scheduling much harder than scheduling for systems with
homogeneous servers. Throughput optimality of the system on one hand and delay
optimality on the other hand creates a dilemma for assigning tasks to servers.
The JSQ-MaxWeight and Balanced-Pandas algorithms are the states of the arts
algorithms with theoretical guarantees on throughput and delay optimality for
systems with two and three levels of data locality. However, the scheduling
complexity of these two algorithms are way too much. Hence, we use the power of
$d$ choices algorithm combined with the Balanced-Pandas algorithm and the
JSQ-MaxWeight algorithm, and compare the complexity of the simple algorithms
and the power of $d$ choices versions of them. We will further show that the
Balanced-Pandas algorithm combined with the power of the $d$ choices,
Balanced-Pandas-Pod, not only performs better than simple Balanced-Pandas, but
also is less sensitive to the parameter $d$ than the combination of the
JSQ-MaxWeight algorithm and the power of the $d$ choices, JSQ-MaxWeight-Pod. In
fact in our extensive simulation results, the Balanced-Pandas-Pod algorithm is
performing better than the simple Balanced-Pandas algorithm in low and medium
loads, where data centers are usually performing at, and performs almost the
same as the Balanced-Pandas algorithm at high loads. Note that the load
balancing complexity of Balanced-Pandas and JSQ-MaxWeight algorithms are
$O(M)$, where $M$ is the number of servers in the system which is in the order
of thousands servers, whereas the complexity of Balanced-Pandas-Pod and
JSQ-MaxWeight-Pod are $O(1)$, that makes the central scheduler faster and saves
energy.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Moaddeli_A/0/1/0/all/0/1&quot;&gt;Amir Moaddeli&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ahmadi_I/0/1/0/all/0/1&quot;&gt;Iman Nabati Ahmadi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Abhar_N/0/1/0/all/0/1&quot;&gt;Negin Abhar&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00450">
<title>On the Computation of Strategically Equivalent Rank-0 Games. (arXiv:1904.00450v1 [cs.GT])</title>
<link>http://arxiv.org/abs/1904.00450</link>
<description rdf:parseType="Literal">&lt;p&gt;It has been well established that in a bimatrix game, the rank of the matrix
formed by summing the payoff (or cost) matrices of the players has an impact on
the runtime of the algorithms that converge to a Nash equilibrium of the game.
In this paper, we devise a fast linear time algorithm that exploits strategic
equivalence between bimatrix games to identify whether or not a given bimatrix
game is strategically equivalent to a zero-sum game, and if it is, then we
present an algorithm that computes a strategically equivalent zero-sum game.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Heyman_J/0/1/0/all/0/1&quot;&gt;Joseph L. Heyman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gupta_A/0/1/0/all/0/1&quot;&gt;Abhishek Gupta&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00453">
<title>Performance Analysis of Large Intelligent Surfaces (LISs): Uplink Spectral Efficiency and Pilot Training. (arXiv:1904.00453v1 [cs.IT])</title>
<link>http://arxiv.org/abs/1904.00453</link>
<description rdf:parseType="Literal">&lt;p&gt;Large intelligent surfaces (LISs) constitute a new and promising wireless
communication paradigm that relies on the integration of a massive number of
antenna elements over the entire surfaces of man-made structures. The LIS
concept provides many advantages, such as the capability to provide reliable
and space-intensive communications by effectively establishing line-of-sight
(LOS) channels. In this paper, the system spectral efficiency (SSE) of an
uplink LIS system is asymptotically analyzed under a practical LIS environment
with a well-defined uplink frame structure. In order to verify the impact on
the SSE of pilot contamination, the SSE of a multi-LIS system is asymptotically
studied and a theoretical bound on its performance is derived. Given this
performance bound, an optimal pilot training length for multi-LIS systems
subjected to pilot contamination is characterized and, subsequently, the
performance-maximizing number of devices that the LIS system must service is
derived. Simulation results show that the derived analyses are in close
agreement with the exact mutual information in presence of a large number of
antennas, and the achievable SSE is limited by the effect of pilot
contamination and intra/inter-LIS interference through the LOS path, even if
the LIS is equipped with an infinite number of antennas. Additionally, the SSE
obtained with the proposed pilot training length and number of scheduled
devices is shown to reach the one obtained via a brute-force search for the
optimal solution.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jung_M/0/1/0/all/0/1&quot;&gt;Minchae Jung&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Saad_W/0/1/0/all/0/1&quot;&gt;Walid Saad&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kong_G/0/1/0/all/0/1&quot;&gt;Gyuyeol Kong&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00457">
<title>Rank Reduction in Bimatrix Games. (arXiv:1904.00457v1 [cs.GT])</title>
<link>http://arxiv.org/abs/1904.00457</link>
<description rdf:parseType="Literal">&lt;p&gt;The rank of a bimatrix game is defined as the rank of the sum of the payoff
matrices of the two players. Under certain conditions on the payoff matrices,
we devise a method that reduces the rank of the game without changing the
equilibrium of the game. We leverage matrix pencil theory and Wedderburn rank
reduction formula to arrive at our results. We also present a constructive
proof of the fact that in a generic square game, the rank of the game can be
reduced by 1, and in generic rectangular game, the rank of the game can be
reduced by 2 under certain assumptions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Heyman_J/0/1/0/all/0/1&quot;&gt;Joseph L. Heyman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gupta_A/0/1/0/all/0/1&quot;&gt;Abhishek Gupta&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00459">
<title>Differentially Private Inference for Binomial Data. (arXiv:1904.00459v1 [math.ST])</title>
<link>http://arxiv.org/abs/1904.00459</link>
<description rdf:parseType="Literal">&lt;p&gt;We derive uniformly most powerful (UMP) tests for simple and one-sided
hypotheses for a population proportion within the framework of Differential
Privacy (DP), optimizing finite sample performance. We show that in general, DP
hypothesis tests can be written in terms of linear constraints, and for
exchangeable data can always be expressed as a function of the empirical
distribution. Using this structure, we prove a &apos;Neyman-Pearson lemma&apos; for
binomial data under DP, where the DP-UMP only depends on the sample sum. Our
tests can also be stated as a post-processing of a random variable, whose
distribution we coin &apos;&apos;Truncated-Uniform-Laplace&apos;&apos; (Tulap), a generalization of
the Staircase and discrete Laplace distributions. Furthermore, we obtain exact
$p$-values, which are easily computed in terms of the Tulap random variable.
&lt;/p&gt;
&lt;p&gt;Using the above techniques, we show that our tests can be applied to give
uniformly most accurate one-sided confidence intervals and optimal confidence
distributions. We also derive uniformly most powerful unbiased (UMPU) two-sided
tests, which lead to uniformly most accurate unbiased (UMAU) two-sided
confidence intervals. We show that our results can be applied to
distribution-free hypothesis tests for continuous data. Our simulation results
demonstrate that all our tests have exact type I error, and are more powerful
than current techniques.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Awan_J/0/1/0/all/0/1&quot;&gt;Jordan Awan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Slavkovic_A/0/1/0/all/0/1&quot;&gt;Aleksandra Slavkovic&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00460">
<title>Spectral density of equitable core-periphery graphs. (arXiv:1904.00460v1 [cs.SI])</title>
<link>http://arxiv.org/abs/1904.00460</link>
<description rdf:parseType="Literal">&lt;p&gt;Core-periphery structures is an emerging property of a wide range of complex
systems and indicate the presence of group of actors in the system with an
higher number of connections among them and a lower number of connections with
a sparsely connected periphery. The dynamics of a complex system which is
interacting on a given graph structure is strictly connected with the spectral
properties of the graph itself, nevertheless it is generally extremely hard to
obtain analytic results which will hold for arbitrary large systems. Recently a
statistical ensemble of random graphs with a regular block structure, i.e. the
ensemble of equitable graphs, has been introduced and analytic results have
been derived in the computationally-hard context of graph partitioning and
community detection. In this paper, we present a general analytic result for a
ensemble of equitable core-periphery graphs, yielding a new explicit formula
for the spectral density of networks with core-periphery structure.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Barucca_P/0/1/0/all/0/1&quot;&gt;Paolo Barucca&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00462">
<title>Video Game Development in a Rush: A Survey of the Global Game Jam Participants. (arXiv:1904.00462v1 [cs.SE])</title>
<link>http://arxiv.org/abs/1904.00462</link>
<description rdf:parseType="Literal">&lt;p&gt;Video game development is a complex endeavor, often involving complex
software, large organizations, and aggressive release deadlines. Several
studies have reported that periods of &quot;crunch time&quot; are prevalent in the video
game industry, but there are few studies on the effects of time pressure. We
conducted a survey with participants of the Global Game Jam (GGJ), a 48-hour
hackathon. Based on 198 responses, the results suggest that: (1) iterative
brainstorming is the most popular method for conceptualizing initial
requirements; (2) continuous integration, minimum viable product, scope
management, version control, and stand-up meetings are frequently applied
development practices; (3) regular communication, internal playtesting, and
dynamic and proactive planning are the most common quality assurance
activities; and (4) familiarity with agile development has a weak correlation
with perception of success in GGJ. We conclude that GGJ teams rely on ad hoc
approaches to development and face-to-face communication, and recommend some
complementary practices with limited overhead. Furthermore, as our findings are
similar to recommendations for software startups, we posit that game jams and
the startup scene share contextual similarities. Finally, we discuss the
drawbacks of systemic &quot;crunch time&quot; and argue that game jam organizers are in a
good position to problematize the phenomenon.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Borg_M/0/1/0/all/0/1&quot;&gt;Markus Borg&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Garousi_V/0/1/0/all/0/1&quot;&gt;Vahid Garousi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mahmoud_A/0/1/0/all/0/1&quot;&gt;Anas Mahmoud&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Olsson_T/0/1/0/all/0/1&quot;&gt;Thomas Olsson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Staalberg_O/0/1/0/all/0/1&quot;&gt;Oskar St&amp;#xe5;lberg&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00463">
<title>Energy Storage in Madeira, Portugal: Co-optimizing for Arbitrage, Self-Sufficiency, Peak Shaving and Energy Backup. (arXiv:1904.00463v1 [cs.SY])</title>
<link>http://arxiv.org/abs/1904.00463</link>
<description rdf:parseType="Literal">&lt;p&gt;Energy storage applications are explored from a prosumer (consumers with
generation) perspective for the island of Madeira in Portugal. These
applications could also be relevant to other power networks. We formulate a
convex co-optimization problem for performing arbitrage under zero feed-in
tariff, increasing self-sufficiency by increasing self-consumption of locally
generated renewable energy, provide peak shaving and act as a backup power
source during anticipated and scheduled power outages. Using real data from
Madeira we perform short and long time-scale simulations in order to select
end-user contract which maximizes their gains considering storage degradation
based on operational cycles. We observe energy storage ramping capability
decides peak shaving potential, fast ramping batteries can significantly reduce
peak demand charge. The numerical experiment indicates that storage providing
backup does not significantly reduce gains performing arbitrage and peak demand
shaving. Furthermore, we also use AutoRegressive Moving Average (ARMA)
forecasting along with Model Predictive Control (MPC) for real-time
implementation of the proposed optimization problem in the presence of
uncertainty.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hashmi_M/0/1/0/all/0/1&quot;&gt;Md Umar Hashmi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pereira_L/0/1/0/all/0/1&quot;&gt;Lucas Pereira&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Busic_A/0/1/0/all/0/1&quot;&gt;Ana Bu&amp;#x161;i&amp;#x107;&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00464">
<title>Operating ITS-G5 DSRC over Unlicensed Bands: A City-Scale Performance Evaluation. (arXiv:1904.00464v1 [cs.NI])</title>
<link>http://arxiv.org/abs/1904.00464</link>
<description rdf:parseType="Literal">&lt;p&gt;Future Connected and Autonomous Vehicles (CAVs) will be equipped with a large
set of sensors. The large amount of generated sensor data is expected to be
exchanged with other CAVs and the road-side infrastructure. Both in Europe and
the US, Dedicated Short Range Communications (DSRC) systems, based on the IEEE
802.11p Physical Layer, are key enabler for the communication among vehicles.
Given the expected market penetration of connected vehicles, the licensed band
of $\mathrm{75 MHz}$, dedicated to DSRC communications, is expected to become
increasingly congested. In this paper, we investigate the performance of a
vehicular communication system, operated over the unlicensed bands $\mathrm{2.4
GHz}$-$\mathrm{2.5 GHz}$ and $\mathrm{5.725 GHz}$-$\mathrm{5.875 GHz}$. Our
experimental evaluation was carried out in a testing track in the centre of
Bristol, UK and our system is a full-stack ETSI ITS-G5 implementation. Our
performance investigation compares key communication metrics (e.g., packet
delivery rate, received signal strength indicator) measured by operating our
system over the licensed DSRC and the considered unlicensed bands. In
particular, when operated over the $\mathrm{2.4 GHz}$-$\mathrm{2.5 GHz}$ band,
our system achieves comparable performance to the case when the DSRC band is
used. On the other hand, as soon as the system, is operated over the
$\mathrm{5.725 GHz}$-$\mathrm{5.875 GHz}$ band, the packet delivery rate is
$30\%$ smaller compared to the case when the DSRC band is employed. These
findings prove that operating our system over unlicensed ISM bands is a viable
option. During our experimental evaluation, we recorded all the generated
network interactions and the complete data set has been publicly available.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mavromatis_I/0/1/0/all/0/1&quot;&gt;Ioannis Mavromatis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tassi_A/0/1/0/all/0/1&quot;&gt;Andrea Tassi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Piechocki_R/0/1/0/all/0/1&quot;&gt;Robert J. Piechocki&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00469">
<title>Perturbative estimation of stochastic gradients. (arXiv:1904.00469v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1904.00469</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper we introduce a family of stochastic gradient estimation
techniques based of the perturbative expansion around the mean of the sampling
distribution. We characterize the bias and variance of the resulting
Taylor-corrected estimators using the Lagrange error formula. Furthermore, we
introduce a family of variance reduction techniques that can be applied to
other gradient estimators. Finally, we show that these new perturbative methods
can be extended to discrete functions using analytic continuation. Using this
technique, we derive a new gradient descent method for training stochastic
networks with binary weights. In our experiments, we show that the perturbative
correction improves the convergence of stochastic variational inference both in
the continuous and in the discrete case.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ambrogioni_L/0/1/0/all/0/1&quot;&gt;Luca Ambrogioni&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Gerven_M/0/1/0/all/0/1&quot;&gt;Marcel A. J. van Gerven&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00472">
<title>Positive Personas: Integrating Well-being Determinants into Personas. (arXiv:1904.00472v1 [cs.HC])</title>
<link>http://arxiv.org/abs/1904.00472</link>
<description rdf:parseType="Literal">&lt;p&gt;System design for well-being needs an appropriate tool to help designers to
determine relevant requirements that can help human well-being to flourish.
Personas come as a simple yet powerful tool in the early development stage of
the user interface design. Considering well-being determinants in the early
design process provide benefits for both the user and the development team.
Therefore, in this short paper, we performed a literature study to provide a
conceptual model of well-being in personas and propose positive design
interventions in the personas creation process.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nurhas_I/0/1/0/all/0/1&quot;&gt;Irawan Nurhas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Geisler_S/0/1/0/all/0/1&quot;&gt;Stefan Geisler&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pawlowski_J/0/1/0/all/0/1&quot;&gt;Jan Pawlowski&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00478">
<title>Exploring the Generality of a Java-based Loop Action Model for the Quorum Programming Language. (arXiv:1904.00478v1 [cs.SE])</title>
<link>http://arxiv.org/abs/1904.00478</link>
<description rdf:parseType="Literal">&lt;p&gt;Many algorithmic steps require more than one statement to implement, but not
big enough to be a method (e.g., add element, find the maximum, determine a
value, etc.). These steps are generally implemented by loops. Internal comments
for the loops often describe these intermediary steps, however, unfortunately a
very small percentage of code is well documented to help new users/coders. As a
result, information at levels of abstraction between the individual statement
and the whole method is not leveraged by current source code analyses, as that
information is not easily available beyond any internal comments describing the
code blocks.
&lt;/p&gt;
&lt;p&gt;Hence, this project explores the generality of an approach to automatically
determine the high level actions of loop constructs. The approach is to mine
loop characteristics of a given loop structure over the repository of the
Quorum language source code, map it to an (already developed for Java) action
identification model, and thus identify the action performed by the specified
loop. The results are promising enough to conclude that this approach could be
applied to other programming languages too.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chatterjee_P/0/1/0/all/0/1&quot;&gt;Preetha Chatterjee&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00479">
<title>Sparse Tensor Additive Regression. (arXiv:1904.00479v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1904.00479</link>
<description rdf:parseType="Literal">&lt;p&gt;Tensors are becoming prevalent in modern applications such as medical imaging
and digital marketing. In this paper, we propose a sparse tensor additive
regression (STAR) that models a scalar response as a flexible nonparametric
function of tensor covariates. The proposed model effectively exploits the
sparse and low-rank structures in the tensor additive regression. We formulate
the parameter estimation as a non-convex optimization problem, and propose an
efficient penalized alternating minimization algorithm. We establish a
non-asymptotic error bound for the estimator obtained from each iteration of
the proposed algorithm, which reveals an interplay between the optimization
error and the statistical rate of convergence. We demonstrate the efficacy of
STAR through extensive comparative simulation studies, and an application to
the click-through-rate prediction in online advertising.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Hao_B/0/1/0/all/0/1&quot;&gt;Botao Hao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wang_B/0/1/0/all/0/1&quot;&gt;Boxiang Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wang_P/0/1/0/all/0/1&quot;&gt;Pengyuan Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zhang_J/0/1/0/all/0/1&quot;&gt;Jingfei Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Yang_J/0/1/0/all/0/1&quot;&gt;Jian Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Sun_W/0/1/0/all/0/1&quot;&gt;Will Wei Sun&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00484">
<title>Synchronization of nonlinearly coupled networks of Chua oscillators. (arXiv:1904.00484v1 [cs.SY])</title>
<link>http://arxiv.org/abs/1904.00484</link>
<description rdf:parseType="Literal">&lt;p&gt;The paper develops new sufficient conditions for synchronization of a network
of $N$ nonlinearly coupled Chua oscillators interconnected via the first state
coordinate only. The nonlinear coupling strength is governed by a function
residing within a sector, i.e. it is bounded from above and below by linear
functions. The derived sufficient conditions provide a trade-off between the
characteristics of the sector and the interconnection topology of the network
to guarantee the synchronization of the oscillators.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Feketa_P/0/1/0/all/0/1&quot;&gt;Petro Feketa&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schaum_A/0/1/0/all/0/1&quot;&gt;Alexander Schaum&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Meurer_T/0/1/0/all/0/1&quot;&gt;Thomas Meurer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Michaelis_D/0/1/0/all/0/1&quot;&gt;Denis Michaelis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ochs_K/0/1/0/all/0/1&quot;&gt;Karl-Heinz Ochs&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00503">
<title>Recharging of Flying Base Stations using Airborne RF Energy Sources. (arXiv:1904.00503v1 [cs.NI])</title>
<link>http://arxiv.org/abs/1904.00503</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper presents a new method for recharging flying base stations, carried
by Unmanned Aerial Vehicles (UAVs), using wireless power transfer from
dedicated, airborne, Radio Frequency (RF) energy sources. In particular, we
study a system in which UAVs receive wireless power without being disrupted
from their regular trajectory. The optimal placement of the energy sources are
studied so as to maximize received power from the energy sources by the
receiver UAVs flying with a linear trajectory over a square area. We find that
for our studied scenario of two UAVs, if an even number of energy sources are
used, placing them in the optimal locations maximizes the total received power,
while achieving fairness among the UAVs. However, in the case of using an odd
number of energy sources, we can either maximize the total received power, or
achieve fairness, but not both at the same time. Numerical results show that
placing the energy sources at the suggested optimal locations results in
significant power gain compared to nonoptimal placements.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hassan_J/0/1/0/all/0/1&quot;&gt;Jahan Hassan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bokani_A/0/1/0/all/0/1&quot;&gt;Ayub Bokani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kanhere_S/0/1/0/all/0/1&quot;&gt;Salil S. Kanhere&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00507">
<title>Semisupervised Clustering by Queries and Locally Encodable Source Coding. (arXiv:1904.00507v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1904.00507</link>
<description rdf:parseType="Literal">&lt;p&gt;Source coding is the canonical problem of data compression in information
theory. In a {\em locally encodable} source coding, each compressed bit depends
on only few bits of the input. In this paper, we show that a recently popular
model of semisupervised clustering is equivalent to locally encodable source
coding. In this model, the task is to perform multiclass labeling of unlabeled
elements. At the beginning, we can ask in parallel a set of simple queries to
an oracle who provides (possibly erroneous) binary answers to the queries. The
queries cannot involve more than two (or a fixed constant number $\Delta$ of)
elements. Now the labeling of all the elements (or clustering) must be
performed based on the (noisy) query answers. The goal is to recover all the
correct labelings while minimizing the number of such queries. The equivalence
to locally encodable source codes leads us to find lower bounds on the number
of queries required in variety of scenarios. We are also able to show
fundamental limitations of pairwise `same cluster&apos; queries - and propose
pairwise AND queries, that provably performs better in many situations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Mazumdar_A/0/1/0/all/0/1&quot;&gt;Arya Mazumdar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Pal_S/0/1/0/all/0/1&quot;&gt;Soumyabrata Pal&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00510">
<title>How to enhance learning of robotic surgery gestures? A tactile cue saliency investigation for 3D hand guidance. (arXiv:1904.00510v1 [cs.RO])</title>
<link>http://arxiv.org/abs/1904.00510</link>
<description rdf:parseType="Literal">&lt;p&gt;The current generation of surgeons requires extensive training in
teleoperation to develop specific dexterous skills, which are independent of
medical knowledge. Training curricula progress from manipulation tasks to
simulated surgical tasks but are limited in time. To tackle this, we propose to
integrate surgical robotic training together with Haptic Feedback (HF) to
improve skill acquisition. This paper present the initial but promising results
of our haptic device designed to support in the training of surgical gestures.
Our ongoing work is related to integrate the HF in the RAVEN II platform.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gil_G/0/1/0/all/0/1&quot;&gt;Gustavo D. Gil&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Walker_J/0/1/0/all/0/1&quot;&gt;Julie M. Walker&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zemiti_N/0/1/0/all/0/1&quot;&gt;Nabil Zemiti&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Okamura_A/0/1/0/all/0/1&quot;&gt;Allison M. Okamura&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Poignet_P/0/1/0/all/0/1&quot;&gt;Philippe Poignet&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00511">
<title>Risk Averse Robust Adversarial Reinforcement Learning. (arXiv:1904.00511v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1904.00511</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep reinforcement learning has recently made significant progress in solving
computer games and robotic control tasks. A known problem, though, is that
policies overfit to the training environment and may not avoid rare,
catastrophic events such as automotive accidents. A classical technique for
improving the robustness of reinforcement learning algorithms is to train on a
set of randomized environments, but this approach only guards against common
situations. Recently, robust adversarial reinforcement learning (RARL) was
developed, which allows efficient applications of random and systematic
perturbations by a trained adversary. A limitation of RARL is that only the
expected control objective is optimized; there is no explicit modeling or
optimization of risk. Thus the agents do not consider the probability of
catastrophic events (i.e., those inducing abnormally large negative reward),
except through their effect on the expected objective. In this paper we
introduce risk-averse robust adversarial reinforcement learning (RARARL), using
a risk-averse protagonist and a risk-seeking adversary. We test our approach on
a self-driving vehicle controller. We use an ensemble of policy networks to
model risk as the variance of value functions. We show through experiments that
a risk-averse agent is better equipped to handle a risk-seeking adversary, and
experiences substantially fewer crashes compared to agents trained without an
adversary.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pan_X/0/1/0/all/0/1&quot;&gt;Xinlei Pan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Seita_D/0/1/0/all/0/1&quot;&gt;Daniel Seita&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1&quot;&gt;Yang Gao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Canny_J/0/1/0/all/0/1&quot;&gt;John Canny&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00512">
<title>Elaboration Tolerant Representation of Markov Decision Process via Decision-Theoretic Extension of Probabilistic Action Language pBC+. (arXiv:1904.00512v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1904.00512</link>
<description rdf:parseType="Literal">&lt;p&gt;We extend probabilistic action language pBC+ with the notion of utility as in
decision theory. The semantics of the extended pBC+ can be defined as a
shorthand notation for a decision-theoretic extension of the probabilistic
answer set programming language LPMLN. Alternatively, the semantics of pBC+ can
also be defined in terms of Markov Decision Process (MDP), which in turn allows
for representing MDP in a succinct and elaboration tolerant way as well as to
leverage an MDP solver to compute pBC+. The idea led to the design of the
system pbcplus2mdp, which can find an optimal policy of a pBC+ action
description using an MDP solver.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yi Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1&quot;&gt;Joohyung Lee&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00513">
<title>Optimal Low-Latency Network Topologies for Cluster Performance Enhancement. (arXiv:1904.00513v1 [cs.NI])</title>
<link>http://arxiv.org/abs/1904.00513</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose that clusters interconnected with network topologies having
minimal mean path length will increase their overall performance for a variety
of applications. We approach our heuristic by constructing clusters of up to 36
nodes having Dragonfly, torus, ring, Chvatal, Wagner, Bidiakis and several
other topologies with minimal mean path lengths and by simulating the
performance of 256-node clusters with the same network topologies. The optimal
(or sub-optimal) low-latency network topologies are found by minimizing the
mean path length of regular graphs. The selected topologies are benchmarked
using ping-pong messaging, the MPI collective communications, and the standard
parallel applications including effective bandwidth, FFTE, Graph 500 and NAS
parallel benchmarks. We established strong correlations between the clusters&apos;
performances and the network topologies, especially the mean path lengths, for
a wide range of applications. In communication-intensive benchmarks, clusters
with optimal network topologies out-perform those with mainstream topologies by
several folds. It is striking that a mere adjustment of the network topology
suffices to reclaim performance from the same computing hardware.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Deng_Y/0/1/0/all/0/1&quot;&gt;Yuefan Deng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guo_M/0/1/0/all/0/1&quot;&gt;Meng Guo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ramos_A/0/1/0/all/0/1&quot;&gt;Alexandre F. Ramos&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_X/0/1/0/all/0/1&quot;&gt;Xiaolong Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1&quot;&gt;Zhipeng Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1&quot;&gt;Weifeng Liu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00516">
<title>Summarizing Event Sequences with Serial Episodes: A Statistical Model and an Application. (arXiv:1904.00516v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1904.00516</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper we address the problem of discovering a small set of frequent
serial episodes from sequential data so as to adequately characterize or
summarize the data. We discuss an algorithm based on the Minimum Description
Length (MDL) principle and the algorithm is a slight modification of an earlier
method, called CSC-2. We present a novel generative model for sequence data
containing prominent pairs of serial episodes and, using this, provide some
statistical justification for the algorithm. We believe this is the first
instance of such a statistical justification for an MDL based algorithm for
summarizing event sequence data. We then present a novel application of this
data mining algorithm in text classification. By considering text documents as
temporal sequences of words, the data mining algorithm can find a set of
characteristic episodes for all the training data as a whole. The words that
are part of these characteristic episodes could then be considered the only
relevant words for the dictionary thus resulting in a considerably reduced
feature vector dimension. We show, through simulation experiments using
benchmark data sets, that the discovered frequent episodes can be used to
achieve more than four-fold reduction in dictionary size without losing any
classification accuracy.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mitra_S/0/1/0/all/0/1&quot;&gt;Soumyajit Mitra&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sastry_P/0/1/0/all/0/1&quot;&gt;P S Sastry&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00518">
<title>A Comparative Study of Asynchronous Many-Tasking Runtimes: Cilk, Charm++, ParalleX and AM++. (arXiv:1904.00518v1 [cs.DC])</title>
<link>http://arxiv.org/abs/1904.00518</link>
<description rdf:parseType="Literal">&lt;p&gt;We evaluate and compare four contemporary and emerging runtimes for
high-performance computing(HPC) applications: Cilk, Charm++, ParalleX and AM++.
We compare along three bases: programming model, execution model and the
implementation on an underlying machine model. The comparison study includes a
survey of each runtime system&apos;s programming models, their corresponding
execution models, their stated features, and performance and productivity
goals. We first qualitatively compare these runtimes with programmability in
mind. The differences in expressivity and programmability arising from their
syntax and semantics are clearly enunciated through examples common to all
runtimes. Then, the execution model of each runtime, which acts as a bridge
between the programming model and the underlying machine model, is compared and
contrasted to that of the others. We also evaluate four mature implementations
of these runtimes, namely: Intel Cilk++, Charm++ 6.5.1, AM++ and HPX, that
embody the principles dictated by these models. With the emergence of the next
generation of supercomputers, it is imperative for parallel programming models
to evolve and address the integral challenges introduced by the increasing
scale. Rather than picking a winner out of these four models under
consideration, we end with a discussion on lessons learned, and how such a
study is instructive in the evolution of parallel programming frameworks to
address the said challenges.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kulkarni_A/0/1/0/all/0/1&quot;&gt;Abhishek Kulkarni&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lumsdaine_A/0/1/0/all/0/1&quot;&gt;Andrew Lumsdaine&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00523">
<title>Toward Real-World Single Image Super-Resolution: A New Benchmark and A New Model. (arXiv:1904.00523v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1904.00523</link>
<description rdf:parseType="Literal">&lt;p&gt;Most of the existing learning-based single image superresolution (SISR)
methods are trained and evaluated on simulated datasets, where the
low-resolution (LR) images are generated by applying a simple and uniform
degradation (i.e., bicubic downsampling) to their high-resolution (HR)
counterparts. However, the degradations in real-world LR images are far more
complicated. As a consequence, the SISR models trained on simulated data become
less effective when applied to practical scenarios. In this paper, we build a
real-world super-resolution (RealSR) dataset where paired LR-HR images on the
same scene are captured by adjusting the focal length of a digital camera. An
image registration algorithm is developed to progressively align the image
pairs at different resolutions. Considering that the degradation kernels are
naturally non-uniform in our dataset, we present a Laplacian pyramid based
kernel prediction network (LP-KPN), which efficiently learns per-pixel kernels
to recover the HR image. Our extensive experiments demonstrate that SISR models
trained on our RealSR dataset deliver better visual quality with sharper edges
and finer textures on real-world scenes than those trained on simulated
datasets. Though our RealSR dataset is built by using only two cameras (Canon
5D3 and Nikon D810), the trained model generalizes well to other camera devices
such as Sony a7II and mobile phones.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cai_J/0/1/0/all/0/1&quot;&gt;Jianrui Cai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zeng_H/0/1/0/all/0/1&quot;&gt;Hui Zeng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yong_H/0/1/0/all/0/1&quot;&gt;Hongwei Yong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cao_Z/0/1/0/all/0/1&quot;&gt;Zisheng Cao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1&quot;&gt;Lei Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00526">
<title>On Limitations of the Witness Configuration Method for Geometric Constraint Solving in CAD Modeling. (arXiv:1904.00526v1 [cs.CG])</title>
<link>http://arxiv.org/abs/1904.00526</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper presents discussions on the limitations of the witness
configuration method. These limitations have rarely been reported in previous
studies. The witness configuration method is a very recent approach for
geometric constraint solving, which is of critical importance for modern
computer-aided design systems. The witness configuration method may be the most
promising method to solve satisfactorily the challenges of geometric constraint
solving. This method, in the current form, is however found to be limited for
the three essential tasks in the geometric constraint solving domain. Examples
are given to validate this work&apos;s statements on these limitations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zou_Q/0/1/0/all/0/1&quot;&gt;Qiang Zou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Feng_H/0/1/0/all/0/1&quot;&gt;Hsi-Yung Feng&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00537">
<title>Perceive Where to Focus: Learning Visibility-aware Part-level Features for Partial Person Re-identification. (arXiv:1904.00537v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1904.00537</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper considers a realistic problem in person re-identification (re-ID)
task, i.e., partial re-ID. Under partial re-ID scenario, the images may contain
a partial observation of a pedestrian. If we directly compare a partial
pedestrian image with a holistic one, the extreme spatial misalignment
significantly compromises the discriminative ability of the learned
representation. We propose a Visibility-aware Part Model (VPM), which learns to
perceive the visibility of regions through self-supervision. The visibility
awareness allows VPM to extract region-level features and compare two images
with focus on their shared regions (which are visible on both images). VPM
gains two-fold benefit toward higher accuracy for partial re-ID. On the one
hand, compared with learning a global feature, VPM learns region-level features
and benefits from fine-grained information. On the other hand, with visibility
awareness, VPM is capable to estimate the shared regions between two images and
thus suppresses the spatial misalignment. Experimental results confirm that our
method significantly improves the learned representation and the achieved
accuracy is on par with the state of the art.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1&quot;&gt;Yifan Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_Q/0/1/0/all/0/1&quot;&gt;Qin Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1&quot;&gt;Yali Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1&quot;&gt;Chi Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1&quot;&gt;Yikang Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1&quot;&gt;Shengjin Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_J/0/1/0/all/0/1&quot;&gt;Jian Sun&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00538">
<title>Maximization of Relative Social Welfare on Truthful Cardinal Voting Schemes. (arXiv:1904.00538v1 [cs.GT])</title>
<link>http://arxiv.org/abs/1904.00538</link>
<description rdf:parseType="Literal">&lt;p&gt;Consider the the problem of maximizing the relative social welfare of
truthful single-winner voting schemes with cardinal preferences compared to the
classical range voting scheme. The range voting scheme is a simple and
straightforward mechanism which deterministically maximizes the social welfare.
However, the scheme that is known to be non-truthful and we studied the
truthful mechanism that maximize the ratio of its expected social welfare to
the social welfare achieved by the range voting scheme. We provide a scheme
which achieve a ratio of $\Omega(m^{-2/3})$ in this paper. It is proved that
this bound is tight asymptotically and it is impossible to find a better voting
scheme.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1&quot;&gt;Sinya Lee&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00540">
<title>PIRM2018 Challenge on Spectral Image Super-Resolution: Dataset and Study. (arXiv:1904.00540v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1904.00540</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper introduces a newly collected and novel dataset (StereoMSI) for
example-based single and colour-guided spectral image super-resolution. The
dataset was first released and promoted during the PIRM2018 spectral image
super-resolution challenge. To the best of our knowledge, the dataset is the
first of its kind, comprising 350 registered colour-spectral image pairs. The
dataset has been used for the two tracks of the challenge and, for each of
these, we have provided a split into training, validation and testing. This
arrangement is a result of the challenge structure and phases, with the first
track focusing on example-based spectral image super-resolution and the second
one aiming at exploiting the registered stereo colour imagery to improve the
resolution of the spectral images. Each of the tracks and splits has been
selected to be consistent across a number of image quality metrics. The dataset
is quite general in nature and can be used for a wide variety of applications
in addition to the development of spectral image super-resolution methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shoeiby_M/0/1/0/all/0/1&quot;&gt;Mehrdad Shoeiby&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Robles_Kelly_A/0/1/0/all/0/1&quot;&gt;Antonio Robles-Kelly&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wei_R/0/1/0/all/0/1&quot;&gt;Ran Wei&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Timofte_R/0/1/0/all/0/1&quot;&gt;Radu Timofte&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00542">
<title>Multi-Task Ordinal Regression for Jointly Predicting the Trustworthiness and the Leading Political Ideology of News Media. (arXiv:1904.00542v1 [cs.IR])</title>
<link>http://arxiv.org/abs/1904.00542</link>
<description rdf:parseType="Literal">&lt;p&gt;In the context of fake news, bias, and propaganda, we study two important but
relatively under-explored problems: (i) trustworthiness estimation (on a
3-point scale) and (ii) political ideology detection (left/right bias on a
7-point scale) of entire news outlets, as opposed to evaluating individual
articles. In particular, we propose a multi-task ordinal regression framework
that models the two problems jointly. This is motivated by the observation that
hyper-partisanship is often linked to low trustworthiness, e.g., appealing to
emotions rather than sticking to the facts, while center media tend to be
generally more impartial and trustworthy. We further use several auxiliary
tasks, modeling centrality, hyperpartisanship, as well as left-vs.-right bias
on a coarse-grained scale. The evaluation results show sizable performance
gains by the joint models over models that target the problems in isolation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Baly_R/0/1/0/all/0/1&quot;&gt;Ramy Baly&lt;/a&gt; (MIT Computer Science and Artificial Intelligence Laboratory, MA, USA), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Karadzhov_G/0/1/0/all/0/1&quot;&gt;Georgi Karadzhov&lt;/a&gt; (SiteGround Hosting EOOD, Bulgaria), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Saleh_A/0/1/0/all/0/1&quot;&gt;Abdelrhman Saleh&lt;/a&gt; (Harvard University, MA, USA), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Glass_J/0/1/0/all/0/1&quot;&gt;James Glass&lt;/a&gt; (MIT Computer Science and Artificial Intelligence Laboratory, MA, USA), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nakov_P/0/1/0/all/0/1&quot;&gt;Preslav Nakov&lt;/a&gt; (Qatar Computing Research Institute, HBKU, Qatar)</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00548">
<title>Unsupervised Contextual Anomaly Detection using Joint Deep Variational Generative Models. (arXiv:1904.00548v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1904.00548</link>
<description rdf:parseType="Literal">&lt;p&gt;A method for unsupervised contextual anomaly detection is proposed using a
cross-linked pair of Variational Auto-Encoders for assigning a normality score
to an observation. The method enables a distinct separation of contextual from
behavioral attributes and is robust to the presence of anomalous or novel
contextual attributes. The method can be trained with data sets that contain
anomalies without any special pre-processing.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Shulman_Y/0/1/0/all/0/1&quot;&gt;Yaniv Shulman&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00549">
<title>MESH: A Flexible Distributed Hypergraph Processing System. (arXiv:1904.00549v1 [cs.DC])</title>
<link>http://arxiv.org/abs/1904.00549</link>
<description rdf:parseType="Literal">&lt;p&gt;With the rapid growth of large online social networks, the ability to analyze
large-scale social structure and behavior has become critically important, and
this has led to the development of several scalable graph processing systems.
In reality, however, social interaction takes place not only between pairs of
individuals as in the graph model, but rather in the context of multi-user
groups. Research has shown that such group dynamics can be better modeled
through a more general hypergraph model, resulting in the need to build
scalable hypergraph processing systems. In this paper, we present MESH, a
flexible distributed framework for scalable hypergraph processing. MESH
provides an easy-to-use and expressive application programming interface that
naturally extends the think like a vertex model common to many popular graph
processing systems. Our framework provides a flexible implementation based on
an underlying graph processing system, and enables different design choices for
the key implementation issues of partitioning a hypergraph representation. We
implement MESH on top of the popular GraphX graph processing framework in
Apache Spark. Using a variety of real datasets and experiments conducted on a
local 8-node cluster as well as a 65-node Amazon AWS testbed, we demonstrate
that MESH provides flexibility based on data and application characteristics,
as well as scalability with cluster size. We further show that it is
competitive in performance to HyperX, another hypergraph processing system
based on Spark, while providing a much simpler implementation (requiring about
5X fewer lines of code), thus showing that simplicity and flexibility need not
come at the cost of performance.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Heintz_B/0/1/0/all/0/1&quot;&gt;Benjamin Heintz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hong_R/0/1/0/all/0/1&quot;&gt;Rankyung Hong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Singh_S/0/1/0/all/0/1&quot;&gt;Shivangi Singh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khandelwal_G/0/1/0/all/0/1&quot;&gt;Gaurav Khandelwal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tesdahl_C/0/1/0/all/0/1&quot;&gt;Corey Tesdahl&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chandra_A/0/1/0/all/0/1&quot;&gt;Abhishek Chandra&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00551">
<title>Weakly Supervised Object Detection with Segmentation Collaboration. (arXiv:1904.00551v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1904.00551</link>
<description rdf:parseType="Literal">&lt;p&gt;Weakly supervised object detection aims at learning precise object detectors,
given image category labels. In recent prevailing works, this problem is
generally formulated as a multiple instance learning module guided by an image
classification loss. The object bounding box is assumed to be the one
contributing most to the classification among all proposals. However, the
region contributing most is also likely to be a crucial part or the supporting
context of an object. To obtain a more accurate detector, in this work we
propose a novel end-to-end weakly supervised detection approach, where a newly
introduced generative adversarial segmentation module interacts with the
conventional detection module in a collaborative loop. The collaboration
mechanism takes full advantages of the complementary interpretations of the
weakly supervised localization task, namely detection and segmentation tasks,
forming a more comprehensive solution. Consequently, our method obtains more
precise object bounding boxes, rather than parts or irrelevant surroundings.
Expectedly, the proposed method achieves an accuracy of 51.0% on the PASCAL VOC
2007 dataset, outperforming the state-of-the-arts and demonstrating its
superiority for weakly supervised object detection.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1&quot;&gt;Xiaoyan Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kan_M/0/1/0/all/0/1&quot;&gt;Meina Kan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shan_S/0/1/0/all/0/1&quot;&gt;Shiguang Shan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1&quot;&gt;Xilin Chen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00553">
<title>Layered Image Compression using Scalable Auto-encoder. (arXiv:1904.00553v1 [cs.MM])</title>
<link>http://arxiv.org/abs/1904.00553</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper presents a novel convolutional neural network (CNN) based image
compression framework via scalable auto-encoder (SAE). Specifically, our SAE
based deep image codec consists of hierarchical coding layers, each of which is
an end-to-end optimized auto-encoder. The coarse image content and texture are
encoded through the first (base) layer while the consecutive (enhance) layers
iteratively code the pixel-level reconstruction errors between the original and
former reconstructed images. The proposed SAE structure alleviates the need to
train multiple models for different bit-rate points by recently proposed
auto-encoder based codecs. The SAE layers can be combined to realize multiple
rate points, or to produce a scalable stream. The proposed method has similar
rate-distortion performance in the low-to-medium rate range as the
state-of-the-art CNN based image codec (which uses different optimized networks
to realize different bit rates) over a standard public image dataset.
Furthermore, the proposed codec generates better perceptual quality in this bit
rate range.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jia_C/0/1/0/all/0/1&quot;&gt;Chuanmin Jia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1&quot;&gt;Zhaoyi Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yao Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ma_S/0/1/0/all/0/1&quot;&gt;Siwei Ma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gao_W/0/1/0/all/0/1&quot;&gt;Wen Gao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00558">
<title>Defogging Kinect: Simultaneous Estimation of Object Region and Depth in Foggy Scenes. (arXiv:1904.00558v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1904.00558</link>
<description rdf:parseType="Literal">&lt;p&gt;Three-dimensional (3D) reconstruction and scene depth estimation from
2-dimensional (2D) images are major tasks in computer vision. However, using
conventional 3D reconstruction techniques gets challenging in participating
media such as murky water, fog, or smoke. We have developed a method that uses
a time-of-flight (ToF) camera to estimate an object region and depth in
participating media simultaneously. The scattering component is saturated, so
it does not depend on the scene depth, and received signals bouncing off
distant points are negligible due to light attenuation in the participating
media, so the observation of such a point contains only a scattering component.
These phenomena enable us to estimate the scattering component in an object
region from a background that only contains the scattering component. The
problem is formulated as robust estimation where the object region is regarded
as outliers, and it enables the simultaneous estimation of an object region and
depth on the basis of an iteratively reweighted least squares (IRLS)
optimization scheme. We demonstrate the effectiveness of the proposed method
using captured images from a Kinect v2 in real foggy scenes and evaluate the
applicability with synthesized data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fujimura_Y/0/1/0/all/0/1&quot;&gt;Yuki Fujimura&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sonogashira_M/0/1/0/all/0/1&quot;&gt;Motoharu Sonogashira&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Iiyama_M/0/1/0/all/0/1&quot;&gt;Masaaki Iiyama&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00560">
<title>Scene Graph Generation with External Knowledge and Image Reconstruction. (arXiv:1904.00560v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1904.00560</link>
<description rdf:parseType="Literal">&lt;p&gt;Scene graph generation has received growing attention with the advancements
in image understanding tasks such as object detection, attributes and
relationship prediction,~\etc. However, existing datasets are biased in terms
of object and relationship labels, or often come with noisy and missing
annotations, which makes the development of a reliable scene graph prediction
model very challenging. In this paper, we propose a novel scene graph
generation algorithm with external knowledge and image reconstruction loss to
overcome these dataset issues. In particular, we extract commonsense knowledge
from the external knowledge base to refine object and phrase features for
improving generalizability in scene graph generation. To address the bias of
noisy object annotations, we introduce an auxiliary image reconstruction path
to regularize the scene graph generation network. Extensive experiments show
that our framework can generate better scene graphs, achieving the
state-of-the-art performance on two benchmark datasets: Visual Relationship
Detection and Visual Genome datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gu_J/0/1/0/all/0/1&quot;&gt;Jiuxiang Gu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_H/0/1/0/all/0/1&quot;&gt;Handong Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1&quot;&gt;Zhe Lin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1&quot;&gt;Sheng Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cai_J/0/1/0/all/0/1&quot;&gt;Jianfei Cai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ling_M/0/1/0/all/0/1&quot;&gt;Mingyang Ling&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00561">
<title>VINE: Visualizing Statistical Interactions in Black Box Models. (arXiv:1904.00561v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1904.00561</link>
<description rdf:parseType="Literal">&lt;p&gt;As machine learning becomes more pervasive, there is an urgent need for
interpretable explanations of predictive models. Prior work has developed
effective methods for visualizing global model behavior, as well as generating
local (instance-specific) explanations. However, relatively little work has
addressed regional explanations - how groups of similar instances behave in a
complex model, and the related issue of visualizing statistical feature
interactions. The lack of utilities available for these analytical needs
hinders the development of models that are mission-critical, transparent, and
align with social goals. We present VINE (Visual INteraction Effects), a novel
algorithm to extract and visualize statistical interaction effects in black box
models. We also present a novel evaluation metric for visualizations in the
interpretable ML space.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Britton_M/0/1/0/all/0/1&quot;&gt;Matthew Britton&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00562">
<title>Deep Clustering With Intra-class Distance Constraint for Hyperspectral Images. (arXiv:1904.00562v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1904.00562</link>
<description rdf:parseType="Literal">&lt;p&gt;The high dimensionality of hyperspectral images often results in the
degradation of clustering performance. Due to the powerful ability of deep
feature extraction and non-linear feature representation, the clustering
algorithm based on deep learning has become a hot research topic in the field
of hyperspectral remote sensing. However, most deep clustering algorithms for
hyperspectral images utilize deep neural networks as feature extractor without
considering prior knowledge constraints that are suitable for clustering. To
solve this problem, we propose an intra-class distance constrained deep
clustering algorithm for high-dimensional hyperspectral images. The proposed
algorithm constrains the feature mapping procedure of the auto-encoder network
by intra-class distance so that raw images are transformed from the original
high-dimensional space to the low-dimensional feature space that is more
conducive to clustering. Furthermore, the related learning process is treated
as a joint optimization problem of deep feature extraction and clustering.
Experimental results demonstrate the intense competitiveness of the proposed
algorithm in comparison with state-of-the-art clustering methods of
hyperspectral images.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_J/0/1/0/all/0/1&quot;&gt;Jinguang Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1&quot;&gt;Wanli Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wei_X/0/1/0/all/0/1&quot;&gt;Xian Wei&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fang_L/0/1/0/all/0/1&quot;&gt;Li Fang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tang_X/0/1/0/all/0/1&quot;&gt;Xiaoliang Tang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1&quot;&gt;Yusheng Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_H/0/1/0/all/0/1&quot;&gt;Hui Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yao_W/0/1/0/all/0/1&quot;&gt;Wei Yao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00566">
<title>Multi-source weak supervision for saliency detection. (arXiv:1904.00566v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1904.00566</link>
<description rdf:parseType="Literal">&lt;p&gt;The high cost of pixel-level annotations makes it appealing to train saliency
detection models with weak supervision. However, a single weak supervision
source usually does not contain enough information to train a well-performing
model. To this end, we propose a unified framework to train saliency detection
models with diverse weak supervision sources. In this paper, we use category
labels, captions, and unlabelled data for training, yet other supervision
sources can also be plugged into this flexible framework. We design a
classification network (CNet) and a caption generation network (PNet), which
learn to predict object categories and generate captions, respectively,
meanwhile highlight the most important regions for corresponding tasks. An
attention transfer loss is designed to transmit supervision signal between
networks, such that the network designed to be trained with one supervision
source can benefit from another. An attention coherence loss is defined on
unlabelled data to encourage the networks to detect generally salient regions
instead of task-specific regions. We use CNet and PNet to generate pixel-level
pseudo labels to train a saliency prediction network (SNet). During the testing
phases, we only need SNet to predict saliency maps. Experiments demonstrate the
performance of our method compares favourably against unsupervised and weakly
supervised methods and even some supervised methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zeng_Y/0/1/0/all/0/1&quot;&gt;Yu Zeng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhuge_Y/0/1/0/all/0/1&quot;&gt;Yunzhi Zhuge&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lu_H/0/1/0/all/0/1&quot;&gt;Huchuan Lu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1&quot;&gt;Lihe Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qian_M/0/1/0/all/0/1&quot;&gt;Mingyang Qian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1&quot;&gt;Yizhou Yu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00575">
<title>A Novel GAN-based Fault Diagnosis Approach for Imbalanced Industrial Time Series. (arXiv:1904.00575v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1904.00575</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper proposes a novel fault diagnosis approach based on generative
adversarial networks (GAN) for imbalanced industrial time series where normal
samples are much larger than failure cases. We combine a well-designed feature
extractor with GAN to help train the whole network. Aimed at obtaining data
distribution and hidden pattern in both original distinguishing features and
latent space, the encoder-decoder-encoder three-sub-network is employed in GAN,
based on Deep Convolution Generative Adversarial Networks (DCGAN) but without
Tanh activation layer and only trained on normal samples. In order to verify
the validity and feasibility of our approach, we test it on rolling bearing
data from Case Western Reserve University and further verify it on data
collected from our laboratory. The results show that our proposed approach can
achieve excellent performance in detecting faulty by outputting much larger
evaluation scores.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jiang_W/0/1/0/all/0/1&quot;&gt;Wenqian Jiang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cheng_C/0/1/0/all/0/1&quot;&gt;Cheng Cheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_B/0/1/0/all/0/1&quot;&gt;Beitong Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ma_G/0/1/0/all/0/1&quot;&gt;Guijun Ma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yuan_Y/0/1/0/all/0/1&quot;&gt;Ye Yuan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00577">
<title>Adaptive Bayesian Linear Regression for Automated Machine Learning. (arXiv:1904.00577v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1904.00577</link>
<description rdf:parseType="Literal">&lt;p&gt;To solve a machine learning problem, one typically needs to perform data
preprocessing, modeling, and hyperparameter tuning, which is known as model
selection and hyperparameter optimization.The goal of automated machine
learning (AutoML) is to design methods that can automatically perform model
selection and hyperparameter optimization without human interventions for a
given dataset. In this paper, we propose a meta-learning method that can search
for a high-performance machine learning pipeline from the predefined set of
candidate pipelines for supervised classification datasets in an efficient way
by leveraging meta-data collected from previous experiments. More specifically,
our method combines an adaptive Bayesian regression model with a neural network
basis function and the acquisition function from Bayesian optimization. The
adaptive Bayesian regression model is able to capture knowledge from previous
meta-data and thus make predictions of the performances of machine learning
pipelines on a new dataset. The acquisition function is then used to guide the
search of possible pipelines based on the predictions.The experiments
demonstrate that our approach can quickly identify high-performance pipelines
for a range of test datasets and outperforms the baseline methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_W/0/1/0/all/0/1&quot;&gt;Weilin Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Precioso_F/0/1/0/all/0/1&quot;&gt;Frederic Precioso&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00579">
<title>Palmprint image registration using convolutional neural networks and Hough transform. (arXiv:1904.00579v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1904.00579</link>
<description rdf:parseType="Literal">&lt;p&gt;Minutia-based palmprint recognition systems has got lots of interest in last
two decades. Due to the large number of minutiae in a palmprint, approximately
1000 minutiae, the matching process is time consuming which makes it
unpractical for real time applications. One way to address this issue is
aligning all palmprint images to a reference image and bringing them to a same
coordinate system. Bringing all palmprint images to a same coordinate system,
results in fewer computations during minutia matching. In this paper, using
convolutional neural network (CNN) and generalized Hough transform (GHT), we
propose a new method to register palmprint images accurately. This method,
finds the corresponding rotation and displacement (in both x and y direction)
between the palmprint and a reference image. Exact palmprint registration can
enhance the speed and the accuracy of matching process. Proposed method is
capable of distinguishing between left and right palmprint automatically which
helps to speed up the matching process. Furthermore, designed structure of CNN
in registration stage, gives us the segmented palmprint image from background
which is a pre-processing step for minutia extraction. The proposed
registration method followed by minutia-cylinder code (MCC) matching algorithm
has been evaluated on the THUPALMLAB database, and the results show the
superiority of our algorithm over most of the state-of-the-art algorithms.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ahmadi_M/0/1/0/all/0/1&quot;&gt;Mohsen Ahmadi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Soleimani_H/0/1/0/all/0/1&quot;&gt;Hossein Soleimani&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00583">
<title>Sound source ranging using a feed-forward neural network with fitting-based early stopping. (arXiv:1904.00583v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1904.00583</link>
<description rdf:parseType="Literal">&lt;p&gt;When a feed-forward neural network (FNN) is trained for source ranging in an
ocean waveguide, it is difficult evaluating the range accuracy of the FNN on
unlabeled test data. A fitting-based early stopping (FEAST) method is
introduced to evaluate the range error of the FNN on test data where the
distance of source is unknown. Based on FEAST, when the evaluated range error
of the FNN reaches the minimum on test data, stopping training, which will help
to improve the ranging accuracy of the FNN on the test data. The FEAST is
demonstrated on simulated and experimental data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chi_J/0/1/0/all/0/1&quot;&gt;Jing Chi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1&quot;&gt;Xiaolei Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1&quot;&gt;Haozhong Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gao_D/0/1/0/all/0/1&quot;&gt;Dazhi Gao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gerstoft_P/0/1/0/all/0/1&quot;&gt;Peter Gerstoft&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00585">
<title>Using Similarity Measures to Select Pretraining Data for NER. (arXiv:1904.00585v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1904.00585</link>
<description rdf:parseType="Literal">&lt;p&gt;Word vectors and Language Models (LMs) pretrained on a large amount of
unlabelled data can dramatically improve various Natural Language Processing
(NLP) tasks. However, the measure and impact of similarity between pretraining
data and target task data are left to intuition. We propose three
cost-effective measures to quantify different aspects of similarity between
source pretraining and target task data. We demonstrate that these measures are
good predictors of the usefulness of pretrained models for Named Entity
Recognition (NER) over 30 data pairs. Results also suggest that pretrained LMs
are more effective and more predictable than pretrained word vectors, but
pretrained word vectors are better when pretraining data is dissimilar.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dai_X/0/1/0/all/0/1&quot;&gt;Xiang Dai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Karimi_S/0/1/0/all/0/1&quot;&gt;Sarvnaz Karimi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hachey_B/0/1/0/all/0/1&quot;&gt;Ben Hachey&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Paris_C/0/1/0/all/0/1&quot;&gt;Cecile Paris&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00592">
<title>ResUNet-a: a deep learning framework for semantic segmentation of remotely sensed data. (arXiv:1904.00592v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1904.00592</link>
<description rdf:parseType="Literal">&lt;p&gt;Scene understanding of high resolution aerial images is of great importance
for the task of automated monitoring in various remote sensing applications.
Due to the large within-class and small between-class variance in pixel values
of objects of interest, this remains a challenging task. In recent years, deep
convolutional neural networks have started being used in remote sensing
applications and demonstrate state-of-the-art performance for pixel level
classification of objects. Here we present a novel deep learning architecture,
ResUNet-a, that combines ideas from various state-of-the-art modules used in
computer vision for semantic segmentation tasks. We analyse the performance of
several flavours of the Generalized Dice loss for semantic segmentation, and we
introduce a novel variant loss function for semantic segmentation of objects
that has better convergence properties and behaves well even under the presence
of highly imbalanced classes. The performance of our modelling framework is
evaluated on the ISPRS 2D Potsdam dataset. Results show state-of-the-art
performance with an average F1 score of 92.1\% over all classes for our best
model.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Diakogiannis_F/0/1/0/all/0/1&quot;&gt;Foivos I. Diakogiannis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Waldner_F/0/1/0/all/0/1&quot;&gt;Fran&amp;#xe7;ois Waldner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Caccetta_P/0/1/0/all/0/1&quot;&gt;Peter Caccetta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_C/0/1/0/all/0/1&quot;&gt;Chen Wu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00597">
<title>Learning Combinatorial Embedding Networks for Deep Graph Matching. (arXiv:1904.00597v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1904.00597</link>
<description rdf:parseType="Literal">&lt;p&gt;Graph matching refers to finding node correspondence between graphs, such
that the corresponding node and edge&apos;s affinity can be maximized. In addition
with its NP-completeness nature, another important challenge is effective
modeling of the node-wise and structure-wise affinity across graphs and the
resulting objective, to guide the matching procedure effectively finding the
true matching against noises. To this end, this paper devises an end-to-end
differentiable deep network pipeline to learn the affinity for graph matching.
It involves a supervised permutation loss regarding with node correspondence to
capture the combinatorial nature for graph matching. Meanwhile deep graph
embedding models are adopted to parameterize both intra-graph and cross-graph
affinity functions, instead of the traditional shallow and simple parametric
forms e.g. a Gaussian kernel. The embedding can also effectively capture the
higher-order structure beyond second-order edges. The permutation loss model is
agnostic to the number of nodes, and the embedding model is shared among nodes
such that the network allows for varying numbers of nodes in graphs for
training and inference. Moreover, our network is class-agnostic with some
generalization capability across different categories. All these features are
welcomed for real-world applications. Experiments show its superiority against
state-of-the-art graph matching learning methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1&quot;&gt;Runzhong Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yan_J/0/1/0/all/0/1&quot;&gt;Junchi Yan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1&quot;&gt;Xiaokang Yang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00601">
<title>Distributed Power Control for Large Energy Harvesting Networks: A Multi-Agent Deep Reinforcement Learning Approach. (arXiv:1904.00601v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1904.00601</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we develop a multi-agent reinforcement learning (MARL)
framework to obtain online power control policies for a large energy harvesting
(EH) multiple access channel, when only the causal information about the EH
process and wireless channel is available. In the proposed framework, we model
the online power control problem as a discrete-time mean-field game (MFG), and
leverage the deep reinforcement learning technique to learn the stationary
solution of the game in a distributed fashion. We analytically show that the
proposed procedure converges to the unique stationary solution of the MFG.
Using the proposed framework, the power control policies are learned in a
completely distributed fashion. In order to benchmark the performance of the
distributed policies, we also develop a deep neural network (DNN) based
centralized as well as distributed online power control schemes. Our simulation
results show the efficacy of the proposed power control policies. In
particular, the DNN based centralized power control policies provide a very
good performance for large EH networks for which the design of optimal policies
is intractable using the conventional methods such as Markov decision
processes. Further, performance of both the distributed policies is close to
the throughput achieved by the centralized policies.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sharma_M/0/1/0/all/0/1&quot;&gt;Mohit K.Sharma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zappone_A/0/1/0/all/0/1&quot;&gt;Alessio Zappone&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Assaad_M/0/1/0/all/0/1&quot;&gt;Mohamad Assaad&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Debbah_M/0/1/0/all/0/1&quot;&gt;Merouane Debbah&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vassilaras_S/0/1/0/all/0/1&quot;&gt;Spyridon Vassilaras&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00605">
<title>Relative Attributing Propagation: Interpreting the Comparative Contributions of Individual Units in Deep Neural Networks. (arXiv:1904.00605v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1904.00605</link>
<description rdf:parseType="Literal">&lt;p&gt;As Deep Neural Networks (DNNs) have demonstrated superhuman performance in
many computer vision tasks, there is an increasing interest in revealing the
complex internal mechanisms of DNNs. In this paper, we propose Relative
Attributing Propagation (RAP), which decomposes the output predictions of DNNs
with a new perspective that precisely separates the positive and negative
attributions. By identifying the fundamental causes of activation and the
proper inversion of relevance, RAP allows each neuron to be assigned an actual
contribution to the output. Furthermore, we devise pragmatic methods to handle
the effect of bias and batch normalization properly in the attributing
procedures. Therefore, our method makes it possible to interpret various kinds
of very deep neural network models with clear and attentive visualizations of
positive and negative attributions. By utilizing the region perturbation method
and comparing the distribution of attributions for a quantitative evaluation,
we verify the correctness of our RAP whether the positive and negative
attributions correctly account for each meaning. The positive and negative
attributions propagated by RAP show the characteristics of vulnerability and
robustness to the distortion of the corresponding pixels, respectively. We
apply RAP to DNN models; VGG-16, ResNet-50 and Inception-V3, demonstrating its
generation of more intuitive and improved interpretation compared to the
existing attribution methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nam_W/0/1/0/all/0/1&quot;&gt;Woo-Jeoung Nam&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Choi_J/0/1/0/all/0/1&quot;&gt;Jaesik Choi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1&quot;&gt;Seong-Whan Lee&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00607">
<title>Video Object Segmentation using Space-Time Memory Networks. (arXiv:1904.00607v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1904.00607</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a novel solution for semi-supervised video object segmentation. By
the nature of the problem, available cues (e.g. video frame(s) with object
masks) become richer with the intermediate predictions. However, the existing
methods are unable to fully exploit this rich source of information. We resolve
the issue by leveraging memory networks and learn to read relevant information
from all available sources. In our framework, the past frames with object masks
form an external memory, and the current frame as the query is segmented using
the mask information in the memory. Specifically, the query and the memory are
densely matched in the feature space, covering all the space-time pixel
locations in a feed-forward fashion. Contrast to the previous approaches, the
abundant use of the guidance information allows us to better handle the
challenges such as appearance changes and occlussions. We validate our method
on the latest benchmark sets and achieved the state-of-the-art performance
(overall score of 79.4 on Youtube-VOS val set, J of 88.7 and 79.2 on DAVIS
2016/2017 val set respectively) while having a fast runtime (0.16 second/frame
on DAVIS 2016 val set).
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Oh_S/0/1/0/all/0/1&quot;&gt;Seoung Wug Oh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1&quot;&gt;Joon-Young Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_N/0/1/0/all/0/1&quot;&gt;Ning Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1&quot;&gt;Seon Joo Kim&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00609">
<title>Passive Head-Mounted Display Music-Listening EEG dataset. (arXiv:1904.00609v1 [cs.HC])</title>
<link>http://arxiv.org/abs/1904.00609</link>
<description rdf:parseType="Literal">&lt;p&gt;We describe the experimental procedures for a dataset that we have made
publicly available at https://doi.org/10.5281/zenodo.2617084 in mat (Mathworks,
Natick, USA) and csv formats. This dataset contains electroencephalographic
recordings of 12 subjects listening to music with and without a passive
head-mounted display, that is, a head-mounted display which does not include
any electronics at the exception of a smartphone. The electroencephalographic
headset consisted of 16 electrodes. Data were recorded during a pilot
experiment taking place in the GIPSA-lab, Grenoble, France, in 2017 (Cattan and
al, 2018). Python code for manipulating the data is available at
https://github.com/plcrodrigues/py.PHMDML.EEG.2017-GIPSA. The ID of this
dataset is PHMDML.EEG.2017-GIPSA.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cattan_G/0/1/0/all/0/1&quot;&gt;Gr&amp;#xe9;goire Cattan&lt;/a&gt; (GIPSA-Services), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rodrigues_P/0/1/0/all/0/1&quot;&gt;Pedro C. Rodrigues&lt;/a&gt; (GIPSA-Services), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Congedo_M/0/1/0/all/0/1&quot;&gt;Marco Congedo&lt;/a&gt; (GIPSA-Services)</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00613">
<title>An Alternative Set Model of Cognitive Jump. (arXiv:1904.00613v1 [cs.GT])</title>
<link>http://arxiv.org/abs/1904.00613</link>
<description rdf:parseType="Literal">&lt;p&gt;When we enumerate numbers up to some specific value, or, even if we do not
specify the number, we know at the same time that there are much greater
numbers which should be reachable by the same enumeration, but indeed we also
congnize them without practical enumeration. Namely, if we deem enumeration to
be a way of reaching a number without any &quot;jump&quot;, there is a &quot;jump&apos;&apos; in our way
of cognition of such greater numbers. In this article, making use of a set
theoretical framework by Vop\v{e}nka (1979) (alternative set theory) which
describes such structure, we attempt to shed light on an analogous sturucture
in human and social phenomenon. As an example, we examine a problem of common
knowledge in electronic mail game presented by Rubinstein (1989). We show an
event comes to common knowledge by a &quot;cognitive jump&quot;.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sakahara_K/0/1/0/all/0/1&quot;&gt;Kiri Sakahara&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sato_T/0/1/0/all/0/1&quot;&gt;Takashi Sato&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00614">
<title>Risk management in design process for Factory of the future. (arXiv:1904.00614v1 [cs.CY])</title>
<link>http://arxiv.org/abs/1904.00614</link>
<description rdf:parseType="Literal">&lt;p&gt;The current globalization is faced to the rapid development of product design
process with the different structure of the actor relationships in the process.
Currently, the risk in the failure relationship among different actors in the
project is shaped by the complexity towards the future all kinds of challenges.
When it comes to the interdependent failure effect, the risk management for
future organization structure in design process will be much more complex to
grasp. In order to cope with adaption of Product-Process-Organization (P-P-O)
model for industry of the future, we propose a risk management methodology to
cope with this interdependent relationship structure. The main objective of
this research is to manage the risks, so that the project manager can find the
priority order of all the actors&apos; total effect to the project with the
consideration of interdependent failure affection, and according to the order,
project manager can release corresponding respond measures.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jin_G/0/1/0/all/0/1&quot;&gt;Guangying Jin&lt;/a&gt; (IMS), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sperandio_S/0/1/0/all/0/1&quot;&gt;S&amp;#xe9;verine Sperandio&lt;/a&gt; (IMS), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Girard_P/0/1/0/all/0/1&quot;&gt;Philippe Girard&lt;/a&gt; (IMS)</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00615">
<title>Discontinuous Constituency Parsing with a Stack-Free Transition System and a Dynamic Oracle. (arXiv:1904.00615v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1904.00615</link>
<description rdf:parseType="Literal">&lt;p&gt;We introduce a novel transition system for discontinuous constituency
parsing. Instead of storing subtrees in a stack --i.e. a data structure with
linear-time sequential access-- the proposed system uses a set of parsing
items, with constant-time random access. This change makes it possible to
construct any discontinuous constituency tree in exactly $4n - 2$ transitions
for a sentence of length $n$. At each parsing step, the parser considers every
item in the set to be combined with a focus item and to construct a new
constituent in a bottom-up fashion. The parsing strategy is based on the
assumption that most syntactic structures can be parsed incrementally and that
the set --the memory of the parser-- remains reasonably small on average.
Moreover, we introduce a provably correct dynamic oracle for the new transition
system, and present the first experiments in discontinuous constituency parsing
using a dynamic oracle. Our parser obtains state-of-the-art results on three
English and German discontinuous treebanks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Coavoux_M/0/1/0/all/0/1&quot;&gt;Maximin Coavoux&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cohen_S/0/1/0/all/0/1&quot;&gt;Shay B. Cohen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00616">
<title>ISS Lyapunov Functions for Cascade Switched Systems and Sampled-Data Control. (arXiv:1904.00616v1 [cs.SY])</title>
<link>http://arxiv.org/abs/1904.00616</link>
<description rdf:parseType="Literal">&lt;p&gt;Input-to-state stability (ISS) of switched systems is studied where the
individual subsystems are connected in a serial cascade configuration, and the
states are allowed to reset at switching times. An ISS Lyapunov function is
associated to each of the two blocks connected in cascade, and these functions
are used as building blocks for constructing ISS Lyapunov function for the
interconnected system. The derivative of individual Lyapunov functions may be
bounded by nonlinear decay functions, and the growth in the value of Lyapunov
function at switching times may also be a nonlinear function of the value of
other Lyapunov functions. The stability of overall hybrid system is analyzed by
constructing a newly constructed ISS-Lyapunov function and deriving lower
bounds on the average dwell-time. The particular case of linear subsystems and
quadratic Lyapunov functions is also studied. The tools are also used for
studying the observer-based feedback stabilization of a nonlinear switched
system with event-based sampling of the output and control inputs. We design
dynamic sampling algorithms based on the proposed Lyapunov functions and
analyze the stability of the resulting closed-loop system.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_G/0/1/0/all/0/1&quot;&gt;GuangXue Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tanwani_A/0/1/0/all/0/1&quot;&gt;Aneel Tanwani&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00617">
<title>Students&apos; Proof Assistant (SPA). (arXiv:1904.00617v1 [cs.LO])</title>
<link>http://arxiv.org/abs/1904.00617</link>
<description rdf:parseType="Literal">&lt;p&gt;The Students&apos; Proof Assistant (SPA) aims to both teach how to use a proof
assistant like Isabelle and also to teach how reliable proof assistants are
built. Technically it is a miniature proof assistant inside the Isabelle proof
assistant. In addition we conjecture that a good way to teach structured
proving is with a concrete prover where the connection between semantics, proof
system, and prover is clear. The proofs in Lamport&apos;s TLAPS proof assistant have
a very similar structure to those in the declarative prover SPA. To illustrate
this we compare a proof of Pelletier&apos;s problem 43 in TLAPS, Isabelle/Isar and
SPA. We also consider Pelletier&apos;s problem 34, also known as Andrews&apos;s
Challenge, where students are encouraged to develop their own justification
function and thus obtain a lot of insight into the proof assistant. Although
SPA is fully functional we have so far only used it in a few educational
scenarios.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schlichtkrull_A/0/1/0/all/0/1&quot;&gt;Anders Schlichtkrull&lt;/a&gt; (Technical University of Denmark), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Villadsen_J/0/1/0/all/0/1&quot;&gt;J&amp;#xf8;rgen Villadsen&lt;/a&gt; (Technical University of Denmark), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+From_A/0/1/0/all/0/1&quot;&gt;Andreas Halkj&amp;#xe6;r From&lt;/a&gt; (Technical University of Denmark)</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00618">
<title>Natural Deduction Assistant (NaDeA). (arXiv:1904.00618v1 [cs.LO])</title>
<link>http://arxiv.org/abs/1904.00618</link>
<description rdf:parseType="Literal">&lt;p&gt;We present the Natural Deduction Assistant (NaDeA) and discuss its advantages
and disadvantages as a tool for teaching logic. NaDeA is available online and
is based on a formalization of natural deduction in the Isabelle proof
assistant. We first provide concise formulations of the main formalization
results. We then elaborate on the prerequisites for NaDeA, in particular we
describe a formalization in Isabelle of &quot;Hilbert&apos;s Axioms&quot; that we use as a
starting point in our bachelor course on mathematical logic. We discuss a
recent evaluation of NaDeA and also give an overview of the exercises in NaDeA.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Villadsen_J/0/1/0/all/0/1&quot;&gt;J&amp;#xf8;rgen Villadsen&lt;/a&gt; (Technical University of Denmark), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+From_A/0/1/0/all/0/1&quot;&gt;Andreas Halkj&amp;#xe6;r From&lt;/a&gt; (Technical University of Denmark), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schlichtkrull_A/0/1/0/all/0/1&quot;&gt;Anders Schlichtkrull&lt;/a&gt; (Technical University of Denmark)</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00619">
<title>Towards Ranking Geometric Automated Theorem Provers. (arXiv:1904.00619v1 [cs.LO])</title>
<link>http://arxiv.org/abs/1904.00619</link>
<description rdf:parseType="Literal">&lt;p&gt;The field of geometric automated theorem provers has a long and rich history,
from the early AI approaches of the 1960s, synthetic provers, to today
algebraic and synthetic provers.
&lt;/p&gt;
&lt;p&gt;The geometry automated deduction area differs from other areas by the strong
connection between the axiomatic theories and its standard models. In many
cases the geometric constructions are used to establish the theorems&apos;
statements, geometric constructions are, in some provers, used to conduct the
proof, used as counter-examples to close some branches of the automatic proof.
Synthetic geometry proofs are done using geometric properties, proofs that can
have a visual counterpart in the supporting geometric construction.
&lt;/p&gt;
&lt;p&gt;With the growing use of geometry automatic deduction tools as applications in
other areas, e.g. in education, the need to evaluate them, using different
criteria, is felt. Establishing a ranking among geometric automated theorem
provers will be useful for the improvement of the current
methods/implementations. Improvements could concern wider scope, better
efficiency, proof readability and proof reliability.
&lt;/p&gt;
&lt;p&gt;To achieve the goal of being able to compare geometric automated theorem
provers a common test bench is needed: a common language to describe the
geometric problems; a comprehensive repository of geometric problems and a set
of quality measures.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Baeta_N/0/1/0/all/0/1&quot;&gt;Nuno Baeta&lt;/a&gt; (University of Coimbra), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Quaresma_P/0/1/0/all/0/1&quot;&gt;Pedro Quaresma&lt;/a&gt; (University of Coimbra)</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00620">
<title>Theorem and Algorithm Checking for Courses on Logic and Formal Methods. (arXiv:1904.00620v1 [cs.LO])</title>
<link>http://arxiv.org/abs/1904.00620</link>
<description rdf:parseType="Literal">&lt;p&gt;The RISC Algorithm Language (RISCAL) is a language for the formal modeling of
theories and algorithms. A RISCAL specification describes an infinite class of
models each of which has finite size; this allows to fully automatically check
in such a model the validity of all theorems and the correctness of all
algorithms. RISCAL thus enables us to quickly verify/falsify the specific truth
of propositions in sample instances of a model class before attempting to prove
their general truth in the whole class: the first can be achieved in a fully
automatic way while the second typically requires our assistance. RISCAL has
been mainly developed for educational purposes. To this end this paper reports
on some new enhancements of the tool: the automatic generation of checkable
verification conditions from algorithms, the visualization of the execution of
procedures and the evaluation of formulas illustrating the computation of their
results, and the generation of Web-based student exercises and assignments from
RISCAL specifications. Furthermore, we report on our first experience with
RISCAL in the teaching of courses on logic and formal methods and on further
plans to use this tool to enhance formal education.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schreiner_W/0/1/0/all/0/1&quot;&gt;Wolfgang Schreiner&lt;/a&gt; (Johannes Kepler University, Linz, Austria)</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00623">
<title>Constructing Hierarchical Q&amp;A Datasets for Video Story Understanding. (arXiv:1904.00623v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1904.00623</link>
<description rdf:parseType="Literal">&lt;p&gt;Video understanding is emerging as a new paradigm for studying human-like AI.
Question-and-Answering (Q&amp;amp;A) is used as a general benchmark to measure the
level of intelligence for video understanding. While several previous studies
have suggested datasets for video Q&amp;amp;A tasks, they did not really incorporate
story-level understanding, resulting in highly-biased and lack of variance in
degree of question difficulty. In this paper, we propose a hierarchical method
for building Q&amp;amp;A datasets, i.e. hierarchical difficulty levels. We introduce
three criteria for video story understanding, i.e. memory capacity, logical
complexity, and DIKW (Data-Information-Knowledge-Wisdom) pyramid. We discuss
how three-dimensional map constructed from these criteria can be used as a
metric for evaluating the levels of intelligence relating to video story
understanding.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Heo_Y/0/1/0/all/0/1&quot;&gt;Yu-Jung Heo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+On_K/0/1/0/all/0/1&quot;&gt;Kyoung-Woon On&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Choi_S/0/1/0/all/0/1&quot;&gt;Seongho Choi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lim_J/0/1/0/all/0/1&quot;&gt;Jaeseo Lim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1&quot;&gt;Jinah Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ryu_J/0/1/0/all/0/1&quot;&gt;Jeh-Kwang Ryu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bae_B/0/1/0/all/0/1&quot;&gt;Byung-Chull Bae&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1&quot;&gt;Byoung-Tak Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00625">
<title>Med3D: Transfer Learning for 3D Medical Image Analysis. (arXiv:1904.00625v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1904.00625</link>
<description rdf:parseType="Literal">&lt;p&gt;The performance on deep learning is significantly affected by volume of
training data. Models pre-trained from massive dataset such as ImageNet become
a powerful weapon for speeding up training convergence and improving accuracy.
Similarly, models based on large dataset are important for the development of
deep learning in 3D medical images. However, it is extremely challenging to
build a sufficiently large dataset due to difficulty of data acquisition and
annotation in 3D medical imaging. We aggregate the dataset from several medical
challenges to build 3DSeg-8 dataset with diverse modalities, target organs, and
pathologies. To extract general medical three-dimension (3D) features, we
design a heterogeneous 3D network called Med3D to co-train multi-domain 3DSeg-8
so as to make a series of pre-trained models. We transfer Med3D pre-trained
models to lung segmentation in LIDC dataset, pulmonary nodule classification in
LIDC dataset and liver segmentation on LiTS challenge. Experiments show that
the Med3D can accelerate the training convergence speed of target 3D medical
tasks 2 times compared with model pre-trained on Kinetics dataset, and 10 times
compared with training from scratch as well as improve accuracy ranging from
3\% to 20\%. Transferring our Med3D model on state-the-of-art DenseASPP
segmentation network, in case of single model, we achieve 94.6\% Dice
coefficient which approaches the result of top-ranged algorithms on the LiTS
challenge.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1&quot;&gt;Sihong Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ma_K/0/1/0/all/0/1&quot;&gt;Kai Ma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zheng_Y/0/1/0/all/0/1&quot;&gt;Yefeng Zheng&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00629">
<title>Multigrid Solvers in Reconfigurable Hardware. (arXiv:1904.00629v1 [cs.DC])</title>
<link>http://arxiv.org/abs/1904.00629</link>
<description rdf:parseType="Literal">&lt;p&gt;The problem of finding the solution of Partial Differential Equations (PDEs)
plays a central role in modeling real world problems. Over the past years,
Multigrid solvers have showed their robustness over other techniques, due to
its high convergence rate which is independent of the problem size. For this
reason, many attempts for exploiting the inherent parallelism of Multigrid have
been made to achieve the desired efficiency and scalability of the method. Yet,
most efforts fail in this respect due to many factors (time, resources)
governed by software implementations. In this paper, we present a hardware
implementation of the V-cycle Multigrid method for finding the solution of a
2D-Poisson equation. We use Handel-C to implement our hardware design, which we
map onto available Field Programmable Gate Arrays (FPGAs). We analyze the
implementation performance using the FPGA vendor&apos;s tools. We demonstrate the
robustness of Multigrid over other iterative solvers, such as Jacobi and
Successive Over Relaxation (SOR), in both hardware and software. We compare our
findings with a C++ version of each algorithm. The obtained results show better
performance when compared to existing software versions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kasbah_S/0/1/0/all/0/1&quot;&gt;Safaa Kasbah&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Damaj_I/0/1/0/all/0/1&quot;&gt;Issam Damaj&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Haraty_R/0/1/0/all/0/1&quot;&gt;Ramzi Haraty&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00631">
<title>TAN: Temporal Affine Network for Real-Time Left Ventricle Anatomical Structure Analysis Based on 2D Ultrasound Videos. (arXiv:1904.00631v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1904.00631</link>
<description rdf:parseType="Literal">&lt;p&gt;With superiorities on low cost, portability, and free of radiation,
echocardiogram is a widely used imaging modality for left ventricle (LV)
function quantification. However, automatic LV segmentation and motion tracking
is still a challenging task. In addition to fuzzy border definition, low
contrast, and abounding artifacts on typical ultrasound images, the shape and
size of the LV change significantly in a cardiac cycle. In this work, we
propose a temporal affine network (TAN) to perform image analysis in a warped
image space, where the shape and size variations due to the cardiac motion as
well as other artifacts are largely compensated. Furthermore, we perform three
frequent echocardiogram interpretation tasks simultaneously: standard cardiac
plane recognition, LV landmark detection, and LV segmentation. Instead of using
three networks with one dedicating to each task, we use a multi-task network to
perform three tasks simultaneously. Since three tasks share the same encoder,
the compact network improves the segmentation accuracy with more supervision.
The network is further finetuned with optical flow adjusted annotations to
enhance motion coherence in the segmentation result. Experiments on 1,714 2D
echocardiographic sequences demonstrate that the proposed method achieves
state-of-the-art segmentation accuracy with real-time efficiency.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1&quot;&gt;Sihong Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ma_K/0/1/0/all/0/1&quot;&gt;Kai Ma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zheng_Y/0/1/0/all/0/1&quot;&gt;Yefeng Zheng&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00634">
<title>CFSNet: Toward a Controllable Feature Space for Image Restoration. (arXiv:1904.00634v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1904.00634</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep learning methods have witnessed the great progress in image restoration
with specific metrics (e.g., PSNR, SSIM). However, the perceptual quality of
the restored image is relatively subjective, and it is necessary for users to
control the reconstruction result according to personal preferences or image
characteristics, which cannot be done using existing deterministic networks.
This motivates us to exquisitely design a unified interactive framework for
general image restoration tasks. Under this framework, users can control
continuous transition of different objectives, e.g., the perception-distortion
trade-off of image super-resolution, the trade-off between noise reduction and
detail preservation. We achieve this goal by controlling latent features of the
designed network. To be specific, our proposed framework, named Controllable
Feature Space Network (CFSNet), is entangled by two branches based on different
objectives. Our model can adaptively learn the coupling coefficients of
different layers and channels, which provides finer control of the restored
image quality. Experiments on several typical image restoration tasks fully
validate the effective benefits of the proposed method.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1&quot;&gt;Wei Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guo_R/0/1/0/all/0/1&quot;&gt;Ruiming Guo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tian_Y/0/1/0/all/0/1&quot;&gt;Yapeng Tian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_W/0/1/0/all/0/1&quot;&gt;Wenming Yang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00637">
<title>Single Image Reflection Removal Exploiting Misaligned Training Data and Network Enhancements. (arXiv:1904.00637v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1904.00637</link>
<description rdf:parseType="Literal">&lt;p&gt;Removing undesirable reflections from a single image captured through a glass
window is of practical importance to visual computing systems. Although
state-of-the-art methods can obtain decent results in certain situations,
performance declines significantly when tackling more general real-world cases.
These failures stem from the intrinsic difficulty of single image reflection
removal -- the fundamental ill-posedness of the problem, and the insufficiency
of densely-labeled training data needed for resolving this ambiguity within
learning-based neural network pipelines. In this paper, we address these issues
by exploiting targeted network enhancements and the novel use of misaligned
data. For the former, we augment a baseline network architecture by embedding
context encoding modules that are capable of leveraging high-level contextual
clues to reduce indeterminacy within areas containing strong reflections. For
the latter, we introduce an alignment-invariant loss function that facilitates
exploiting misaligned real-world training data that is much easier to collect.
Experimental results collectively show that our method outperforms the
state-of-the-art with aligned data, and that significant improvements are
possible when using additional misaligned data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wei_K/0/1/0/all/0/1&quot;&gt;Kaixuan Wei&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1&quot;&gt;Jiaolong Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fu_Y/0/1/0/all/0/1&quot;&gt;Ying Fu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wipf_D/0/1/0/all/0/1&quot;&gt;David Wipf&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_H/0/1/0/all/0/1&quot;&gt;Hua Huang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00639">
<title>Multimodal Machine Translation with Embedding Prediction. (arXiv:1904.00639v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1904.00639</link>
<description rdf:parseType="Literal">&lt;p&gt;Multimodal machine translation is an attractive application of neural machine
translation (NMT). It helps computers to deeply understand visual objects and
their relations with natural languages. However, multimodal NMT systems suffer
from a shortage of available training data, resulting in poor performance for
translating rare words. In NMT, pretrained word embeddings have been shown to
improve NMT of low-resource domains, and a search-based approach is proposed to
address the rare word problem. In this study, we effectively combine these two
approaches in the context of multimodal NMT and explore how we can take full
advantage of pretrained word embeddings to better translate rare words. We
report overall performance improvements of 1.24 METEOR and 2.49 BLEU and
achieve an improvement of 7.67 F-score for rare word translation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hirasawa_T/0/1/0/all/0/1&quot;&gt;Tosho Hirasawa&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yamagishi_H/0/1/0/all/0/1&quot;&gt;Hayahide Yamagishi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Matsumura_Y/0/1/0/all/0/1&quot;&gt;Yukio Matsumura&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Komachi_M/0/1/0/all/0/1&quot;&gt;Mamoru Komachi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00641">
<title>Harvesting Visual Objects from Internet Images via Deep Learning Based Objectness Assessment. (arXiv:1904.00641v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1904.00641</link>
<description rdf:parseType="Literal">&lt;p&gt;The collection of internet images has been growing in an astonishing speed.
It is undoubted that these images contain rich visual information that can be
useful in many applications, such as visual media creation and data-driven
image synthesis. In this paper, we focus on the methodologies for building a
visual object database from a collection of internet images. Such database is
built to contain a large number of high-quality visual objects that can help
with various data-driven image applications. Our method is based on dense
proposal generation and objectness-based re-ranking. A novel deep convolutional
neural network is designed for the inference of proposal objectness, the
probability of a proposal containing optimally-located foreground object. In
our work, the objectness is quantitatively measured in regard of completeness
and fullness, reflecting two complementary features of an optimal proposal: a
complete foreground and relatively small background. Our experiments indicate
that object proposals re-ranked according to the output of our network
generally achieve higher performance than those produced by other
state-of-the-art methods. As a concrete example, a database of over 1.2 million
visual objects has been built using the proposed method, and has been
successfully used in various data-driven image applications.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_K/0/1/0/all/0/1&quot;&gt;Kan Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_G/0/1/0/all/0/1&quot;&gt;Guanbin Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1&quot;&gt;Haofeng Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1&quot;&gt;Jianjun Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1&quot;&gt;Yizhou Yu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00646">
<title>Mapping social media attention in Microbiology: Identifying main topics and actors. (arXiv:1904.00646v1 [cs.DL])</title>
<link>http://arxiv.org/abs/1904.00646</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper aims to map and identify topics of interest within the field of
Microbiology and identify the main sources driving such attention. We combine
data from Web of Science and Altmetric.com, a platform which retrieves mentions
to scientific literature from social media and other non-academic communication
outlets. We focus on the dissemination of microbial publications in Twitter,
news media and policy briefs. A two-mode network of social accounts shows
distinctive areas of activity. We identify a cluster of papers mentioned solely
by regional news media. A central area of the network is formed by papers
discussed by the three outlets. A large portion of the network is driven by
Twitter activity. When analyzing top actors contributing to such network, we
observe that more than half of the Twitter accounts are bots, mentioning 32% of
the documents in our dataset. Within news media outlets, there is a
predominance of popular science outlets. With regard to policy briefs, both
international and national bodies are represented. Finally, our topic analysis
shows that the thematic focus of papers mentioned varies by outlet. While news
media cover the wider range of topics, policy briefs are focused on
translational medicine, and bacterial outbreaks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Robinson_Garcia_N/0/1/0/all/0/1&quot;&gt;Nicolas Robinson-Garcia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Arroyo_Machado_W/0/1/0/all/0/1&quot;&gt;Wenceslao Arroyo-Machado&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Torres_Salinas_D/0/1/0/all/0/1&quot;&gt;Daniel Torres-Salinas&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00647">
<title>On Minimizing the Maximum Age-of-Information For Wireless Erasure Channels. (arXiv:1904.00647v1 [cs.IT])</title>
<link>http://arxiv.org/abs/1904.00647</link>
<description rdf:parseType="Literal">&lt;p&gt;Age-of-Information (AoI) is a recently proposed metric for quantifying the
freshness of information from the UE&apos;s perspective in a communication network.
Recently, Kadota et al. [1] have proposed an index-type approximately optimal
scheduling policy for minimizing the average-AoI metric for a downlink
transmission problem. For delay-sensitive applications, including real-time
control of a cyber-physical system, or scheduling URLLC traffic in 5G, it is
essential to have a more stringent uniform control on AoI across all users. In
this paper, we derive an exactly optimal scheduling policy for this problem in
a downlink cellular system with erasure channels. Our proof of optimality
involves an explicit solution to the associated average-cost Bellman Equation,
which might be of independent theoretical interest. We also establish that the
resulting Age-process is positive recurrent under the optimal policy, and has
an exponentially light tail, with the optimal large-deviation exponent.
Finally, motivated by typical applications in small-cell residential networks,
we consider the problem of minimizing the peak-AoI with throughput constraints
to specific UEs, and derive a heuristic policy for this problem. Extensive
numerical simulations have been carried out to compare the efficacy of the
proposed policies with other well-known scheduling policies, such as Randomized
scheduling and Proportional Fair.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Srivastava_A/0/1/0/all/0/1&quot;&gt;Arunabh Srivastava&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sinha_A/0/1/0/all/0/1&quot;&gt;Abhishek Sinha&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jagannathan_K/0/1/0/all/0/1&quot;&gt;Krishna Jagannathan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00648">
<title>Recognizing Musical Entities in User-generated Content. (arXiv:1904.00648v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1904.00648</link>
<description rdf:parseType="Literal">&lt;p&gt;Recognizing Musical Entities is important for Music Information Retrieval
(MIR) since it can improve the performance of several tasks such as music
recommendation, genre classification or artist similarity. However, most entity
recognition systems in the music domain have concentrated on formal texts (e.g.
artists&apos; biographies, encyclopedic articles, etc.), ignoring rich and noisy
user-generated content. In this work, we present a novel method to recognize
musical entities in Twitter content generated by users following a classical
music radio channel. Our approach takes advantage of both formal radio schedule
and users&apos; tweets to improve entity recognition. We instantiate several machine
learning algorithms to perform entity recognition combining task-specific and
corpus-based features. We also show how to improve recognition results by
jointly considering formal and user-generated content
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Porcaro_L/0/1/0/all/0/1&quot;&gt;Lorenzo Porcaro&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Saggion_H/0/1/0/all/0/1&quot;&gt;Horacio Saggion&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00649">
<title>Deep Learning for Large-Scale Traffic-Sign Detection and Recognition. (arXiv:1904.00649v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1904.00649</link>
<description rdf:parseType="Literal">&lt;p&gt;Automatic detection and recognition of traffic signs plays a crucial role in
management of the traffic-sign inventory. It provides accurate and timely way
to manage traffic-sign inventory with a minimal human effort. In the computer
vision community the recognition and detection of traffic signs is a
well-researched problem. A vast majority of existing approaches perform well on
traffic signs needed for advanced drivers-assistance and autonomous systems.
However, this represents a relatively small number of all traffic signs (around
50 categories out of several hundred) and performance on the remaining set of
traffic signs, which are required to eliminate the manual labor in traffic-sign
inventory management, remains an open question. In this paper, we address the
issue of detecting and recognizing a large number of traffic-sign categories
suitable for automating traffic-sign inventory management. We adopt a
convolutional neural network (CNN) approach, the Mask R-CNN, to address the
full pipeline of detection and recognition with automatic end-to-end learning.
We propose several improvements that are evaluated on the detection of traffic
signs and result in an improved overall performance. This approach is applied
to detection of 200 traffic-sign categories represented in our novel dataset.
Results are reported on highly challenging traffic-sign categories that have
not yet been considered in previous works. We provide comprehensive analysis of
the deep learning method for the detection of traffic signs with large
intra-category appearance variation and show below 3% error rates with the
proposed approach, which is sufficient for deployment in practical applications
of traffic-sign inventory management.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tabernik_D/0/1/0/all/0/1&quot;&gt;Domen Tabernik&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Skocaj_D/0/1/0/all/0/1&quot;&gt;Danijel Sko&amp;#x10d;aj&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00655">
<title>Transfer Learning for Clinical Time Series Analysis using Deep Neural Networks. (arXiv:1904.00655v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1904.00655</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep neural networks have shown promising results for various clinical
prediction tasks. However, training deep networks such as those based on
Recurrent Neural Networks (RNNs) requires large labeled data, significant
hyper-parameter tuning effort and expertise, and high computational resources.
In this work, we investigate as to what extent can transfer learning address
these issues when using deep RNNs to model multivariate clinical time series.
We consider two scenarios for transfer learning using RNNs: i)
domain-adaptation, i.e., leveraging a deep RNN - namely, TimeNet - pre-trained
for feature extraction on time series from diverse domains, and adapting it for
feature extraction and subsequent target tasks in healthcare domain, ii)
task-adaptation, i.e., pre-training a deep RNN - namely, HealthNet - on diverse
tasks in healthcare domain, and adapting it to new target tasks in the same
domain. We evaluate the above approaches on publicly available MIMIC-III
benchmark dataset, and demonstrate that (a) computationally-efficient linear
models trained using features extracted via pre-trained RNNs outperform or, in
the worst case, perform as well as deep RNNs and statistical hand-crafted
features based models trained specifically for target task; (b) models obtained
by adapting pre-trained models for target tasks are significantly more robust
to the size of labeled data compared to task-specific RNNs, while also being
computationally efficient. We, therefore, conclude that pre-trained deep models
like TimeNet and HealthNet allow leveraging the advantages of deep learning for
clinical time series analysis tasks, while also minimize dependence on
hand-crafted features, deal robustly with scarce labeled training data
scenarios without overfitting, as well as reduce dependence on expertise and
resources required to train deep networks from scratch.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gupta_P/0/1/0/all/0/1&quot;&gt;Priyanka Gupta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Malhotra_P/0/1/0/all/0/1&quot;&gt;Pankaj Malhotra&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Narwariya_J/0/1/0/all/0/1&quot;&gt;Jyoti Narwariya&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vig_L/0/1/0/all/0/1&quot;&gt;Lovekesh Vig&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shroff_G/0/1/0/all/0/1&quot;&gt;Gautam Shroff&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00661">
<title>Data of low quality is better than no data. (arXiv:1904.00661v1 [cs.SE])</title>
<link>http://arxiv.org/abs/1904.00661</link>
<description rdf:parseType="Literal">&lt;p&gt;Missing data is not uncommon in empirical software engineering research but a
common way to handle it is to remove data completely. We believe that this is
wasteful and should not be done out of habit. This paper aims to present a
typical case in empirical software engineering research: Analyzing data,
consisting of missingness, which has been collected and classified by others.
By transferring empirical analysis methods from other disciplines, we here
introduce the reader to approaches suitable for analyzing empirical software
engineering data. We present a case study where we contrast with previous
studies&apos; methodologies (in effort estimation). Using principled Bayesian data
analysis, together with state of art imputation techniques, we show how missing
data and Bayesian data analysis can be considered a good match. The results
show that by using low-quality data, instead of throwing data away, we still
gain a better understanding of the resulting analysis if we are prepared to
embrace uncertainty. Inferences can become weaker but, we argue, this is how it
should be. Empirical software engineering research should make use of more
state of art missing data techniques, not throw data away, and lean towards
Bayesian data analysis in order to get a more nuanced view of the challenges we
investigate.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Torkar_R/0/1/0/all/0/1&quot;&gt;Richard Torkar&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00664">
<title>Learning Content-Weighted Deep Image Compression. (arXiv:1904.00664v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1904.00664</link>
<description rdf:parseType="Literal">&lt;p&gt;Learning-based lossy image compression usually involves the joint
optimization of rate-distortion performance. Most existing methods adopt
spatially invariant bit length allocation and incorporate discrete entropy
approximation to constrain compression rate. Nonetheless, the information
content is spatially variant, where the regions with complex and salient
structures generally are more essential to image compression. Taking the
spatial variation of image content into account, this paper presents a
content-weighted encoder-decoder model, which involves an importance map subnet
to produce the importance mask for locally adaptive bit rate allocation.
Consequently, the summation of importance mask can thus be utilized as an
alternative of entropy estimation for compression rate control. Furthermore,
the quantized representations of the learned code and importance map are still
spatially dependent, which can be losslessly compressed using arithmetic
coding. To compress the codes effectively and efficiently, we propose a trimmed
convolutional network to predict the conditional probability of quantized
codes. Experiments show that the proposed method can produce visually much
better results, and performs favorably in comparison with deep and traditional
lossy image compression approaches.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1&quot;&gt;Mu Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zuo_W/0/1/0/all/0/1&quot;&gt;Wangmeng Zuo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gu_S/0/1/0/all/0/1&quot;&gt;Shuhang Gu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+You_J/0/1/0/all/0/1&quot;&gt;Jane You&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1&quot;&gt;David Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00665">
<title>Learn2MAC: Online Learning Multiple Access for URLLC Applications. (arXiv:1904.00665v1 [cs.NI])</title>
<link>http://arxiv.org/abs/1904.00665</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper addresses a fundamental limitation of previous random access
protocols, their lack of latency performance guarantees. We consider $K$ IoT
transmitters competing for uplink resources and we design a fully distributed
protocol for deciding how they access the medium. Specifically, each
transmitter restricts decisions to a locally-generated dictionary of
transmission patterns. At the beginning of a frame, pattern $i$ is chosen with
probability $p^i$, and an online exponentiated gradient algorithm is used to
adjust this probability distribution. The performance of the proposed scheme is
showcased in simulations, where it is compared with a baseline random access
protocol. Simulation results show that (a) the proposed scheme achieves good
latent throughput performance and low energy consumption, while (b) it
outperforms by a big margin random transmissions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Destounis_A/0/1/0/all/0/1&quot;&gt;Apostolos Destounis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tsilimantos_D/0/1/0/all/0/1&quot;&gt;Dimitrios Tsilimantos&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Debbah_M/0/1/0/all/0/1&quot;&gt;M&amp;#xe9;rouane Debbah&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Paschos_G/0/1/0/all/0/1&quot;&gt;Georgios S. Paschos&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00669">
<title>Syntactic Interchangeability in Word Embedding Models. (arXiv:1904.00669v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1904.00669</link>
<description rdf:parseType="Literal">&lt;p&gt;Nearest neighbors in word embedding models are commonly observed to be
semantically similar, but the relations between them can vary greatly. We
investigate the extent to which word embedding models preserve syntactic
interchangeability, as reflected by distances between word vectors, and the
effect of hyper-parameters---context window size in particular. We use part of
speech (POS) as a proxy for syntactic interchangeability, as generally
speaking, words with the same POS are syntactically valid in the same contexts.
We also investigate the relationship between interchangeability and similarity
as judged by commonly-used word similarity benchmarks, and correlate the result
with the performance of word embedding models on these benchmarks. Our results
will inform future research and applications in the selection of word embedding
model, suggesting a principle for an appropriate selection of the context
window size parameter depending on the use-case.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hershcovich_D/0/1/0/all/0/1&quot;&gt;Daniel Hershcovich&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Toledo_A/0/1/0/all/0/1&quot;&gt;Assaf Toledo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Halfon_A/0/1/0/all/0/1&quot;&gt;Alon Halfon&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Slonim_N/0/1/0/all/0/1&quot;&gt;Noam Slonim&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00670">
<title>Robust Optimisation Monte Carlo. (arXiv:1904.00670v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1904.00670</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper is on Bayesian inference for parametric statistical models that
are implicitly defined by a stochastic simulator which specifies how data is
generated. While exact sampling is possible, evaluating the likelihood function
is typically prohibitively expensive. Approximate Bayesian Computation (ABC) is
a framework to perform approximate inference in such situations. While basic
ABC algorithms are widely applicable, they are notoriously slow and much
research has focused on increasing their efficiency. Optimisation Monte Carlo
(OMC) has recently been proposed as an efficient and embarrassingly parallel
method that leverages optimisation to accelerate the inference. In this paper,
we demonstrate a previously unrecognised important failure mode of OMC: It
generates strongly overconfident approximations by collapsing regions of
similar or near-constant posterior density into a single point. We propose an
efficient, robust generalisation of OMC that corrects this. It makes fewer
assumptions, retains the main benefits of OMC, and can be performed either as
part of OMC or entirely as post-processing. We demonstrate the effectiveness of
the proposed Robust OMC on toy examples and tasks in inverse-graphics where we
perform Bayesian inference with a complex image renderer.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ikonomov_B/0/1/0/all/0/1&quot;&gt;Borislav Ikonomov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Gutmann_M/0/1/0/all/0/1&quot;&gt;Michael U. Gutmann&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00671">
<title>Application-Agnostic Offloading of Packet Processing. (arXiv:1904.00671v1 [cs.NI])</title>
<link>http://arxiv.org/abs/1904.00671</link>
<description rdf:parseType="Literal">&lt;p&gt;As network speed increases, servers struggle to serve all requests directed
at them. This challenge is rooted in a partitioned data path where the split
between the kernel space networking stack and user space applications induces
overheads. To address this challenge, we propose Santa, a new architecture to
optimize the data path by enabling server applications to partially offload
packet processing to a generic rule processor. We exemplify Santa by showing
how it can drastically accelerate kernel-based packet processing - a currently
neglected domain. Our evaluation of a broad class of applications, namely DNS,
Memcached, and HTTP, highlights that Santa can substantially improve the server
performance by a factor of 5.5, 2.1, and 2.5, respectively.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hohlfeld_O/0/1/0/all/0/1&quot;&gt;Oliver Hohlfeld&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Reelfs_H/0/1/0/all/0/1&quot;&gt;Helge Reelfs&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ruth_J/0/1/0/all/0/1&quot;&gt;Jan R&amp;#xfc;th&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schmidt_F/0/1/0/all/0/1&quot;&gt;Florian Schmidt&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zimmermann_T/0/1/0/all/0/1&quot;&gt;Torsten Zimmermann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hiller_J/0/1/0/all/0/1&quot;&gt;Jens Hiller&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wehrle_K/0/1/0/all/0/1&quot;&gt;Klaus Wehrle&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00672">
<title>Enhancing the long-term performance of recommender system. (arXiv:1904.00672v1 [physics.soc-ph])</title>
<link>http://arxiv.org/abs/1904.00672</link>
<description rdf:parseType="Literal">&lt;p&gt;Recommender system is a critically important tool in online commercial system
and provide users with personalized recommendation on items. So far, numerous
recommendation algorithms have been made to further improve the recommendation
performance in a single-step recommendation, while the long-term recommendation
performance is neglected. In this paper, we proposed an approach called
Adjustment of Recommendation List (ARL) to enhance the long-term recommendation
accuracy. In order to observe the long-term accuracy, we developed an evolution
model of network to simulate the interaction between the recommender system and
user&apos;s behaviour. The result shows that not only long-term recommendation
accuracy can be enhanced significantly but the diversity of item in online
system maintains healthy. Notably, an optimal parameter n* of ARL existed in
long-term recommendation, indicating that there is a trade-off between keeping
diversity of item and user&apos;s preference to maximize the long-term
recommendation accuracy. Finally, we confirmed that the optimal parameter n* is
stable during evolving network, which reveals the robustness of ARL method.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Xue_L/0/1/0/all/0/1&quot;&gt;Leyang Xue&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Zhang_P/0/1/0/all/0/1&quot;&gt;Peng Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Zeng_A/0/1/0/all/0/1&quot;&gt;An Zeng&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00674">
<title>Deep Built-Structure Counting in Satellite Imagery Using Attention Based Re-Weighting. (arXiv:1904.00674v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1904.00674</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we attempt to address the challenging problem of counting
built-structures in the satellite imagery. Building density is a more accurate
estimate of the population density, urban area expansion and its impact on the
environment, than the built-up area segmentation. However, building shape
variances, overlapping boundaries, and variant densities make this a complex
task. To tackle this difficult problem, we propose a deep learning based
regression technique for counting built-structures in satellite imagery. Our
proposed framework intelligently combines features from different regions of
satellite image using attention based re-weighting techniques. Multiple
parallel convolutional networks are designed to capture information at
different granulates. These features are combined into the FusionNet which is
trained to weigh features from different granularity differently, allowing us
to predict a precise building count. To train and evaluate the proposed method,
we put forward a new large-scale and challenging built-structure-count dataset.
Our dataset is constructed by collecting satellite imagery from diverse
geographical areas (planes, urban centers, deserts, etc.,) across the globe
(Asia, Europe, North America, and Africa) and captures the wide density of
built structures. Detailed experimental results and analysis validate the
proposed technique. FusionNet has Mean Absolute Error of 3.65 and R-squared
measure of 88% over the testing data. Finally, we perform the test on the 274:3
? 103 m2 of the unseen region, with the error of 19 buildings off the 656
buildings in that area.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shakeel_A/0/1/0/all/0/1&quot;&gt;Anza Shakeel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sultani_W/0/1/0/all/0/1&quot;&gt;Waqas Sultani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ali_M/0/1/0/all/0/1&quot;&gt;Mohsen Ali&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00676">
<title>Ranking and Selecting Multi-Hop Knowledge Paths to Better Predict Human Needs. (arXiv:1904.00676v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1904.00676</link>
<description rdf:parseType="Literal">&lt;p&gt;To make machines better understand sentiments, research needs to move from
polarity identification to understanding the reasons that underlie the
expression of sentiment. Categorizing the goals or needs of humans is one way
to explain the expression of sentiment in text. Humans are good at
understanding situations described in natural language and can easily connect
them to the character&apos;s psychological needs using commonsense knowledge. We
present a novel method to extract, rank, filter and select multi-hop relation
paths from a commonsense knowledge resource to interpret the expression of
sentiment in terms of their underlying human needs. We efficiently integrate
the acquired knowledge paths in a neural model that interfaces context
representations with knowledge using a gated attention mechanism. We assess the
model&apos;s performance on a recently published dataset for categorizing human
needs. Selectively integrating knowledge paths boosts performance and
establishes a new state-of-the-art. Our model offers interpretability through
the learned attention map over commonsense knowledge paths. Human evaluation
highlights the relevance of the encoded knowledge.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Paul_D/0/1/0/all/0/1&quot;&gt;Debjit Paul&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Frank_A/0/1/0/all/0/1&quot;&gt;Anette Frank&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00680">
<title>End-to-End Time-Lapse Video Synthesis from a Single Outdoor Image. (arXiv:1904.00680v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1904.00680</link>
<description rdf:parseType="Literal">&lt;p&gt;Time-lapse videos usually contain visually appealing content but are often
difficult and costly to create. In this paper, we present an end-to-end
solution to synthesize a time-lapse video from a single outdoor image using
deep neural networks. Our key idea is to train a conditional generative
adversarial network based on existing datasets of time-lapse videos and image
sequences. We propose a multi-frame joint conditional generation framework to
effectively learn the correlation between the illumination change of an outdoor
scene and the time of the day. We further present a multi-domain training
scheme for robust training of our generative models from two datasets with
different distributions and missing timestamp labels. Compared to alternative
time-lapse video synthesis algorithms, our method uses the timestamp as the
control variable and does not require a reference video to guide the synthesis
of the final output. We conduct ablation studies to validate our algorithm and
compare with state-of-the-art techniques both qualitatively and quantitatively.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nam_S/0/1/0/all/0/1&quot;&gt;Seonghyeon Nam&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ma_C/0/1/0/all/0/1&quot;&gt;Chongyang Ma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chai_M/0/1/0/all/0/1&quot;&gt;Menglei Chai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Brendel_W/0/1/0/all/0/1&quot;&gt;William Brendel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_N/0/1/0/all/0/1&quot;&gt;Ning Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1&quot;&gt;Seon Joo Kim&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00682">
<title>Standardized Assessment of Automatic Segmentation of White Matter Hyperintensities and Results of the WMH Segmentation Challenge. (arXiv:1904.00682v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1904.00682</link>
<description rdf:parseType="Literal">&lt;p&gt;Quantification of cerebral white matter hyperintensities (WMH) of presumed
vascular origin is of key importance in many neurological research studies.
Currently, measurements are often still obtained from manual segmentations on
brain MR images, which is a laborious procedure. Automatic WMH segmentation
methods exist, but a standardized comparison of the performance of such methods
is lacking. We organized a scientific challenge, in which developers could
evaluate their method on a standardized multi-center/-scanner image dataset,
giving an objective comparison: the WMH Segmentation Challenge
(https://wmh.isi.uu.nl/).
&lt;/p&gt;
&lt;p&gt;Sixty T1+FLAIR images from three MR scanners were released with manual WMH
segmentations for training. A test set of 110 images from five MR scanners was
used for evaluation. Segmentation methods had to be containerized and submitted
to the challenge organizers. Five evaluation metrics were used to rank the
methods: (1) Dice similarity coefficient, (2) modified Hausdorff distance (95th
percentile), (3) absolute log-transformed volume difference, (4) sensitivity
for detecting individual lesions, and (5) F1-score for individual lesions.
Additionally, methods were ranked on their inter-scanner robustness.
&lt;/p&gt;
&lt;p&gt;Twenty participants submitted their method for evaluation. This paper
provides a detailed analysis of the results. In brief, there is a cluster of
four methods that rank significantly better than the other methods, with one
clear winner. The inter-scanner robustness ranking shows that not all methods
generalize to unseen scanners.
&lt;/p&gt;
&lt;p&gt;The challenge remains open for future submissions and provides a public
platform for method evaluation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kuijf_H/0/1/0/all/0/1&quot;&gt;Hugo J. Kuijf&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Biesbroek_J/0/1/0/all/0/1&quot;&gt;J. Matthijs Biesbroek&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bresser_J/0/1/0/all/0/1&quot;&gt;Jeroen de Bresser&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Heinen_R/0/1/0/all/0/1&quot;&gt;Rutger Heinen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Andermatt_S/0/1/0/all/0/1&quot;&gt;Simon Andermatt&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bento_M/0/1/0/all/0/1&quot;&gt;Mariana Bento&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Berseth_M/0/1/0/all/0/1&quot;&gt;Matt Berseth&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Belyaev_M/0/1/0/all/0/1&quot;&gt;Mikhail Belyaev&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cardoso_M/0/1/0/all/0/1&quot;&gt;M. Jorge Cardoso&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Casamitjana_A/0/1/0/all/0/1&quot;&gt;Adri&amp;#xe0; Casamitjana&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Collins_D/0/1/0/all/0/1&quot;&gt;D. Louis Collins&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dadar_M/0/1/0/all/0/1&quot;&gt;Mahsa Dadar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Georgiou_A/0/1/0/all/0/1&quot;&gt;Achilleas Georgiou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ghafoorian_M/0/1/0/all/0/1&quot;&gt;Mohsen Ghafoorian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jin_D/0/1/0/all/0/1&quot;&gt;Dakai Jin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khademi_A/0/1/0/all/0/1&quot;&gt;April Khademi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Knight_J/0/1/0/all/0/1&quot;&gt;Jesse Knight&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1&quot;&gt;Hongwei Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Llado_X/0/1/0/all/0/1&quot;&gt;Xavier Llad&amp;#xf3;&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Luna_M/0/1/0/all/0/1&quot;&gt;Miguel Luna&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mahmood_Q/0/1/0/all/0/1&quot;&gt;Qaiser Mahmood&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+McKinley_R/0/1/0/all/0/1&quot;&gt;Richard McKinley&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mehrtash_A/0/1/0/all/0/1&quot;&gt;Alireza Mehrtash&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ourselin_S/0/1/0/all/0/1&quot;&gt;S&amp;#xe9;bastien Ourselin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Park_B/0/1/0/all/0/1&quot;&gt;Bo-yong Park&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Park_H/0/1/0/all/0/1&quot;&gt;Hyunjin Park&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Park_S/0/1/0/all/0/1&quot;&gt;Sang Hyun Park&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pezold_S/0/1/0/all/0/1&quot;&gt;Simon Pezold&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Puybareau_E/0/1/0/all/0/1&quot;&gt;Elodie Puybareau&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rittner_L/0/1/0/all/0/1&quot;&gt;Leticia Rittner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sudre_C/0/1/0/all/0/1&quot;&gt;Carole H. Sudre&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Valverde_S/0/1/0/all/0/1&quot;&gt;Sergi Valverde&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vilaplana_V/0/1/0/all/0/1&quot;&gt;Ver&amp;#xf3;nica Vilaplana&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wiest_R/0/1/0/all/0/1&quot;&gt;Roland Wiest&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1&quot;&gt;Yongchao Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1&quot;&gt;Ziyue Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zeng_G/0/1/0/all/0/1&quot;&gt;Guodong Zeng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1&quot;&gt;Jianguo Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zheng_G/0/1/0/all/0/1&quot;&gt;Guoyan Zheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1&quot;&gt;Christopher Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Flier_W/0/1/0/all/0/1&quot;&gt;Wiesje van der Flier&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Barkhof_F/0/1/0/all/0/1&quot;&gt;Frederik Barkhof&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Viergever_M/0/1/0/all/0/1&quot;&gt;Max A. Viergever&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Biessels_G/0/1/0/all/0/1&quot;&gt;Geert Jan Biessels&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00685">
<title>Secure OTA Software Updates in Connected Vehicles: A survey. (arXiv:1904.00685v1 [cs.CR])</title>
<link>http://arxiv.org/abs/1904.00685</link>
<description rdf:parseType="Literal">&lt;p&gt;This survey highlights and discusses remote OTA software updates in the
automotive sector, mainly from the security perspective. In particular, the
major objective of this survey is to provide a comprehensive and structured
outline of various research directions and approaches in OTA update
technologies in vehicles. At first, we discuss the connected car technology and
then integrate the relationship of remote OTA update features with the
connected car. We also present the benefits of remote OTA updates for cars
along with relevant statistics. Then, we emphasize on the security challenges
and requirements of remote OTA updates along with use cases and standard road
safety regulations followed in different countries. We also provide for a
classification of the existing works in literature that deal with implementing
different secured techniques for remote OTA updates in vehicles. We further
provide an analytical discussion on the present scenario of remote OTA updates
with respect to care manufacturers. Finally, we identify possible future
research directions of remote OTA updates for automobiles, particularly in the
area of security.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Halder_S/0/1/0/all/0/1&quot;&gt;Subir Halder&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ghosal_A/0/1/0/all/0/1&quot;&gt;Amrita Ghosal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Conti_M/0/1/0/all/0/1&quot;&gt;Mauro Conti&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00687">
<title>On the Power and Limitations of Random Features for Understanding Neural Networks. (arXiv:1904.00687v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1904.00687</link>
<description rdf:parseType="Literal">&lt;p&gt;Recently, a spate of papers have provided positive theoretical results for
training over-parameterized neural networks (where the network size is larger
than what is needed to achieve low error). The key insight is that with
sufficient over-parameterization, gradient-based methods will implicitly leave
some components of the network relatively unchanged, so the optimization
dynamics will behave as if those components are essentially fixed at their
initial random values. In fact, fixing these explicitly leads to the well-known
approach of learning with random features. In other words, these techniques
imply that we can successfully learn with neural networks, whenever we can
successfully learn with random features. In this paper, we first review these
techniques, providing a simple and self-contained analysis for one-hidden-layer
networks. We then argue that despite the impressive positive results, random
feature approaches are also inherently limited in what they can explain. In
particular, we rigorously show that random features cannot be used to learn
even a single ReLU neuron with standard Gaussian inputs, unless the network
size (or magnitude of the weights) is exponentially large. Since a single
neuron is learnable with gradient-based methods, we conclude that we are still
far from a satisfying general explanation for the empirical success of neural
networks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yehudai_G/0/1/0/all/0/1&quot;&gt;Gilad Yehudai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shamir_O/0/1/0/all/0/1&quot;&gt;Ohad Shamir&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00688">
<title>Automatic text summarization: What has been done and what has to be done. (arXiv:1904.00688v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1904.00688</link>
<description rdf:parseType="Literal">&lt;p&gt;Summaries are important when it comes to process huge amounts of information.
Their most important benefit is saving time, which we do not have much
nowadays. Therefore, a summary must be short, representative and readable.
Generating summaries automatically can be beneficial for humans, since it can
save time and help selecting relevant documents.
&lt;/p&gt;
&lt;p&gt;Automatic summarization and, in particular, Automatic text summarization
(ATS) is not a new research field; It was known since the 50s. Since then,
researchers have been active to find the perfect summarization method.
&lt;/p&gt;
&lt;p&gt;In this article, we will discuss different works in automatic summarization,
especially the recent ones. We will present some problems and limits which
prevent works to move forward. Most of these challenges are much more related
to the nature of processed languages. These challenges are interesting for
academics and developers, as a path to follow in this field.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Aries_A/0/1/0/all/0/1&quot;&gt;Abdelkrime Aries&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zegour_D/0/1/0/all/0/1&quot;&gt;Djamel eddine Zegour&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hidouci_W/0/1/0/all/0/1&quot;&gt;Walid Khaled Hidouci&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00689">
<title>Defending against adversarial attacks by randomized diversification. (arXiv:1904.00689v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1904.00689</link>
<description rdf:parseType="Literal">&lt;p&gt;The vulnerability of machine learning systems to adversarial attacks
questions their usage in many applications. In this paper, we propose a
randomized diversification as a defense strategy. We introduce a multi-channel
architecture in a gray-box scenario, which assumes that the architecture of the
classifier and the training data set are known to the attacker. The attacker
does not only have access to a secret key and to the internal states of the
system at the test time. The defender processes an input in multiple channels.
Each channel introduces its own randomization in a special transform domain
based on a secret key shared between the training and testing stages. Such a
transform based randomization with a shared key preserves the gradients in
key-defined sub-spaces for the defender but it prevents gradient back
propagation and the creation of various bypass systems for the attacker. An
additional benefit of multi-channel randomization is the aggregation that fuses
soft-outputs from all channels, thus increasing the reliability of the final
score. The sharing of a secret key creates an information advantage to the
defender. Experimental evaluation demonstrates an increased robustness of the
proposed method to a number of known state-of-the-art attacks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Taran_O/0/1/0/all/0/1&quot;&gt;Olga Taran&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rezaeifar_S/0/1/0/all/0/1&quot;&gt;Shideh Rezaeifar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Holotyak_T/0/1/0/all/0/1&quot;&gt;Taras Holotyak&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Voloshynovskiy_S/0/1/0/all/0/1&quot;&gt;Slava Voloshynovskiy&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00690">
<title>Customer churn prediction in telecom using machine learning and social network analysis in big data platform. (arXiv:1904.00690v1 [cs.CY])</title>
<link>http://arxiv.org/abs/1904.00690</link>
<description rdf:parseType="Literal">&lt;p&gt;Customer churn is a major problem and one of the most important concerns for
large companies. Due to the direct effect on the revenues of the companies,
especially in the telecom field, companies are seeking to develop means to
predict potential customer to churn. Therefore, finding factors that increase
customer churn is important to take necessary actions to reduce this churn. The
main contribution of our work is to develop a churn prediction model which
assists telecom operators to predict customers who are most likely subject to
churn. The model developed in this work uses machine learning techniques on big
data platform and builds a new way of features&apos; engineering and selection. In
order to measure the performance of the model, the Area Under Curve (AUC)
standard measure is adopted, and the AUC value obtained is 93.3%. Another main
contribution is to use customer social network in the prediction model by
extracting Social Network Analysis (SNA) features. The use of SNA enhanced the
performance of the model from 84 to 93.3% against AUC standard. The model was
prepared and tested through Spark environment by working on a large dataset
created by transforming big raw data provided by SyriaTel telecom company. The
dataset contained all customers&apos; information over 9 months, and was used to
train, test, and evaluate the system at SyriaTel. The model experimented four
algorithms: Decision Tree, Random Forest, Gradient Boosted Machine Tree &quot;GBM&quot;
and Extreme Gradient Boosting &quot;XGBOOST&quot;. However, the best results were
obtained by applying XGBOOST algorithm. This algorithm was used for
classification in this churn predictive model.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ahmad_A/0/1/0/all/0/1&quot;&gt;Abdelrahim Kasem Ahmad&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jafar_A/0/1/0/all/0/1&quot;&gt;Assef Jafar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Aljoumaa_K/0/1/0/all/0/1&quot;&gt;Kadan Aljoumaa&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00691">
<title>Human Values and Attitudes towards Vaccination in Social Media. (arXiv:1904.00691v1 [cs.CY])</title>
<link>http://arxiv.org/abs/1904.00691</link>
<description rdf:parseType="Literal">&lt;p&gt;Psychological, political, cultural, and even societal factors are entangled
in the reasoning and decision-making process towards vaccination, rendering
vaccine hesitancy a complex issue. Here, administering a series of surveys via
a Facebook-hosted application, we study the worldviews of people that &quot;Liked&quot;
supportive or vaccine resilient Facebook Pages. In particular, we assess
differences in political viewpoints, moral values, personality traits, and
general interests, finding that those sceptical about vaccination, appear to
trust less the government, are less agreeable, while they are emphasising more
on anti-authoritarian values. Exploring the differences in moral narratives as
expressed in the linguistic descriptions of the Facebook Pages, we see that
pages that defend vaccines prioritise the value of the family while the vaccine
hesitancy pages are focusing on the value of freedom. Finally, creating
embeddings based on the health-related likes on Facebook Pages, we explore
common, latent interests of vaccine-hesitant people, showing a strong
preference for natural cures. This exploratory analysis aims at exploring the
potentials of a social media platform to act as a sensing tool, providing
researchers and policymakers with insights drawn from the digital traces, that
can help design communication campaigns that build confidence, based on the
values that also appeal to the socio-moral criteria of people.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kalimeri_K/0/1/0/all/0/1&quot;&gt;Kyriaki Kalimeri&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Beiro_M/0/1/0/all/0/1&quot;&gt;Mariano Beiro&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Urbinati_A/0/1/0/all/0/1&quot;&gt;Alessandra Urbinati&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bonanomi_A/0/1/0/all/0/1&quot;&gt;Andrea Bonanomi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rosino_A/0/1/0/all/0/1&quot;&gt;Alessandro Rosino&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cattuto_C/0/1/0/all/0/1&quot;&gt;Ciro Cattuto&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00692">
<title>Fully Dynamic Data Structures for Interval Coloring. (arXiv:1904.00692v1 [cs.DS])</title>
<link>http://arxiv.org/abs/1904.00692</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider the dynamic graph coloring problem restricted to the class of
interval graphs. At each update step the algorithm is presented with an
interval to be colored, or a previously colored interval to delete. The goal of
the algorithm is to efficiently maintain a proper coloring of the intervals
with as few colors as possible by an online algorithm. In the incremental
model, each update step presents the algorithm with an interval to be colored.
The problem is closely connected to the online vertex coloring problem of
interval graphs for which the Kierstead-Trotter (KT) algorithm achieves the
best possible competitive ratio. We first show that a sub-quadratic time direct
implementation of the KT-algorithm is unlikely to exist conditioned on the
correctness of the Online Boolean Matrix Vector multiplication conjecture due
to Henzinger et al. \cite{DBLP:conf/stoc/HenzingerKNS15}. We then design an
incremental algorithm that is subtly different from the KT-algorithm and uses
at most $3 \omega - 2$ colors, where $\omega$ is the maximum clique in the
interval graph associated with the set of intervals. Our incremental data
structure maintains a proper coloring in amortized $O(\log n + \Delta)$ update
time where $n$ is the total number of intervals inserted and $\Delta$ is the
maximum degree of a vertex in the interval graph. We then consider the fully
dynamic framework involving insertions and deletions. On each update, our aim
is to maintain a $3 \omega - 2$ coloring of the remaining set of intervals,
where $\omega$ is the maximum clique in the interval graph associated with the
remaining set of intervals. Our fully dynamic algorithm supports insertion of
an interval in $O(\log n + \Delta \log \omega)$ worst case update time and
deletion of an interval in $O(\Delta^2 \log n)$ worst case update time.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+J_G/0/1/0/all/0/1&quot;&gt;Girish Raguvir J&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kashyop_M/0/1/0/all/0/1&quot;&gt;Manas Jyoti Kashyop&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Narayanaswamy_N/0/1/0/all/0/1&quot;&gt;N. S. Narayanaswamy&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00696">
<title>Dance with Flow: Two-in-One Stream Action Detection. (arXiv:1904.00696v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1904.00696</link>
<description rdf:parseType="Literal">&lt;p&gt;The goal of this paper is to detect the spatio-temporal extent of an action.
The two-stream detection network based on RGB and flow provides
state-of-the-art accuracy at the expense of a large model-size and heavy
computation. We propose to embed RGB and optical-flow into a single two-in-one
stream network with new layers. A motion condition layer extracts motion
information from flow images, which is leveraged by the motion modulation layer
to generate transformation parameters for modulating the low-level RGB
features. The method is easily embedded in existing appearance- or two-stream
action detection networks, and trained end-to-end. Experiments demonstrate that
leveraging the motion condition to modulate RGB features improves detection
accuracy. With only half the computation and parameters of the state-of-the-art
two-stream methods, our two-in-one stream still achieves impressive results on
UCF101-24, UCFSports and J-HMDB.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_J/0/1/0/all/0/1&quot;&gt;Jiaojiao Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Snoek_C/0/1/0/all/0/1&quot;&gt;Cees G.M. Snoek&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00699">
<title>JSIS3D: Joint Semantic-Instance Segmentation of 3D Point Clouds with Multi-Task Pointwise Networks and Multi-Value Conditional Random Fields. (arXiv:1904.00699v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1904.00699</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep learning techniques have become the to-go models for most vision-related
tasks on 2D images. However, their power has not been fully realised on several
tasks in 3D space, e.g., 3D scene understanding. In this work, we jointly
address the problems of semantic and instance segmentation of 3D point clouds.
Specifically, we develop a multi-task pointwise network that simultaneously
performs two tasks: predicting the semantic classes of 3D points and embedding
the points into high-dimensional vectors so that points of the same object
instance are represented by similar embeddings. We then propose a multi-value
conditional random field model to incorporate the semantic and instance labels
and formulate the problem of semantic and instance segmentation as jointly
optimising labels in the field model. The proposed method is thoroughly
evaluated and compared with existing methods on different indoor scene datasets
including S3DIS and SceneNN. Experimental results showed the robustness of the
proposed joint semantic-instance segmentation scheme over its single
components. Our method also achieved state-of-the-art performance on semantic
segmentation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pham_Q/0/1/0/all/0/1&quot;&gt;Quang-Hieu Pham&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nguyen_D/0/1/0/all/0/1&quot;&gt;Duc Thanh Nguyen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hua_B/0/1/0/all/0/1&quot;&gt;Binh-Son Hua&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Roig_G/0/1/0/all/0/1&quot;&gt;Gemma Roig&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yeung_S/0/1/0/all/0/1&quot;&gt;Sai-Kit Yeung&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00702">
<title>Intersection multiplicity of a sparse curve and a low-degree curve. (arXiv:1904.00702v1 [math.AG])</title>
<link>http://arxiv.org/abs/1904.00702</link>
<description rdf:parseType="Literal">&lt;p&gt;Let $F(x, y) \in \mathbb{C}[x,y]$ be a polynomial of degree $d$ and let
$G(x,y) \in \mathbb{C}[x,y]$ be a polynomial with $t$ monomials. We want to
estimate the maximal multiplicity of a solution of the system $F(x,y) = G(x,y)
= 0$. Our main result is that the multiplicity of any isolated solution $(a,b)
\in \mathbb{C}^2$ with nonzero coordinates is no greater than
$\frac{5}{2}d^2t^2$. We ask whether this intersection multiplicity can be
polynomially bounded in the number of monomials of $F$ and $G$, and we briefly
review some connections between sparse polynomials and algebraic complexity
theory.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Koiran_P/0/1/0/all/0/1&quot;&gt;Pascal Koiran&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Skomra_M/0/1/0/all/0/1&quot;&gt;Mateusz Skomra&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00704">
<title>Getting the Most Out of Your VNFs: Flexible Assignment of Service Priorities in 5G. (arXiv:1904.00704v1 [cs.NI])</title>
<link>http://arxiv.org/abs/1904.00704</link>
<description rdf:parseType="Literal">&lt;p&gt;Through their computational and forwarding capabilities, 5G networks can
support multiple vertical services. Such services may include several common
virtual (network) functions (VNFs), which could be shared to increase resource
efficiency. In this paper, we focus on the seldom studied VNF-sharing problem,
and decide (i) whether sharing a VNF instance is possible/beneficial or not,
(ii) how to scale virtual machines hosting the VNFs to share, and (iii) the
priorities of the different services sharing the same VNF. These decisions are
made with the aim to minimize the mobile operator&apos;s costs while meeting the
verticals&apos; performance requirements. Importantly, we show that the
aforementioned priorities should not be determined a priori on a per-service
basis, rather they should change across VNFs since such additional flexibility
allows for more efficient solutions. We then present an effective methodology
called FlexShare, enabling near-optimal VNF-sharing decisions in polynomial
time. Our performance evaluation, using real-world VNF graphs, confirms the
effectiveness of our approach, which consistently outperforms baseline
solutions using per-service priorities.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Malandrino_F/0/1/0/all/0/1&quot;&gt;Francesco Malandrino&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chiasserini_C/0/1/0/all/0/1&quot;&gt;Carla-Fabiana Chiasserini&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00708">
<title>Optimal Fusion of Elliptic Extended Target Estimates based on the Wasserstein Distance. (arXiv:1904.00708v1 [eess.SP])</title>
<link>http://arxiv.org/abs/1904.00708</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper considers the fusion of multiple estimates of a spatially extended
object, where the object extent is modeled as an ellipse that is parameterized
by the orientation and semi-axes lengths. For this purpose, we propose a novel
systematic approach that employs a distance measure for ellipses, i.e., the
Gaussian Wasserstein distance, as a cost function. We derive an explicit
expression for the Minimium Mean Gaussian Wasserstein distance (MMGW) estimate.
Based on the concept of a MMGW estimator, we develop efficient methods for the
fusion of extended target estimates. The proposed fusion methods are evaluated
in a simulated experiment and the benefits of the novel methods are discussed.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Thormann_K/0/1/0/all/0/1&quot;&gt;Kolja Thormann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Baum_M/0/1/0/all/0/1&quot;&gt;Marcus Baum&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00712">
<title>NewsCompare -- a novel application for detecting news influence in a country. (arXiv:1904.00712v1 [cs.SI])</title>
<link>http://arxiv.org/abs/1904.00712</link>
<description rdf:parseType="Literal">&lt;p&gt;The concept of ``fake news&apos;&apos; has been referenced and thrown around in news
reports so much in recent years that it has become a news topic in its own
right. At its core, it poses a chilling question -- what do we do if our
worldview is fundamentally wrong? Even if internally consistent, what if it
does not match the real world? Are our beliefs justified, or could we become
indoctrinated from living in a ``bubble&apos;&apos;? If the latter is true, how could we
even test the limits of said bubble from within its confines? We propose a new
method to augment the process of identifying fake news, by speeding up and
automating the more cumbersome and time-consuming tasks involved. Our
application, NewsCompare takes any list of target websites as input
(news-related in our use case, but otherwise not restricted), visits them in
parallel and retrieves any text content found within. Web pages are
subsequently compared to each other, and similarities are tentatively pointed
out. These results can be manually verified in order to determine which
websites tend to draw inspiration from one another. The data gathered on every
intermediate step can be queried and analyzed separately, and most notably we
already use the set of hyperlinks to and from the various websites we encounter
to paint a sort of ``map&apos;&apos; of that particular slice of the web. This map can
then be cross-referenced and further strengthen the conclusion that a
particular grouping of sites with strong links to each other, and posting
similar content, are likely to share the same allegiance. We run our
application on the Romanian news websites and we draw several interesting
observations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pop_C/0/1/0/all/0/1&quot;&gt;Cristian Pop&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Popa_A/0/1/0/all/0/1&quot;&gt;Alexandru Popa&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00714">
<title>Combining Crowd and Machines for Multi-predicate Item Screening. (arXiv:1904.00714v1 [cs.IR])</title>
<link>http://arxiv.org/abs/1904.00714</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper discusses how crowd and machine classifiers can be efficiently
combined to screen items that satisfy a set of predicates. We show that this is
a recurring problem in many domains, present machine-human (hybrid) algorithms
that screen items efficiently and estimate the gain over human-only or
machine-only screening in terms of performance and cost. We further show how,
given a new classification problem and a set of classifiers of unknown accuracy
for the problem at hand, we can identify how to manage the cost-accuracy trade
off by progressively determining if we should spend budget to obtain test data
(to assess the accuracy of the given classifiers), or to train an ensemble of
classifiers, or whether we should leverage the existing machine classifiers
with the crowd, and in this case how to efficiently combine them based on their
estimated characteristics to obtain the classification. We demonstrate that the
techniques we propose obtain significant cost/accuracy improvements with
respect to the leading classification algorithms.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Krivosheev_E/0/1/0/all/0/1&quot;&gt;Evgeny Krivosheev&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Casati_F/0/1/0/all/0/1&quot;&gt;Fabio Casati&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Baez_M/0/1/0/all/0/1&quot;&gt;Marcos Baez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Benatallah_B/0/1/0/all/0/1&quot;&gt;Boualem Benatallah&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00717">
<title>Smart Routing: Towards Proactive Fault-Handling in Software-Defined Networks. (arXiv:1904.00717v1 [cs.NI])</title>
<link>http://arxiv.org/abs/1904.00717</link>
<description rdf:parseType="Literal">&lt;p&gt;Software-defined networking offers numerous benefits against the legacy
networking systems through simplifying the process of network management and
reducing the cost of network configuration. Currently, the management of
failures in the data plane is limited to two mechanisms: proactive and
reactive. Such failure recovery techniques are activated after occurrences of
failures. Therefore, packet loss is highly likely to occur as a result of
service disruption and unavailability. This issue is not only related to the
slow speed of recovery mechanisms, but also the delay caused by the failure
detection process. In this paper, we define a new approach to the management of
fault tolerance in software-defined networks where the goal is to eliminate the
convergence process altogether, rather than speed up failure detection and
recovery. We propose a new framework, called Smart Routing, which works based
on the forewarning signs on failures in order to compute alternative paths and
isolate the risky links from the routing tables of the data plane devices. We
validate our framework through a set of experiments that demonstrate how the
underlying model runs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Malik_A/0/1/0/all/0/1&quot;&gt;Ali Malik&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Aziz_B/0/1/0/all/0/1&quot;&gt;Benjamin Aziz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Adda_M/0/1/0/all/0/1&quot;&gt;Mo Adda&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ke_C/0/1/0/all/0/1&quot;&gt;Chih-Heng Ke&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00720">
<title>CoaCor: Code Annotation for Code Retrieval with Reinforcement Learning. (arXiv:1904.00720v1 [cs.SE])</title>
<link>http://arxiv.org/abs/1904.00720</link>
<description rdf:parseType="Literal">&lt;p&gt;To accelerate software development, much research has been performed to help
people understand and reuse the huge amount of available code resources. Two
important tasks have been widely studied: code retrieval, which aims to
retrieve code snippets relevant to a given natural language query from a code
base, and code annotation, where the goal is to annotate a code snippet with a
natural language description. Despite their advancement in recent years, the
two tasks are mostly explored separately. In this work, we investigate a novel
perspective of Code annotation for Code retrieval (hence called `CoaCor&apos;),
where a code annotation model is trained to generate a natural language
annotation that can represent the semantic meaning of a given code snippet and
can be leveraged by a code retrieval model to better distinguish relevant code
snippets from others. To this end, we propose an effective framework based on
reinforcement learning, which explicitly encourages the code annotation model
to generate annotations that can be used for the retrieval task. Through
extensive experiments, we show that code annotations generated by our framework
are much more detailed and more useful for code retrieval, and they can further
improve the performance of existing code retrieval models significantly.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yao_Z/0/1/0/all/0/1&quot;&gt;Ziyu Yao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Peddamail_J/0/1/0/all/0/1&quot;&gt;Jayavardhan Reddy Peddamail&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_H/0/1/0/all/0/1&quot;&gt;Huan Sun&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00721">
<title>Challenges and issues in collaborative software developments. (arXiv:1904.00721v1 [cs.SE])</title>
<link>http://arxiv.org/abs/1904.00721</link>
<description rdf:parseType="Literal">&lt;p&gt;The software development process has evolved with respect to the problems in
developing large and complex applications. There is a paradigm shift towards
collaborative development, which necessitates the need to evaluate this
approach. A number of tools are used for collaborative software development
(CSD) including social media and web 2.0 features. Collaborative development
facilities are provided by IDEs and project hosting websites. In this paper, we
present a survey of collaboratively developed projects and discuss challenges
and issues in CSD. We analyze various issues of communication, coordination,
support, lifecycle management and discuss their effect on software quality.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yasrab_R/0/1/0/all/0/1&quot;&gt;Robail Yasrab&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ferzund_J/0/1/0/all/0/1&quot;&gt;Javed Ferzund&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Razzaq_S/0/1/0/all/0/1&quot;&gt;Saad Razzaq&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00722">
<title>Learning Soft Tissue Behavior of Organs for Surgical Navigation with Convolutional Neural Networks. (arXiv:1904.00722v1 [cs.GR])</title>
<link>http://arxiv.org/abs/1904.00722</link>
<description rdf:parseType="Literal">&lt;p&gt;Purpose: In surgical navigation, pre-operative organ models are presented to
surgeons during the intervention to help them in efficiently finding their
target. In the case of soft tissue, these models need to be deformed and
adapted to the current situation by using intra-operative sensor data. A
promising method to realize this are real-time capable biomechanical models.
&lt;/p&gt;
&lt;p&gt;Methods: We train a fully convolutional neural network to estimate a
displacement field of all points inside an organ when given only the
displacement of a part of the organ&apos;s surface. The network trains on entirely
synthetic data of random organ-like meshes, which allows us to generate much
more data than is otherwise available. The input and output data is discretized
into a regular grid, allowing us to fully utilize the capabilities of
convolutional operators and to train and infer in a highly parallelized manner.
&lt;/p&gt;
&lt;p&gt;Results: The system is evaluated on in-silico liver models, phantom liver
data and human in-vivo breathing data. We test the performance with varying
material parameters, organ shapes and amount of visible surface. Even though
the network is only trained on synthetic data, it adapts well to the various
cases and gives a good estimation of the internal organ displacement. The
inference runs at over 50 frames per second.
&lt;/p&gt;
&lt;p&gt;Conclusions: We present a novel method for training a data-driven, real-time
capable deformation model. The accuracy is comparable to other registration
methods, it adapts very well to previously unseen organs and does not need to
be re-trained for every patient. The high inferring speed makes this method
useful for many applications such as surgical navigation and real-time
simulation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pfeiffer_M/0/1/0/all/0/1&quot;&gt;Micha Pfeiffer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Riediger_C/0/1/0/all/0/1&quot;&gt;Carina Riediger&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Weitz_J/0/1/0/all/0/1&quot;&gt;J&amp;#xfc;rgen Weitz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Speidel_S/0/1/0/all/0/1&quot;&gt;Stefanie Speidel&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00724">
<title>GAN You Do the GAN GAN?. (arXiv:1904.00724v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1904.00724</link>
<description rdf:parseType="Literal">&lt;p&gt;Generative Adversarial Networks (GANs) have become a dominant class of
generative models. In recent years, GAN variants have yielded especially
impressive results in the synthesis of a variety of forms of data. Examples
include compelling natural and artistic images, textures, musical sequences,
and 3D object files. However, one obvious synthesis candidate is missing. In
this work, we answer one of deep learning&apos;s most pressing questions: GAN you do
the GAN GAN? That is, is it possible to train a GAN to model a distribution of
GANs? We release the full source code for this project under the MIT license.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Suarez_J/0/1/0/all/0/1&quot;&gt;Joseph Suarez&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00726">
<title>Unsupervised Concatenation Hashing with Sparse Constraint for Cross-Modal Retrieval. (arXiv:1904.00726v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1904.00726</link>
<description rdf:parseType="Literal">&lt;p&gt;With the advantage of low storage cost and high efficiency, hashing learning
has received much attention in retrieval field. As multiple modal data
representing a common object semantically are complementary, many works focus
on learning unified binary codes. However, these works ignore the importance of
manifold structre among data. In fact, it is still an interesting problem to
directly preserve the local manifold structure among samples in hamming space.
Since different modalities are isomerous, we adopt the concatenated feature of
multiple modality feature to represent original object. In our framework,
Locally Linear Embedding and Locality Preserving Projection are introduced to
reconstruct the manifold structure of original space in the Hamming space.
Besides, The L21-norm regularization are imposed on the projection matrices to
further exploit the discriminative features for different modalities
simultaneously. Extensive experiments are performed to evaluate the proposed
method, dubbed Unsupervised Concatenation Hashing (UCH), on the three publicly
available datasets and the experimental results show the superior performance
of UCH outperforming most of state-of-the-art unsupervised hashing models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_J/0/1/0/all/0/1&quot;&gt;Jun Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1&quot;&gt;Xiao-Jun Wu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00727">
<title>Adaptive sampling of time-space signals in a reproducing kernel subspace of mixed Lebesgue space. (arXiv:1904.00727v1 [cs.IT])</title>
<link>http://arxiv.org/abs/1904.00727</link>
<description rdf:parseType="Literal">&lt;p&gt;The Mixed Lebesgue space is a suitable tool for modelling and measuring
signals living in time-space domains. And sampling in such spaces plays an
important role for processing high-dimensional time-varying signals. In this
paper, we first define reproducing kernel subspaces of mixed Lebesgue spaces.
Then, we study the frame properties and show that the reproducing kernel
subspace has finite rate of innovation. Finally, we propose a semi-adaptive
sampling scheme for time-space signals in a reproducing kernel subspace, where
the sampling in time domain is conducted by a time encoding machine. Two kinds
of timing sampling methods are considered and the corresponding iterative
approximation algorithms with exponential convergence are given.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1&quot;&gt;Yingchun Jiang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_W/0/1/0/all/0/1&quot;&gt;Wenchang Sun&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00731">
<title>A survey on efficient parallelization of blockchain-based smart contracts. (arXiv:1904.00731v1 [cs.CR])</title>
<link>http://arxiv.org/abs/1904.00731</link>
<description rdf:parseType="Literal">&lt;p&gt;The main problem faced by smart contract platforms is the amount of time and
computational power required to reach consensus. In a classical blockchain
model, each operation is in fact performed by each node, both to update the
status and to validate the results of the calculations performed by others. In
this short survey we sketch some state-of-the-art approaches to obtain an
efficient and scalable computation of smart contracts. Particular emphasis is
given to sharding, a promising method that allows parallelization and therefore
a more efficient management of the computational resources of the network.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Meneghetti_A/0/1/0/all/0/1&quot;&gt;Alessio Meneghetti&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Parise_T/0/1/0/all/0/1&quot;&gt;Tommaso Parise&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sala_M/0/1/0/all/0/1&quot;&gt;Massimiliano Sala&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Taufer_D/0/1/0/all/0/1&quot;&gt;Daniele Taufer&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00732">
<title>From Golden to Unimodular Cryptography. (arXiv:1904.00732v1 [cs.CR])</title>
<link>http://arxiv.org/abs/1904.00732</link>
<description rdf:parseType="Literal">&lt;p&gt;We introduce a natural generalization of the golden cryptography, which uses
general unimodular matrices in place of the traditional Q-matrices, and prove
that it preserves the original error correction properties of the encryption.
Moreover, the additional parameters involved in generating the coding matrices
make this unimodular cryptography resilient to the chosen plaintext attacks
that worked against the golden cryptography. Finally, we show that even the
golden cryptography is generally unable to correct double errors in the same
row of the ciphertext matrix, and offer an additional check number which, if
transmitted, allows for the correction.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Koshkin_S/0/1/0/all/0/1&quot;&gt;Sergiy Koshkin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Styers_T/0/1/0/all/0/1&quot;&gt;Taylor Styers&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00733">
<title>Blockchain And The Future of the Internet:A Comprehensive Review. (arXiv:1904.00733v1 [cs.CR])</title>
<link>http://arxiv.org/abs/1904.00733</link>
<description rdf:parseType="Literal">&lt;p&gt;Blockchain is challenging the status quo of the central trust infrastructure
currently prevalent in the Internet towards a design principle that is
underscored by decentralization and transparency. In ideal terms, blockchain
advocates a decentralized, transparent, and more democratic version of the
Internet. Essentially being a trusted and decentralized database, blockchain
finds its applications in fields as varied as the energy sector, forestry,
fisheries, mining, material recycling, air pollution monitoring, supply chain
management, and their associated operations. In this paper, we present a survey
of blockchain-based network applications. Our goal is to cover the evolution of
blockchain-based systems that are trying to bring in a renaissance in the
existing, mostly centralized, space of network applications. While reimagining
the space with blockchain, we highlight various common challenges, pitfalls,
and shortcomings that can occur. Our aim is to make this work as a guiding
reference manual for someone interested in shifting towards a blockchain-based
solution for one&apos;s existing use case or automating one from the ground up.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hassan_F/0/1/0/all/0/1&quot;&gt;Fakhar ul Hassan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ali_A/0/1/0/all/0/1&quot;&gt;Anwaar Ali&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Latif_S/0/1/0/all/0/1&quot;&gt;Siddique Latif&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qadir_J/0/1/0/all/0/1&quot;&gt;Junaid Qadir&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kanhere_S/0/1/0/all/0/1&quot;&gt;Salil Kanhere&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Singh_J/0/1/0/all/0/1&quot;&gt;Jatinder Singh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Crowcroft_J/0/1/0/all/0/1&quot;&gt;Jon Crowcroft&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00734">
<title>Forensics Analysis of Xbox One Game Console. (arXiv:1904.00734v1 [cs.CR])</title>
<link>http://arxiv.org/abs/1904.00734</link>
<description rdf:parseType="Literal">&lt;p&gt;Games console devices have been designed to be an entertainment system.
However, the 8th generation games console have new features that can support
criminal activities and investigators need to be aware of them. This paper
highlights the forensics value of the Microsoft game console Xbox One, the
latest version of their Xbox series. The Xbox One game console provides many
features including web browsing, social networking, and chat functionality.
From a forensic perspective, all those features will be a place of interest in
forensic examinations. However, the available published literature focused on
examining the physical hard drive artefacts, which are encrypted and cannot
provide deep analysis of the user&apos;s usage of the console. In this paper, we
carried out an investigation of the Xbox One games console by using two
approaches: a physical investigation of the hard drive to identify the valuable
file timestamp information and logical examination via the graphical user
interface. Furthermore, this paper identifies potential valuable forensic data
sources within the Xbox One and provides best practices guidance for collecting
data in a forensically sound manner.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Al_Haj_A/0/1/0/all/0/1&quot;&gt;Ali M. Al-Haj&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00735">
<title>A Comparative Analysis of Android Malware. (arXiv:1904.00735v1 [cs.CR])</title>
<link>http://arxiv.org/abs/1904.00735</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we present a comparative analysis of benign and malicious
Android applications, based on static features. In particular, we focus our
attention on the permissions requested by an application. We consider both
binary classification of malware versus benign, as well as the multiclass
problem, where we classify malware samples into their respective families. Our
experiments are based on substantial malware datasets and we employ a wide
variety of machine learning techniques, including decision trees and random
forests, support vector machines, logistic model trees, AdaBoost, and
artificial neural networks. We find that permissions are a strong feature and
that by careful feature engineering, we can significantly reduce the number of
features needed for highly accurate detection and classification.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chavan_N/0/1/0/all/0/1&quot;&gt;Neeraj Chavan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Troia_F/0/1/0/all/0/1&quot;&gt;Fabio Di Troia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Stamp_M/0/1/0/all/0/1&quot;&gt;Mark Stamp&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00736">
<title>Using Deep Neural Network for Android Malware Detection. (arXiv:1904.00736v1 [cs.CR])</title>
<link>http://arxiv.org/abs/1904.00736</link>
<description rdf:parseType="Literal">&lt;p&gt;The pervasiveness of the Android operating system, with the availability of
applications almost for everything, is readily accessible in the official
Google play store or a dozen alternative third-party markets. Additionally, the
vital role of smartphones in modern life leads to store significant information
on devices, not only personal information but also corporate information, which
attract malware developers to develop applications that can infiltrate user&apos;s
devices to steal information and perform harmful tasks. This accompanied with
the limitation of currently defenses techniques such as ineffective screening
in Google play store, weak or no screening in third-party markets. Antiviruses
software that still relies on a signature-based database that is effective only
in identifying known malware. To contrive with malicious applications that are
increased in volume and sophistication, we propose an Android malware detection
system that applies deep learning technique to face the threats of Android
malware. Extensive experiments on a real-world dataset contain benign and
malicious applications uncovered that the proposed system reaches an accuracy
of 95.31%.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Naway_A/0/1/0/all/0/1&quot;&gt;Abdelmonim Naway&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+LI_Y/0/1/0/all/0/1&quot;&gt;Yuancheng LI&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00737">
<title>Defending via strategic ML selection. (arXiv:1904.00737v1 [cs.CR])</title>
<link>http://arxiv.org/abs/1904.00737</link>
<description rdf:parseType="Literal">&lt;p&gt;The results of a learning process depend on the input data. There are cases
in which an adversary can strategically tamper with the input data to affect
the outcome of the learning process. While some datasets are difficult to
attack, many others are susceptible to manipulation. A resourceful attacker can
tamper with large portions of the dataset and affect them. An attacker can
additionally strategically focus on a preferred subset of the attributes in the
dataset to maximize the effectiveness of the attack and minimize the resources
allocated to data manipulation. In light of this vulnerability, we introduce a
solution according to which the defender implements an array of learners, and
their activation is performed strategically. The defender computes the (game
theoretic) strategy space and accordingly applies a dominant strategy where
possible, and a Nash-stable strategy otherwise. In this paper we provide the
details of this approach. We analyze Nash equilibrium in such a strategic
learning environment, and demonstrate our solution by specific examples.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Farchi_E/0/1/0/all/0/1&quot;&gt;Eitan Farchi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shehory_O/0/1/0/all/0/1&quot;&gt;Onn Shehory&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Barash_G/0/1/0/all/0/1&quot;&gt;Guy Barash&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00738">
<title>Semantic Nearest Neighbor Fields Monocular Edge Visual-Odometry. (arXiv:1904.00738v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1904.00738</link>
<description rdf:parseType="Literal">&lt;p&gt;Recent advances in deep learning for edge detection and segmentation opens up
a new path for semantic-edge-based ego-motion estimation. In this work, we
propose a robust monocular visual odometry (VO) framework using category-aware
semantic edges. It can reconstruct large-scale semantic maps in challenging
outdoor environments. The core of our approach is a semantic nearest neighbor
field that facilitates a robust data association of edges across frames using
semantics. This significantly enlarges the convergence radius during tracking
phases. The proposed edge registration method can be easily integrated into
direct VO frameworks to estimate photometrically, geometrically, and
semantically consistent camera motions. Different types of edges are evaluated
and extensive experiments demonstrate that our proposed system outperforms
state-of-art indirect, direct, and semantic monocular VO systems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1&quot;&gt;Xiaolong Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Benbihi_A/0/1/0/all/0/1&quot;&gt;Assia Benbihi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Richard_A/0/1/0/all/0/1&quot;&gt;Antoine Richard&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pradalier_C/0/1/0/all/0/1&quot;&gt;Cedric Pradalier&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00739">
<title>The Sixth Sense with Artificial Intelligence: An Innovative Solution for Real-Time Retrieval of the Human Figure Behind Visual Obstruction. (arXiv:1904.00739v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1904.00739</link>
<description rdf:parseType="Literal">&lt;p&gt;Overcoming the visual barrier and developing &quot;see-through vision&quot; has been
one of mankind&apos;s long-standing dreams. However, visible light cannot travel
through opaque obstructions (e.g. walls). Unlike visible light, though, Radio
Frequency (RF) signals penetrate many common building objects and reflect
highly off humans. This project creates a breakthrough artificial intelligence
methodology by which the skeletal structure of a human can be reconstructed
with RF even through visual occlusion. In a novel procedural flow, video and RF
data are first collected simultaneously using a co-located setup containing an
RGB camera and RF antenna array transceiver. Next, the RGB video is processed
with a Part Affinity Field computer-vision model to generate ground truth label
locations for each keypoint in the human skeleton. Then, a collective
deep-learning model consisting of a Residual Convolutional Neural Network,
Region Proposal Network, and Recurrent Neural Network 1) extracts spatial
features from RF images, 2) detects and crops out all people present in the
scene, and 3) aggregates information over dozens of time-steps to piece
together the various limbs that reflect signals back to the receiver at
different times. A simulator is created to demonstrate the system. This project
has impactful applications in medicine, military, search &amp;amp; rescue, and
robotics. Especially during a fire emergency, neither visible light nor
infrared thermal imaging can penetrate smoke or fire, but RF can. With over 1
million fires reported in the US per year, this technology could save thousands
of lives and tens-of-thousands of injuries.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Meng_K/0/1/0/all/0/1&quot;&gt;Kevin Meng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Meng_Y/0/1/0/all/0/1&quot;&gt;Yu Meng&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00740">
<title>Projectron -- A Shallow and Interpretable Network for Classifying Medical Images. (arXiv:1904.00740v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1904.00740</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper introduces the `Projectron&apos; as a new neural network architecture
that uses Radon projections to both classify and represent medical images. The
motivation is to build shallow networks which are more interpretable in the
medical imaging domain. Radon transform is an established technique that can
reconstruct images from parallel projections. The Projectron first applies
global Radon transform to each image using equidistant angles and then feeds
these transformations for encoding to a single layer of neurons followed by a
layer of suitable kernels to facilitate a linear separation of projections.
Finally, the Projectron provides the output of the encoding as an input to two
more layers for final classification. We validate the Projectron on five
publicly available datasets, a general dataset (namely MNIST) and four medical
datasets (namely Emphysema, IDC, IRMA, and Pneumonia). The results are
encouraging as we compared the Projectron&apos;s performance against MLPs with raw
images and Radon projections as inputs, respectively. Experiments clearly
demonstrate the potential of the proposed Projectron for
representing/classifying medical images.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sriram_A/0/1/0/all/0/1&quot;&gt;Aditya Sriram&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kalra_S/0/1/0/all/0/1&quot;&gt;Shivam Kalra&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tizhoosh_H/0/1/0/all/0/1&quot;&gt;H.R. Tizhoosh&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00741">
<title>Fashion Outfit Generation for E-commerce. (arXiv:1904.00741v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1904.00741</link>
<description rdf:parseType="Literal">&lt;p&gt;Combining items of clothing into an outfit is a major task in fashion retail.
Recommending sets of items that are compatible with a particular seed item is
useful for providing users with guidance and inspiration, but is currently a
manual process that requires expert stylists and is therefore not scalable or
easy to personalise. We use a multilayer neural network fed by visual and
textual features to learn embeddings of items in a latent style space such that
compatible items of different types are embedded close to one another. We train
our model using the ASOS outfits dataset, which consists of a large number of
outfits created by professional stylists and which we release to the research
community. Our model shows strong performance in an offline outfit
compatibility prediction task. We use our model to generate outfits and for the
first time in this field perform an AB test, comparing our generated outfits to
those produced by a baseline model which matches appropriate product types but
uses no information on style. Users approved of outfits generated by our model
21% and 34% more frequently than those generated by the baseline model for
womenswear and menswear respectively.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bettaney_E/0/1/0/all/0/1&quot;&gt;Elaine M. Bettaney&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hardwick_S/0/1/0/all/0/1&quot;&gt;Stephen R. Hardwick&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zisimopoulos_O/0/1/0/all/0/1&quot;&gt;Odysseas Zisimopoulos&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chamberlain_B/0/1/0/all/0/1&quot;&gt;Benjamin Paul Chamberlain&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00742">
<title>A smartphone application to detection and classification of coffee leaf miner and coffee leaf rust. (arXiv:1904.00742v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1904.00742</link>
<description rdf:parseType="Literal">&lt;p&gt;Generally, the identification and classification of plant diseases and/or
pests are performed by an expert . One of the problems facing coffee farmers in
Brazil is crop infestation, particularly by leaf rust Hemileia vastatrix and
leaf miner Leucoptera coffeella. The progression of the diseases and or pests
occurs spatially and temporarily. So, it is very important to automatically
identify the degree of severity. The main goal of this article consists on the
development of a method and its i implementation as an App that allow the
detection of the foliar damages from images of coffee leaf that are captured
using a smartphone, and identify whether it is rust or leaf miner, and in turn
the calculation of its severity degree. The method consists of identifying a
leaf from the image and separates it from the background with the use of a
segmentation algorithm. In the segmentation process, various types of
backgrounds for the image using the HSV and YCbCr color spaces are tested. In
the segmentation of foliar damages, the Otsu algorithm and the iterative
threshold algorithm, in the YCgCr color space, have been used and compared to
k-means. Next, features of the segmented foliar damages are calculated. For the
classification, artificial neural network trained with extreme learning machine
have been used. The results obtained shows the feasibility and effectiveness of
the approach to identify and classify foliar damages, and the automatic
calculation of the severity. The results obtained are very promising according
to experts.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Manso_G/0/1/0/all/0/1&quot;&gt;Giuliano L. Manso&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Knidel_H/0/1/0/all/0/1&quot;&gt;Helder Knidel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Krohling_R/0/1/0/all/0/1&quot;&gt;Renato A. Krohling&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ventura_J/0/1/0/all/0/1&quot;&gt;Jose A. Ventura&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00744">
<title>Mutual Linear Regression-based Discrete Hashing. (arXiv:1904.00744v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1904.00744</link>
<description rdf:parseType="Literal">&lt;p&gt;Label information is widely used in hashing methods because of its
effectiveness of improving the precision. The existing hashing methods always
use two different projections to represent the mutual regression between hash
codes and class labels. In contrast to the existing methods, we propose a novel
learning-based hashing method termed stable supervised discrete hashing with
mutual linear regression (S2DHMLR) in this study, where only one stable
projection is used to describe the linear correlation between hash codes and
corresponding labels. To the best of our knowledge, this strategy has not been
used for hashing previously. In addition, we further use a boosting strategy to
improve the final performance of the proposed method without adding extra
constraints and with little extra expenditure in terms of time and space.
Extensive experiments conducted on three image benchmarks demonstrate the
superior performance of the proposed method.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1&quot;&gt;Xingbo Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nie_X/0/1/0/all/0/1&quot;&gt;Xiushan Nie&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yin_Y/0/1/0/all/0/1&quot;&gt;Yilong Yin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00746">
<title>Token Exchange Games. (arXiv:1904.00746v1 [cs.GT])</title>
<link>http://arxiv.org/abs/1904.00746</link>
<description rdf:parseType="Literal">&lt;p&gt;Human societies engage in a number of games which use tokens as a means to
allocate, issue and access gated resources and property rights: The notion of
exchanging tokens that represent and carry value from the past into the future
to facilitate economic exchange is a fundamental concept. As agents exchange
tokens a network structure is created in which the tokens move from agent to
agent. Agents form the vertices in the network and the exchange of tokens
creates the link structure. The rules of exchange adopted collectively by
agents shape the network structure and affect the distribution of tokens
amongst agents. Many inventions including banking, payments networks and
blockchain technology have been created for the purpose of keeping accurate
records of these implicit networks. However, our formal understanding of
tokenised systems as large scale, iterative, interacting structures is limited.
The aim of this paper is to study the dynamics of token exchanges as a game,
and introduce a mathematical framework for understanding ledgers as complex
networks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Naicker_V/0/1/0/all/0/1&quot;&gt;Viroshan Naicker&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00747">
<title>A Novel Pixel-Averaging Technique for Extracting Training Data from a Single Image, Used in ML-Based Image Enlargement. (arXiv:1904.00747v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1904.00747</link>
<description rdf:parseType="Literal">&lt;p&gt;Size of the training dataset is an important factor in the performance of a
machine learning algorithms and tools used in medical image processing are not
exceptions. Machine learning tools normally require a decent amount of training
data before they could efficiently predict a target. For image processing and
computer vision, the number of images determines the validity and reliability
of the training set. Medical images in some cases, suffer from poor quality and
inadequate quantity required for a suitable training set. The proposed
algorithm in this research obviates the need for large or even small image
datasets used in machine learning based image enlargement techniques by
extracting the required data from a single image. The extracted data was then
introduced to a decision tree regressor for upscaling greyscale medical images
at different zoom levels. Results from the algorithm are relatively acceptable
compared to third-party applications and promising for future research. This
technique could be tailored to the requirements of other machine learning tools
and the results may be improved by further tweaking of the tools
hyperparameters.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rastar_A/0/1/0/all/0/1&quot;&gt;Amir Rastar&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00748">
<title>Manual Encryption Revisited. (arXiv:1904.00748v1 [cs.CR])</title>
<link>http://arxiv.org/abs/1904.00748</link>
<description rdf:parseType="Literal">&lt;p&gt;This document brings together several articles devoted to manual encryption
and introduces new algorithms and ciphers: a permutation algorithm, Spirale (a
one-time-pad cipher), a solution to the problem of the ordered route of a
table, Diagonales (a cipher by transposition), Carousel (another cipher by
transposition), solutions to the problem of creating keys or passwords.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Allard_P/0/1/0/all/0/1&quot;&gt;Philippe Allard&lt;/a&gt; (Pr&amp;#xe9;Tech)</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00750">
<title>H2B: Heartbeat-based Secret Key Generation Using Piezo Vibration Sensors. (arXiv:1904.00750v1 [cs.CR])</title>
<link>http://arxiv.org/abs/1904.00750</link>
<description rdf:parseType="Literal">&lt;p&gt;We present Heartbeats-2-Bits (H2B), which is a system for securely pairing
wearable devices by generating a shared secret key from the skin vibrations
caused by heartbeat. This work is motivated by potential power saving
opportunity arising from the fact that heartbeat intervals can be detected
energy-efficiently using inexpensive and power-efficient piezo sensors, which
obviates the need to employ complex heartbeat monitors such as
Electrocardiogram or Photoplethysmogram. Indeed, our experiments show that
piezo sensors can measure heartbeat intervals on many different body locations
including chest, wrist, waist, neck and ankle. Unfortunately, we also discover
that the heartbeat interval signal captured by piezo vibration sensors has low
Signal-to-Noise Ratio (SNR) because they are not designed as precision
heartbeat monitors, which becomes the key challenge for H2B. To overcome this
problem, we first apply a quantile function-based quantization method to fully
extract the useful entropy from the noisy piezo measurements. We then propose a
novel Compressive Sensing-based reconciliation method to correct the high bit
mismatch rates between the two independently generated keys caused by low SNR.
We prototype H2B using off-the-shelf piezo sensors and evaluate its performance
on a dataset collected from different body positions of 23 participants. Our
results show that H2B has an overwhelming pairing success rate of 95.6%. We
also analyze and demonstrate H2B&apos;s robustness against three types of attacks.
Finally, our power measurements show that H2B is very power-efficient.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_Q/0/1/0/all/0/1&quot;&gt;Qi Lin&lt;/a&gt; (1 and 2), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_W/0/1/0/all/0/1&quot;&gt;Weitao Xu&lt;/a&gt; (1), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1&quot;&gt;Jun Liu&lt;/a&gt; (1), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khamis_A/0/1/0/all/0/1&quot;&gt;Abdelwahed Khamis&lt;/a&gt; (1 and 2), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hu_W/0/1/0/all/0/1&quot;&gt;Wen Hu&lt;/a&gt; (1 and 2), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hassan_M/0/1/0/all/0/1&quot;&gt;Mahbub Hassan&lt;/a&gt; (1 and 2), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Seneviratne_A/0/1/0/all/0/1&quot;&gt;Aruna Seneviratne&lt;/a&gt; (1 and 2) ((1) UNSW Australia (2) Data61, CSIRO, Australia)</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00753">
<title>SCADA System Testbed for Cybersecurity Research Using Machine Learning Approach. (arXiv:1904.00753v1 [cs.NI])</title>
<link>http://arxiv.org/abs/1904.00753</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper presents the development of a Supervisory Control and Data
Acquisition (SCADA) system testbed used for cybersecurity research. The testbed
consists of a water storage tank&apos;s control system, which is a stage in the
process of water treatment and distribution. Sophisticated cyber-attacks were
conducted against the testbed. During the attacks, the network traffic was
captured, and features were extracted from the traffic to build a dataset for
training and testing different machine learning algorithms. Five traditional
machine learning algorithms were trained to detect the attacks: Random Forest,
Decision Tree, Logistic Regression, Naive Bayes and KNN. Then, the trained
machine learning models were built and deployed in the network, where new tests
were made using online network traffic. The performance obtained during the
training and testing of the machine learning models was compared to the
performance obtained during the online deployment of these models in the
network. The results show the efficiency of the machine learning models in
detecting the attacks in real time. The testbed provides a good understanding
of the effects and consequences of attacks on real SCADA environments
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Teixeira_M/0/1/0/all/0/1&quot;&gt;Marcio Andrey Teixeira&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Salman_T/0/1/0/all/0/1&quot;&gt;Tara Salman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zolanvari_M/0/1/0/all/0/1&quot;&gt;Maede Zolanvari&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jain_R/0/1/0/all/0/1&quot;&gt;Raj Jain&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Meskin_N/0/1/0/all/0/1&quot;&gt;Nader Meskin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Samaka_M/0/1/0/all/0/1&quot;&gt;Mohammed Samaka&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00758">
<title>Value of Temporal Dynamics Information in Driving Scene Segmentation. (arXiv:1904.00758v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1904.00758</link>
<description rdf:parseType="Literal">&lt;p&gt;Semantic scene segmentation has primarily been addressed by forming
representations of single images both with supervised and unsupervised methods.
The problem of semantic segmentation in dynamic scenes has begun to recently
receive attention with video object segmentation approaches. What is not known
is how much extra information the temporal dynamics of the visual scene carries
that is complimentary to the information available in the individual frames of
the video. There is evidence that the human visual system can effectively
perceive the scene from temporal dynamics information of the scene&apos;s changing
visual characteristics without relying on the visual characteristics of
individual snapshots themselves. Our work takes steps to explore whether
machine perception can exhibit similar properties by combining appearance-based
representations and temporal dynamics representations in a joint-learning
problem that reveals the contribution of each toward successful dynamic scene
segmentation. Additionally, we provide the MIT Driving Scene Segmentation
dataset, which is a large-scale full driving scene segmentation dataset,
densely annotated for every pixel and every one of 5,000 video frames. This
dataset is intended to help further the exploration of the value of temporal
dynamics information for semantic segmentation in video.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ding_L/0/1/0/all/0/1&quot;&gt;Li Ding&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Terwilliger_J/0/1/0/all/0/1&quot;&gt;Jack Terwilliger&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sherony_R/0/1/0/all/0/1&quot;&gt;Rini Sherony&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Reimer_B/0/1/0/all/0/1&quot;&gt;Bryan Reimer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fridman_L/0/1/0/all/0/1&quot;&gt;Lex Fridman&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00759">
<title>Adversarial camera stickers: A Physical Camera Attack on Deep Learning Classifier. (arXiv:1904.00759v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1904.00759</link>
<description rdf:parseType="Literal">&lt;p&gt;Recent work has thoroughly documented the susceptibility of deep learning
systems to adversarial examples, but most such instances directly manipulate
the digital input to a classifier. Although a smaller line of work considers
physical adversarial attacks, in all cases these involve manipulating the
object of interest, e.g., putting a physical sticker on a object to misclassify
it, or manufacturing an object specifically intended to be misclassified. In
this work, we consider an alternative question: is it possible to fool deep
classifiers, over all perceived objects of a certain type, by physically
manipulating the camera itself? We show that this is indeed possible, that by
placing a carefully crafted and mainly-translucent sticker over the lens of a
camera, one can create universal perturbations of the observed images that are
inconspicuous, yet reliably misclassify target objects as a different
(targeted) class. To accomplish this, we propose an iterative procedure for
both updating the attack perturbation (to make it adversarial for a given
classifier), and the threat model itself (to ensure it is physically
realizable). For example, we show that we can achieve physically-realizable
attacks that fool ImageNet classifiers in a targeted fashion 49.6% of the time.
This presents a new class of physically-realizable threat models to consider in
the context of adversarially robust machine learning. Link to our demo video:
https://youtu.be/wUVmL33Fx54
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1&quot;&gt;Juncheng B. Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schmidt_F/0/1/0/all/0/1&quot;&gt;Frank R. Schmidt&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kolter_J/0/1/0/all/0/1&quot;&gt;J. Zico Kolter&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00760">
<title>Approximating CNNs with Bag-of-local-Features models works surprisingly well on ImageNet. (arXiv:1904.00760v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1904.00760</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep Neural Networks (DNNs) excel on many complex perceptual tasks but it has
proven notoriously difficult to understand how they reach their decisions. We
here introduce a high-performance DNN architecture on ImageNet whose decisions
are considerably easier to explain. Our model, a simple variant of the
ResNet-50 architecture called BagNet, classifies an image based on the
occurrences of small local image features without taking into account their
spatial ordering. This strategy is closely related to the bag-of-feature (BoF)
models popular before the onset of deep learning and reaches a surprisingly
high accuracy on ImageNet (87.6% top-5 for 33 x 33 px features and Alexnet
performance for 17 x 17 px features). The constraint on local features makes it
straight-forward to analyse how exactly each part of the image influences the
classification. Furthermore, the BagNets behave similar to state-of-the art
deep neural networks such as VGG-16, ResNet-152 or DenseNet-169 in terms of
feature sensitivity, error distribution and interactions between image parts.
This suggests that the improvements of DNNs over previous bag-of-feature
classifiers in the last few years is mostly achieved by better fine-tuning
rather than by qualitatively different decision strategies.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Brendel_W/0/1/0/all/0/1&quot;&gt;Wieland Brendel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bethge_M/0/1/0/all/0/1&quot;&gt;Matthias Bethge&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00761">
<title>Neural Speed Reading with Structural-Jump-LSTM. (arXiv:1904.00761v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1904.00761</link>
<description rdf:parseType="Literal">&lt;p&gt;Recurrent neural networks (RNNs) can model natural language by sequentially
&apos;reading&apos; input tokens and outputting a distributed representation of each
token. Due to the sequential nature of RNNs, inference time is linearly
dependent on the input length, and all inputs are read regardless of their
importance. Efforts to speed up this inference, known as &apos;neural speed
reading&apos;, either ignore or skim over part of the input. We present
Structural-Jump-LSTM: the first neural speed reading model to both skip and
jump text during inference. The model consists of a standard LSTM and two
agents: one capable of skipping single words when reading, and one capable of
exploiting punctuation structure (sub-sentence separators (,:), sentence end
symbols (.!?), or end of text markers) to jump ahead after reading a word. A
comprehensive experimental evaluation of our model against all five
state-of-the-art neural reading models shows that Structural-Jump-LSTM achieves
the best overall floating point operations (FLOP) reduction (hence is faster),
while keeping the same accuracy or even improving it compared to a vanilla LSTM
that reads the whole text.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hansen_C/0/1/0/all/0/1&quot;&gt;Christian Hansen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hansen_C/0/1/0/all/0/1&quot;&gt;Casper Hansen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Alstrup_S/0/1/0/all/0/1&quot;&gt;Stephen Alstrup&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Simonsen_J/0/1/0/all/0/1&quot;&gt;Jakob Grue Simonsen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lioma_C/0/1/0/all/0/1&quot;&gt;Christina Lioma&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00762">
<title>Affect in Tweets Using Experts Model. (arXiv:1904.00762v1 [cs.IR])</title>
<link>http://arxiv.org/abs/1904.00762</link>
<description rdf:parseType="Literal">&lt;p&gt;Estimating the intensity of emotion has gained significance as modern textual
inputs in potential applications like social media, e-retail markets,
psychology, advertisements etc., carry a lot of emotions, feelings, expressions
along with its meaning. However, the approaches of traditional sentiment
analysis primarily focuses on classifying the sentiment in general (positive or
negative) or at an aspect level(very positive, low negative, etc.) and cannot
exploit the intensity information. Moreover, automatically identifying emotions
like anger, fear, joy, sadness, disgust etc., from text introduces challenging
scenarios where single tweet may contain multiple emotions with different
intensities and some emotions may even co-occur in some of the tweets. In this
paper, we propose an architecture, Experts Model, inspired from the standard
Mixture of Experts (MoE) model. The key idea here is each expert learns
different sets of features from the feature vector which helps in better
emotion detection from the tweet. We compared the results of our Experts Model
with both baseline results and top five performers of SemEval-2018 Task-1,
Affect in Tweets (AIT). The experimental results show that our proposed
approach deals with the emotion detection problem and stands at top-5 results.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Oota_S/0/1/0/all/0/1&quot;&gt;Subba Reddy Oota&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Avvaru_A/0/1/0/all/0/1&quot;&gt;Adithya Avvaru&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Marreddy_M/0/1/0/all/0/1&quot;&gt;Mounika Marreddy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mamidi_R/0/1/0/all/0/1&quot;&gt;Radhika Mamidi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00763">
<title>Part-based approximations for morphological operators using asymmetric auto-encoders. (arXiv:1904.00763v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1904.00763</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper addresses the issue of building a part-based representation of a
dataset of images. More precisely, we look for a non-negative, sparse
decomposition of the images on a reduced set of atoms, in order to unveil a
morphological and interpretable structure of the data. Additionally, we want
this decomposition to be computed online for any new sample that is not part of
the initial dataset. Therefore, our solution relies on a sparse, non-negative
auto-encoder where the encoder is deep (for accuracy) and the decoder shallow
(for interpretability). This method compares favorably to the state-of-the-art
online methods on two datasets (MNIST and Fashion MNIST), according to
classical metrics and to a new one we introduce, based on the invariance of the
representation to morphological dilation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ponchon_B/0/1/0/all/0/1&quot;&gt;Bastien Ponchon&lt;/a&gt; (CMM, LTCI), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Velasco_Forero_S/0/1/0/all/0/1&quot;&gt;Santiago Velasco-Forero&lt;/a&gt; (CMM), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Blusseau_S/0/1/0/all/0/1&quot;&gt;Samy Blusseau&lt;/a&gt; (CMM), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Angulo_J/0/1/0/all/0/1&quot;&gt;Jesus Angulo&lt;/a&gt; (CMM), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bloch_I/0/1/0/all/0/1&quot;&gt;Isabelle Bloch&lt;/a&gt; (LTCI)</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00764">
<title>3D human action analysis and recognition through GLAC descriptor on 2D motion and static posture images. (arXiv:1904.00764v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1904.00764</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we present an approach for identification of actions within
depth action videos. First, we process the video to get motion history images
(MHIs) and static history images (SHIs) corresponding to an action video based
on the use of 3D Motion Trail Model (3DMTM). We then characterize the action
video by extracting the Gradient Local Auto-Correlations (GLAC) features from
the SHIs and the MHIs. The two sets of features i.e., GLAC features from MHIs
and GLAC features from SHIs are concatenated to obtain a representation vector
for action. Finally, we perform the classification on all the action samples by
using the l2-regularized Collaborative Representation Classifier (l2-CRC) to
recognize different human actions in an effective way. We perform evaluation of
the proposed method on three action datasets, MSR-Action3D, DHA and UTD-MHAD.
Through experimental results, we observe that the proposed method performs
superior to other approaches.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bulbul_M/0/1/0/all/0/1&quot;&gt;Mohammad Farhad Bulbul&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Islam_S/0/1/0/all/0/1&quot;&gt;Saiful Islam&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ali_H/0/1/0/all/0/1&quot;&gt;Hazrat Ali&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00765">
<title>Non-rigid 3D shape retrieval based on multi-view metric learning. (arXiv:1904.00765v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1904.00765</link>
<description rdf:parseType="Literal">&lt;p&gt;This study presents a novel multi-view metric learning algorithm, which aims
to improve 3D non-rigid shape retrieval. With the development of non-rigid 3D
shape analysis, there exist many shape descriptors. The intrinsic descriptors
can be explored to construct various intrinsic representations for non-rigid 3D
shape retrieval task. The different intrinsic representations (features) focus
on different geometric properties to describe the same 3D shape, which makes
the representations are related. Therefore, it is possible and necessary to
learn multiple metrics for different representations jointly. We propose an
effective multi-view metric learning algorithm by extending the Marginal Fisher
Analysis (MFA) into the multi-view domain, and exploring Hilbert-Schmidt
Independence Criteria (HSCI) as a diversity term to jointly learning the new
metrics. The different classes can be separated by MFA in our method.
Meanwhile, HSCI is exploited to make the multiple representations to be
consensus. The learned metrics can reduce the redundancy between the multiple
representations, and improve the accuracy of the retrieval results. Experiments
are performed on SHREC&apos;10 benchmarks, and the results show that the proposed
method outperforms the state-of-the-art non-rigid 3D shape retrieval methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1&quot;&gt;Haohao Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1&quot;&gt;Shengfa Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_N/0/1/0/all/0/1&quot;&gt;Nannan Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Su_Z/0/1/0/all/0/1&quot;&gt;Zhixun Su&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1&quot;&gt;Ximin Liu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00766">
<title>A Weighted Multi-Criteria Decision Making Approach for Image Captioning. (arXiv:1904.00766v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1904.00766</link>
<description rdf:parseType="Literal">&lt;p&gt;Image captioning aims at automatically generating descriptions of an image in
natural language. This is a challenging problem in the field of artificial
intelligence that has recently received significant attention in the computer
vision and natural language processing. Among the existing approaches, visual
retrieval based methods have been proven to be highly effective. These
approaches search for similar images, then build a caption for the query image
based on the captions of the retrieved images. In this study, we present a
method for visual retrieval based image captioning, in which we use a multi
criteria decision making algorithm to effectively combine several criteria with
proportional impact weights to retrieve the most relevant caption for the query
image. The main idea of the proposed approach is to design a mechanism to
retrieve more semantically relevant captions with the query image and then
selecting the most appropriate caption by imitation of the human act based on a
weighted multi-criteria decision making algorithm. Experiments conducted on MS
COCO benchmark dataset have shown that proposed method provides much more
effective results in compare to the state-of-the-art models by using criteria
with proportional impact weights .
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Galandouz_H/0/1/0/all/0/1&quot;&gt;Hassan Maleki Galandouz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Moghaddam_M/0/1/0/all/0/1&quot;&gt;Mohsen Ebrahimi Moghaddam&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shamsfard_M/0/1/0/all/0/1&quot;&gt;Mehrnoush Shamsfard&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00767">
<title>Boosted Attention: Leveraging Human Attention for Image Captioning. (arXiv:1904.00767v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1904.00767</link>
<description rdf:parseType="Literal">&lt;p&gt;Visual attention has shown usefulness in image captioning, with the goal of
enabling a caption model to selectively focus on regions of interest. Existing
models typically rely on top-down language information and learn attention
implicitly by optimizing the captioning objectives. While somewhat effective,
the learned top-down attention can fail to focus on correct regions of interest
without direct supervision of attention. Inspired by the human visual system
which is driven by not only the task-specific top-down signals but also the
visual stimuli, we in this work propose to use both types of attention for
image captioning. In particular, we highlight the complementary nature of the
two types of attention and develop a model (Boosted Attention) to integrate
them for image captioning. We validate the proposed approach with
state-of-the-art performance across various evaluation metrics.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1&quot;&gt;Shi Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_Q/0/1/0/all/0/1&quot;&gt;Qi Zhao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00768">
<title>Concatenated Feature Pyramid Network for Instance Segmentation. (arXiv:1904.00768v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1904.00768</link>
<description rdf:parseType="Literal">&lt;p&gt;Low level features like edges and textures play an important role in
accurately localizing instances in neural networks. In this paper, we propose
an architecture which improves feature pyramid networks commonly used instance
segmentation networks by incorporating low level features in all layers of the
pyramid in an optimal and efficient way. Specifically, we introduce a new layer
which learns new correlations from feature maps of multiple feature pyramid
levels holistically and enhances the semantic information of the feature
pyramid to improve accuracy. Our architecture is simple to implement in
instance segmentation or object detection frameworks to boost accuracy. Using
this method in Mask RCNN, our model achieves consistent improvement in
precision on COCO Dataset with the computational overhead compared to the
original feature pyramid network.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1&quot;&gt;Yongqing Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+P_P/0/1/0/all/0/1&quot;&gt;Pranav Shenoy K P&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shimamura_J/0/1/0/all/0/1&quot;&gt;Jun Shimamura&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sagata_A/0/1/0/all/0/1&quot;&gt;Atsushi Sagata&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00770">
<title>Netherlands Dataset: A New Public Dataset for Machine Learning in Seismic Interpretation. (arXiv:1904.00770v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1904.00770</link>
<description rdf:parseType="Literal">&lt;p&gt;Machine learning and, more specifically, deep learning algorithms have seen
remarkable growth in their popularity and usefulness in the last years. This is
arguably due to three main factors: powerful computers, new techniques to train
deeper networks and larger datasets. Although the first two are readily
available in modern computers and ML libraries, the last one remains a
challenge for many domains. It is a fact that big data is a reality in almost
all fields nowadays, and geosciences are not an exception. However, to achieve
the success of general-purpose applications such as ImageNet - for which there
are +14 million labeled images for 1000 target classes - we not only need more
data, we need more high-quality labeled data. When it comes to the Oil&amp;amp;Gas
industry, confidentiality issues hamper even more the sharing of datasets. In
this work, we present the Netherlands interpretation dataset, a contribution to
the development of machine learning in seismic interpretation. The Netherlands
F3 dataset acquisition was carried out in the North Sea, Netherlands offshore.
The data is publicly available and contains pos-stack data, 8 horizons and well
logs of 4 wells. For the purposes of our machine learning tasks, the original
dataset was reinterpreted, generating 9 horizons separating different seismic
facies intervals. The interpreted horizons were used to generate approximatelly
190,000 labeled images for inlines and crosslines. Finally, we present two deep
learning applications in which the proposed dataset was employed and produced
compelling results.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Silva_R/0/1/0/all/0/1&quot;&gt;Reinaldo Mozart Silva&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Baroni_L/0/1/0/all/0/1&quot;&gt;Lais Baroni&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ferreira_R/0/1/0/all/0/1&quot;&gt;Rodrigo S. Ferreira&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Civitarese_D/0/1/0/all/0/1&quot;&gt;Daniel Civitarese&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Szwarcman_D/0/1/0/all/0/1&quot;&gt;Daniela Szwarcman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Brazil_E/0/1/0/all/0/1&quot;&gt;Emilio Vital Brazil&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00771">
<title>Training Multi-Speaker Neural Text-to-Speech Systems using Speaker-Imbalanced Speech Corpora. (arXiv:1904.00771v1 [eess.AS])</title>
<link>http://arxiv.org/abs/1904.00771</link>
<description rdf:parseType="Literal">&lt;p&gt;When the available data of a target speaker is insufficient to train a high
quality speaker-dependent neural text-to-speech (TTS) system, we can combine
data from multiple speakers and train a multi-speaker TTS model instead. Many
studies have shown that neural multi-speaker TTS model trained with a small
amount data from multiple speakers combined can generate synthetic speech with
better quality and stability than a speaker-dependent one. However when the
amount of data from each speaker is highly unbalanced, the best approach to
make use of the excessive data remains unknown. Our experiments showed that
simply combining all available data from every speaker to train a multi-speaker
model produces better than or at least similar performance to its
speaker-dependent counterpart. Moreover by using an ensemble multi-speaker
model, in which each subsystem is trained on a subset of available data, we can
further improve the quality of the synthetic speech especially for
underrepresented speakers whose training data is limited.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Luong_H/0/1/0/all/0/1&quot;&gt;Hieu-Thi Luong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Wang_X/0/1/0/all/0/1&quot;&gt;Xin Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Yamagishi_J/0/1/0/all/0/1&quot;&gt;Junichi Yamagishi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Nishizawa_N/0/1/0/all/0/1&quot;&gt;Nobuyuki Nishizawa&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00775">
<title>Deep Demosaicing for Edge Implementation. (arXiv:1904.00775v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1904.00775</link>
<description rdf:parseType="Literal">&lt;p&gt;Most digital cameras use sensors coated with a Color Filter Array (CFA) to
capture channel components at every pixel location, resulting in a mosaic image
that does not contain pixel values in all channels. Current research on
reconstructing these missing channels, also known as demosaicing, introduces
many artifacts, such as zipper effect and false color. Many deep learning
demosaicing techniques outperform other classical techniques in reducing the
impact of artifacts. However, most of these models tend to be
over-parametrized. Consequently, edge implementation of the state-of-the-art
deep learning-based demosaicing algorithms on low-end edge devices is a major
challenge. We provide an exhaustive search of deep neural network architectures
and obtain a pareto front of Color Peak Signal to Noise Ratio (CPSNR) as the
performance criterion versus the number of parameters as the model complexity
that beats the state-of-the-art. Architectures on the pareto front can then be
used to choose the best architecture for a variety of resource constraints.
Simple architecture search methods such as exhaustive search and grid search
require some conditions of the loss function to converge to the optimum. We
clarify these conditions in a brief theoretical study.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ramakrishnan_R/0/1/0/all/0/1&quot;&gt;Ramchalam Kinattinkara Ramakrishnan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shangling_J/0/1/0/all/0/1&quot;&gt;Jui Shangling&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nia_V/0/1/0/all/0/1&quot;&gt;Vahid Patrovi Nia&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00776">
<title>Cross-modal subspace learning with Kernel correlation maximization and Discriminative structure preserving. (arXiv:1904.00776v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1904.00776</link>
<description rdf:parseType="Literal">&lt;p&gt;The measure between heterogeneous data is still an open problem. Many
research works have been developed to learn a common subspace where the
similarity between different modalities can be calculated. However, most of
existing works focus on learning low dimensional subspace and ignore the loss
of discriminative information in process of reducing dimension. Thus, these
approaches cannot get the results they expected. On basis of the Hilbert space
theory in which different Hilbert spaces but with same dimension are
isomorphic, we propose a novel framework where the multiple use of label
information can facilitate more discriminative subspace representation to learn
isomorphic Hilbert space for each modal. Our model not only considers the
inter-modality correlation by maximizing the kernel correlation, but also
preserves the structure information within each modal according to constructed
graph model. Extensive experiments are performed to evaluate the proposed
framework, termed Cross-modal subspace learning with Kernel correlation
maximization and Discriminative structure preserving (CKD), on the three public
datasets. Experimental results demonstrated the competitive performance of the
proposed CKD compared with the classic subspace learning methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_J/0/1/0/all/0/1&quot;&gt;Jun Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1&quot;&gt;Xiao-Jun Wu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00781">
<title>Efficient Incremental Learning for Mobile Object Detection. (arXiv:1904.00781v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1904.00781</link>
<description rdf:parseType="Literal">&lt;p&gt;Object detection models shipped with camera-equipped mobile devices cannot
cover the objects of interest for every user. Therefore, the incremental
learning capability is a critical feature for a robust and personalized mobile
object detection system that many applications would rely on. In this paper, we
present an efficient yet practical system, IMOD, to incrementally train an
existing object detection model such that it can detect new object classes
without losing its capability to detect old classes. The key component of IMOD
is a novel incremental learning algorithm that trains end-to-end for one-stage
object detection deep models only using training data of new object classes.
Specifically, to avoid catastrophic forgetting, the algorithm distills three
types of knowledge from the old model to mimic the old model&apos;s behavior on
object classification, bounding box regression and feature extraction. In
addition, since the training data for the new classes may not be available, a
real-time dataset construction pipeline is designed to collect training images
on-the-fly and automatically label the images with both category and bounding
box annotations. We have implemented IMOD under both mobile-cloud and
mobile-only setups. Experiment results show that the proposed system can learn
to detect a new object class in just a few minutes, including both dataset
construction and model training. In comparison, traditional fine-tuning based
method may take a few hours for training, and in most cases would also need a
tedious and costly manual dataset labeling step.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_D/0/1/0/all/0/1&quot;&gt;Dawei Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tasci_S/0/1/0/all/0/1&quot;&gt;Serafettin Tasci&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ghosh_S/0/1/0/all/0/1&quot;&gt;Shalini Ghosh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1&quot;&gt;Jingwen Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1&quot;&gt;Junting Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Heck_L/0/1/0/all/0/1&quot;&gt;Larry Heck&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00783">
<title>Implementation of Fruits Recognition Classifier using Convolutional Neural Network Algorithm for Observation of Accuracies for Various Hidden Layers. (arXiv:1904.00783v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1904.00783</link>
<description rdf:parseType="Literal">&lt;p&gt;Fruit recognition using Deep Convolutional Neural Network (CNN) is one of the
most promising applications in computer vision. In recent times, deep learning
based classifications are making it possible to recognize fruits from images.
However, fruit recognition is still a problem for the stacked fruits on
weighing scale because of the complexity and similarity. In this paper, a fruit
recognition system using CNN is proposed. The proposed method uses deep
learning techniques for the classification. We have used Fruits-360 dataset for
the evaluation purpose. From the dataset, we have established a dataset which
contains 17,823 images from 25 different categories. The images are divided
into training and test dataset. Moreover, for the classification accuracies, we
have used various combinations of hidden layer and epochs for different cases
and made a comparison between them. The overall performance losses of the
network for different cases also observed. Finally, we have achieved the best
test accuracy of 100% and a training accuracy of 99.79%.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sakib_S/0/1/0/all/0/1&quot;&gt;Shadman Sakib&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ashrafi_Z/0/1/0/all/0/1&quot;&gt;Zahidun Ashrafi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Siddique_M/0/1/0/all/0/1&quot;&gt;Md. Abu Bakr Siddique&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00784">
<title>A Survey of Code-switched Speech and Language Processing. (arXiv:1904.00784v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1904.00784</link>
<description rdf:parseType="Literal">&lt;p&gt;Code-switching, the alternation of languages within a conversation or
utterance, is a common communicative phenomenon that occurs in multilingual
communities across the world. This survey reviews computational approaches for
code-switched Speech and Natural Language Processing. We motivate why
processing code-switched text and speech is essential for building intelligent
agents and systems that interact with users in multilingual communities. As
code-switching data and resources are scarce, we list what is available in
various code-switched language pairs with the language processing tasks they
can be used for. We review code-switching research in various Speech and NLP
applications, including language processing tools and end-to-end systems. We
conclude with future directions and open problems in the field.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sitaram_S/0/1/0/all/0/1&quot;&gt;Sunayana Sitaram&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chandu_K/0/1/0/all/0/1&quot;&gt;Khyathi Raghavi Chandu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rallabandi_S/0/1/0/all/0/1&quot;&gt;Sai Krishna Rallabandi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Black_A/0/1/0/all/0/1&quot;&gt;Alan W Black&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00785">
<title>Question Embeddings Based on Shannon Entropy: Solving intent classification task in goal-oriented dialogue system. (arXiv:1904.00785v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1904.00785</link>
<description rdf:parseType="Literal">&lt;p&gt;Question-answering systems and voice assistants are becoming major part of
client service departments of many organizations, helping them to reduce the
labor costs of staff. In many such systems, there is always natural language
understanding module that solves intent classification task. This task is
complicated because of its case-dependency - every subject area has its own
semantic kernel. The state of art approaches for intent classification are
different machine learning and deep learning methods that use text vector
representations as input. The basic vector representation models such as Bag of
words and TF-IDF generate sparse matrixes, which are becoming very big as the
amount of input data grows. Modern methods such as word2vec and FastText use
neural networks to evaluate word embeddings with fixed dimension size. As we
are developing a question-answering system for students and enrollees of the
Perm National Research Polytechnic University, we have faced the problem of
user&apos;s intent detection. The subject area of our system is very specific, that
is why there is a lack of training data. This aspect makes intent
classification task more challenging for using state of the art deep learning
methods. In this paper, we propose an approach of the questions embeddings
representation based on calculation of Shannon entropy.The goal of the approach
is to produce low dimensional question vectors as neural approaches do and to
outperform related methods, described above in condition of small dataset. We
evaluate and compare our model with existing ones using logistic regression and
dataset that contains questions asked by students and enrollees. The data is
labeled into six classes. Experimental comparison of proposed approach and
other models revealed that proposed model performed better in the given task.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Perevalov_A/0/1/0/all/0/1&quot;&gt;Aleksandr Perevalov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kurushin_D/0/1/0/all/0/1&quot;&gt;Daniil Kurushin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Faizrakhmanov_R/0/1/0/all/0/1&quot;&gt;Rustam Faizrakhmanov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khabibrakhmanova_F/0/1/0/all/0/1&quot;&gt;Farida Khabibrakhmanova&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00786">
<title>Improved Dynamic Time Warping (DTW) Approach for Online Signature Verification. (arXiv:1904.00786v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1904.00786</link>
<description rdf:parseType="Literal">&lt;p&gt;Online signature verification is the process of verifying time series
signature data which is generally obtained from the tablet-based device. Unlike
offline signature images, the online signature image data consists of points
that are arranged in a sequence of time. The aim of this research is to develop
an improved approach to map the strokes in both test and reference signatures.
Current methods make use of the Dynamic Time Warping (DTW) algorithm and its
variant to segment them before comparing each of its data dimension. This paper
presents a modified DTW algorithm with the proposed Lost Box Recovery Algorithm
aims to improve the mapping performance for online signature verification
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jaini_A/0/1/0/all/0/1&quot;&gt;Azhar Ahmad Jaini&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sulong_G/0/1/0/all/0/1&quot;&gt;Ghazali Sulong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rehman_A/0/1/0/all/0/1&quot;&gt;Amjad Rehman&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00787">
<title>CUSUM Filter for Brain Segmentation on DSC Perfusion MR Head Scans with Abnormal Brain Anatomy. (arXiv:1904.00787v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1904.00787</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper presents a new approach for relatively accurate brain region of
interest (ROI) detection from dynamic susceptibility contrast (DSC) perfusion
magnetic resonance (MR) images of a human head with abnormal brain anatomy.
Such images produce problems for automatic brain segmentation algorithms, and
as a result, poor perfusion ROI detection affects both quantitative
measurements and visual assessment of perfusion data. In the proposed approach
image segmentation is based on CUSUM filter usage that was adapted to be
applicable to process DSC perfusion MR images. The result of segmentation is a
binary mask of brain ROI that is generated via usage of brain boundary
location. Each point of the boundary between the brain and surrounding tissues
is detected as a change-point by CUSUM filter. Proposed adopted CUSUM filter
operates by accumulating the deviations between the observed and expected
intensities of image points at the time of moving on a trajectory. Motion
trajectory is created by the iterative change of movement direction inside the
background region in order to reach brain region, and vice versa after boundary
crossing. Proposed segmentation approach was evaluated with Dice index
comparing obtained results to the reference standard. Manually marked brain
region pixels (reference standard), as well as visual inspection of detected
with CUSUM filter usage brain ROI, were provided by experienced radiologists.
The results showed that proposed approach is suitable to be used for brain ROI
detection from DSC perfusion MR images of a human head with abnormal brain
anatomy and can, therefore, be applied in the DSC perfusion data analysis.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Alkhimova_S/0/1/0/all/0/1&quot;&gt;Svitlana Alkhimova&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00788">
<title>Neural Abstractive Text Summarization and Fake News Detection. (arXiv:1904.00788v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1904.00788</link>
<description rdf:parseType="Literal">&lt;p&gt;In this work, we study abstractive text summarization by exploring different
models such as LSTM-encoder-decoder with attention, pointer-generator networks,
coverage mechanisms, and transformers. Upon extensive and careful
hyperparameter tuning we compare the proposed architectures against each other
for the abstractive text summarization task. Finally, as an extension of our
work, we apply our text summarization model as a feature extractor for a fake
news detection task where the news articles prior to classification will be
summarized and the results are compared against the classification using only
the original news text.
&lt;/p&gt;
&lt;p&gt;keywords: abstractive text summarization, pointer-generator, coverage
mechanism, transformers, fake news detection
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Esmaeilzadeh_S/0/1/0/all/0/1&quot;&gt;Soheil Esmaeilzadeh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Peh_G/0/1/0/all/0/1&quot;&gt;Gao Xian Peh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_A/0/1/0/all/0/1&quot;&gt;Angela Xu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00790">
<title>Retinal OCT disease classification with variational autoencoder regularization. (arXiv:1904.00790v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1904.00790</link>
<description rdf:parseType="Literal">&lt;p&gt;According to the World Health Organization, 285 million people worldwide live
with visual impairment. The most commonly used imaging technique for diagnosis
in ophthalmology is optical coherence tomography (OCT). However, analysis of
retinal OCT requires trained ophthalmologists and time, making a comprehensive
early diagnosis unlikely. A recent study established a diagnostic tool based on
convolutional neural networks (CNN), which was trained on a large database of
retinal OCT images. The performance of the tool in classifying retinal
conditions was on par to that of trained medical experts. However, the training
of these networks is based on an enormous amount of labeled data, which is
expensive and difficult to obtain. Therefore, this paper describes a method
based on variational autoencoder regularization that improves classification
performance when using a limited amount of labeled data. This work uses a
two-path CNN model combining a classification network with an autoencoder (AE)
for regularization. The key idea behind this is to prevent overfitting when
using a limited training dataset size with small number of patients. Results
show superior classification performance compared to a pre-trained and fully
fine-tuned baseline ResNet-34. Clustering of the latent space in relation to
the disease class is distinct. Neural networks for disease classification on
OCTs can benefit from regularization using variational autoencoders when
trained with limited amount of patient data. Especially in the medical imaging
domain, data annotated by experts is expensive to obtain.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Laves_M/0/1/0/all/0/1&quot;&gt;Max-Heinrich Laves&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ihler_S/0/1/0/all/0/1&quot;&gt;Sontje Ihler&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kahrs_L/0/1/0/all/0/1&quot;&gt;L&amp;#xfc;der A. Kahrs&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ortmaier_T/0/1/0/all/0/1&quot;&gt;Tobias Ortmaier&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00791">
<title>DSL: Discriminative Subgraph Learning via Sparse Self-Representation. (arXiv:1904.00791v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1904.00791</link>
<description rdf:parseType="Literal">&lt;p&gt;The goal in network state prediction (NSP) is to classify the global state
(label) associated with features embedded in a graph. This graph structure
encoding feature relationships is the key distinctive aspect of NSP compared to
classical supervised learning. NSP arises in various applications: gene
expression samples embedded in a protein-protein interaction (PPI) network,
temporal snapshots of infrastructure or sensor networks, and fMRI coherence
network samples from multiple subjects to name a few. Instances from these
domains are typically ``wide&apos;&apos; (more features than samples), and thus, feature
sub-selection is required for robust and generalizable prediction. How to best
employ the network structure in order to learn succinct connected subgraphs
encompassing the most discriminative features becomes a central challenge in
NSP. Prior work employs connected subgraph sampling or graph smoothing within
optimization frameworks, resulting in either large variance of quality or weak
control over the connectivity of selected subgraphs.
&lt;/p&gt;
&lt;p&gt;In this work we propose an optimization framework for discriminative subgraph
learning (DSL) which simultaneously enforces (i) sparsity, (ii) connectivity
and (iii) high discriminative power of the resulting subgraphs of features. Our
optimization algorithm is a single-step solution for the NSP and the associated
feature selection problem. It is rooted in the rich literature on
maximal-margin optimization, spectral graph methods and sparse subspace
self-representation. DSL simultaneously ensures solution interpretability and
superior predictive power (up to 16% improvement in challenging instances
compared to baselines), with execution times up to an hour for large instances.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1&quot;&gt;Lin Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bogdanov_P/0/1/0/all/0/1&quot;&gt;Petko Bogdanov&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00792">
<title>Cursive Overlapped Character Segmentation: An Enhanced Approach. (arXiv:1904.00792v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1904.00792</link>
<description rdf:parseType="Literal">&lt;p&gt;Segmentation of highly slanted and horizontally overlapped characters is a
challenging research area that is still fresh. Several techniques are reported
in the state of art, but produce low accuracy for the highly slanted characters
segmentation and cause overall low handwriting recognition precision.
Accordingly, this paper presents a simple yet effective approach for character
segmentation of such difficult slanted cursive words without using any slant
correction technique. Rather a new concept of core-zone is introduced for
segmenting such difficult slanted handwritten words. However, due to the
inherent nature of cursive words, few characters are over-segmented and
therefore, a threshold is selected heuristically to overcome this problem. For
fair comparison, difficult words are extracted from the IAM benchmark database.
Experiments thus performed exhibit promising result and high speed.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rehman_A/0/1/0/all/0/1&quot;&gt;Amjad Rehman&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00796">
<title>Making Neural Machine Reading Comprehension Faster. (arXiv:1904.00796v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1904.00796</link>
<description rdf:parseType="Literal">&lt;p&gt;This study aims at solving the Machine Reading Comprehension problem where
questions have to be answered given a context passage. The challenge is to
develop a computationally faster model which will have improved inference time.
State of the art in many natural language understanding tasks, BERT model, has
been used and knowledge distillation method has been applied to train two
smaller models. The developed models are compared with other models which have
been developed with the same intention.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chatterjee_D/0/1/0/all/0/1&quot;&gt;Debajyoti Chatterjee&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00800">
<title>Private Shotgun DNA Sequencing: A Structured Approach. (arXiv:1904.00800v1 [cs.IT])</title>
<link>http://arxiv.org/abs/1904.00800</link>
<description rdf:parseType="Literal">&lt;p&gt;Current techniques in sequencing a genome allow a service provider (e.g. a
sequencing company) to have full access to the genome information, and thus the
privacy of individuals regarding their lifetime secret is violated. In this
paper, we introduce the problem of private DNA sequencing and propose a
sequencing scheme to keep the genome information private at the service
provider. In this technique, rather than a single sequencer (i.e. sequencing
machine), a set of multiple sequencers is used. Then to each sequencer, a set
of DNA fragments belonging to a pool of individuals is assigned to be read.
However, the assignment is such that each sequencer cannot reconstruct each
individuals sequence. Still, when the results of the reads are collected at a
data collector, the reconstruction is possible. To increase the ambiguity at
the sequencers, we add the fragments of some known DNA molecules, which are
still unknown to the sequencers, to the pool. In continue, we show that it is
possible to recover the genome with provable privacy guarantees if the
parameters are adjusted correctly.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gholami_A/0/1/0/all/0/1&quot;&gt;Ali Gholami&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Maddah_Ali_M/0/1/0/all/0/1&quot;&gt;Mohammad Ali Maddah-Ali&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Motahari_S/0/1/0/all/0/1&quot;&gt;Seyed Abolfazl Motahari&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00805">
<title>A Convolutional Neural Network for Language-Agnostic Source Code Summarization. (arXiv:1904.00805v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1904.00805</link>
<description rdf:parseType="Literal">&lt;p&gt;Descriptive comments play a crucial role in the software engineering process.
They decrease development time, enable better bug detection, and facilitate the
reuse of previously written code. However, comments are commonly the last of a
software developer&apos;s priorities and are thus either insufficient or missing
entirely. Automatic source code summarization may therefore have the ability to
significantly improve the software development process. We introduce a novel
encoder-decoder model that summarizes source code, effectively writing a
comment to describe the code&apos;s functionality. We make two primary innovations
beyond current source code summarization models. First, our encoder is fully
language-agnostic and requires no complex input preprocessing. Second, our
decoder has an open vocabulary, enabling it to predict any word, even ones not
seen in training. We demonstrate results comparable to state-of-the-art methods
on a single-language data set and provide the first results on a data set
consisting of multiple programming languages.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Moore_J/0/1/0/all/0/1&quot;&gt;Jessica Moore&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gelman_B/0/1/0/all/0/1&quot;&gt;Ben Gelman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Slater_D/0/1/0/all/0/1&quot;&gt;David Slater&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00812">
<title>Polysemy and brevity versus frequency in language. (arXiv:1904.00812v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1904.00812</link>
<description rdf:parseType="Literal">&lt;p&gt;The pioneering research of G. K. Zipf on the relationship between word
frequency and other word features led to the formulation of various linguistic
laws. The most popular is Zipf&apos;s law for word frequencies. Here we focus on two
laws that have been studied less intensively: the meaning-frequency law, i.e.
the tendency of more frequent words to be more polysemous, and the law of
abbreviation, i.e. the tendency of more frequent words to be shorter. In a
previous work, we tested the robustness of these Zipfian laws for English,
roughly measuring word length in number of characters and distinguishing adult
from child speech. In the present article, we extend our study to other
languages (Dutch and Spanish) and introduce two additional measures of length:
syllabic length and phonemic length. Our correlation analysis indicates that
both the meaning-frequency law and the law of abbreviation hold overall in all
the analyzed languages.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Casas_B/0/1/0/all/0/1&quot;&gt;Bernardino Casas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hernandez_Fernandez_A/0/1/0/all/0/1&quot;&gt;Antoni Hern&amp;#xe1;ndez-Fern&amp;#xe1;ndez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Catala_N/0/1/0/all/0/1&quot;&gt;Neus Catal&amp;#xe0;&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ferrer_i_Cancho_R/0/1/0/all/0/1&quot;&gt;Ramon Ferrer-i-Cancho&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Baixeries_J/0/1/0/all/0/1&quot;&gt;Jaume Baixeries&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00813">
<title>Tightness-aware Evaluation Protocol for Scene Text Detection. (arXiv:1904.00813v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1904.00813</link>
<description rdf:parseType="Literal">&lt;p&gt;Evaluation protocols play key role in the developmental progress of text
detection methods. There are strict requirements to ensure that the evaluation
methods are fair, objective and reasonable. However, existing metrics exhibit
some obvious drawbacks: 1) They are not goal-oriented; 2) they cannot recognize
the tightness of detection methods; 3) existing one-to-many and many-to-one
solutions involve inherent loopholes and deficiencies. Therefore, this paper
proposes a novel evaluation protocol called Tightness-aware
Intersect-over-Union (TIoU) metric that could quantify completeness of ground
truth, compactness of detection, and tightness of matching degree.
Specifically, instead of merely using the IoU value, two common detection
behaviors are properly considered; meanwhile, directly using the score of TIoU
to recognize the tightness. In addition, we further propose a straightforward
method to address the annotation granularity issue, which can fairly evaluate
word and text-line detections simultaneously. By adopting the detection results
from published methods and general object detection frameworks, comprehensive
experiments on ICDAR 2013 and ICDAR 2015 datasets are conducted to compare
recent metrics and the proposed TIoU metric. The comparison demonstrated some
promising new prospects, e.g., determining the methods and frameworks for which
the detection is tighter and more beneficial to recognize. Our method is
extremely simple; however, the novelty is none other than the proposed metric
can utilize simplest but reasonable improvements to lead to many interesting
and insightful prospects and solving most the issues of the previous metrics.
The code is publicly available at https://github.com/Yuliang-Liu/TIoU-metric .
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1&quot;&gt;Yuliang Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jin_L/0/1/0/all/0/1&quot;&gt;Lianwen Jin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xie_Z/0/1/0/all/0/1&quot;&gt;Zecheng Xie&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Luo_C/0/1/0/all/0/1&quot;&gt;Canjie Luo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1&quot;&gt;Shuaitao Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xie_L/0/1/0/all/0/1&quot;&gt;Lele Xie&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00815">
<title>Understanding Unconventional Preprocessors in Deep Convolutional Neural Networks for Face Identification. (arXiv:1904.00815v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1904.00815</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep networks have achieved huge successes in application domains like object
and face recognition. The performance gain is attributed to different facets of
the network architecture such as: depth of the convolutional layers, activation
function, pooling, batch normalization, forward and back propagation and many
more. However, very little emphasis is made on the preprocessors. Therefore, in
this paper, the network&apos;s preprocessing module is varied across different
preprocessing approaches while keeping constant other facets of the network
architecture, to investigate the contribution preprocessing makes to the
network. Commonly used preprocessors are the data augmentation and
normalization and are termed conventional preprocessors. Others are termed the
unconventional preprocessors, they are: color space converters; HSV, CIE L*a*b*
and YCBCR, grey-level resolution preprocessors; full-based and plane-based
image quantization, illumination normalization and insensitive feature
preprocessing using: histogram equalization (HE), local contrast normalization
(LN) and complete face structural pattern (CFSP). To achieve fixed network
parameters, CNNs with transfer learning is employed. Knowledge from the
high-level feature vectors of the Inception-V3 network is transferred to
offline preprocessed LFW target data; and features trained using the SoftMax
classifier for face identification. The experiments show that the
discriminative capability of the deep networks can be improved by preprocessing
RGB data with HE, full-based and plane-based quantization, rgbGELog, and YCBCR,
preprocessors before feeding it to CNNs. However, for best performance, the
right setup of preprocessed data with augmentation and/or normalization is
required. The plane-based image quantization is found to increase the
homogeneity of neighborhood pixels and utilizes reduced bit depth for better
storage efficiency.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Olisah_C/0/1/0/all/0/1&quot;&gt;Chollette C. Olisah&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Smith_L/0/1/0/all/0/1&quot;&gt;Lyndon Smith&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00816">
<title>k-Same-Siamese-GAN: k-Same Algorithm with Generative Adversarial Network for Facial Image De-identification with Hyperparameter Tuning and Mixed Precision Training. (arXiv:1904.00816v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1904.00816</link>
<description rdf:parseType="Literal">&lt;p&gt;In recent years, advances in camera and computing hardware have made it easy
to capture and store amounts of image and video data. Consider a data holder,
such as a hospital or a government entity, who has a privately held collection
of personal data. Then, how can we ensure that the data holder does conceal the
identity of each individual in the imagery of personal data while still
preserving certain useful aspects of the data after de-identification? In this
work, we proposed a novel approach towards high-resolution facial image
de-identification, called k-Same-Siamese-GAN (kSS-GAN), which leverages
k-Same-Anonymity mechanism, Generative Adversarial Network (GAN), and
hyperparameter tuning. To speed up training and reduce memory consumption, the
mixed precision training (MPT) technique is also applied to make kSS-GAN
provide guarantees regarding privacy protection on close-form identities and be
trained much more efficiently as well. Finally, we dedicated our system to an
actual dataset: RafD dataset for performance testing. Besides protecting
privacy of high resolution of facial images, the proposed system is also
justified for its ability in automating parameter tuning and breaking through
the limitation of the number of adjustable parameters.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pan_Y/0/1/0/all/0/1&quot;&gt;Yi-Lun Pan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Haung_M/0/1/0/all/0/1&quot;&gt;Min-Jhih Haung&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ding_K/0/1/0/all/0/1&quot;&gt;Kuo-Teng Ding&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1&quot;&gt;Ja-Ling Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jang_J/0/1/0/all/0/1&quot;&gt;Jyh-Shing Jang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00817">
<title>DeepPoint3D: Learning Discriminative Local Descriptors using Deep Metric Learning on 3D Point Clouds. (arXiv:1904.00817v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1904.00817</link>
<description rdf:parseType="Literal">&lt;p&gt;Learning local descriptors is an important problem in computer vision. While
there are many techniques for learning local patch descriptors for 2D images,
recently efforts have been made for learning local descriptors for 3D points.
The recent progress towards solving this problem in 3D leverages the strong
feature representation capability of image based convolutional neural networks
by utilizing RGB-D or multi-view representations. However, in this paper, we
propose to learn 3D local descriptors by directly processing unstructured 3D
point clouds without needing any intermediate representation. The method
constitutes a deep network for learning permutation invariant representation of
3D points. To learn the local descriptors, we use a multi-margin contrastive
loss which discriminates between similar and dissimilar points on a surface
while also leveraging the extent of dissimilarity among the negative samples at
the time of training. With comprehensive evaluation against strong baselines,
we show that the proposed method outperforms state-of-the-art methods for
matching points in 3D point clouds. Further, we demonstrate the effectiveness
of the proposed method on various applications achieving state-of-the-art
results.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Srivastava_S/0/1/0/all/0/1&quot;&gt;Siddharth Srivastava&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lall_B/0/1/0/all/0/1&quot;&gt;Brejesh Lall&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00818">
<title>COCO\_TS Dataset: Pixel--level Annotations Based on Weak Supervision for Scene Text Segmentation. (arXiv:1904.00818v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1904.00818</link>
<description rdf:parseType="Literal">&lt;p&gt;The absence of large scale datasets with pixel-level supervisions is a
significant obstacle for the training of deep convolutional networks for scene
text segmentation. For this reason, synthetic data generation is normally
employed to enlarge the training dataset. Nonetheless, synthetic data cannot
reproduce the complexity and variability of natural images. In this paper, a
weakly supervised learning approach is used to reduce the shift between
training on real and synthetic data. Pixel-level supervisions for a text
detection dataset (i.e. where only bounding-box annotations are available) are
generated. In particular, the COCO-Text-Segmentation (COCO_TS) dataset, which
provides pixel-level supervisions for the COCO-Text dataset, is created and
released. The generated annotations are used to train a deep convolutional
neural network for semantic segmentation. Experiments show that the proposed
dataset can be used instead of synthetic data, allowing us to use only a
fraction of the training samples and significantly improving the performances.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bonechi_S/0/1/0/all/0/1&quot;&gt;Simone Bonechi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Andreini_P/0/1/0/all/0/1&quot;&gt;Paolo Andreini&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bianchini_M/0/1/0/all/0/1&quot;&gt;Monica Bianchini&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Scarselli_F/0/1/0/all/0/1&quot;&gt;Franco Scarselli&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00820">
<title>A Game-Theoretic Framework for Resource Sharing in Clouds. (arXiv:1904.00820v1 [cs.MA])</title>
<link>http://arxiv.org/abs/1904.00820</link>
<description rdf:parseType="Literal">&lt;p&gt;Providing resources to different users or applications is fundamental to
cloud computing. This is a challenging problem as a cloud service provider may
have insufficient resources to satisfy all user requests. Furthermore,
allocating available resources optimally to different applications is also
challenging. Resource sharing among different cloud service providers can
improve resource availability and resource utilization as certain cloud service
providers may have free resources available that can be ``rented&apos;&apos; by other
service providers. However, different cloud service providers can have
different objectives or \emph{utilities}. Therefore, there is a need for a
framework that can share and allocate resources in an efficient and effective
way, while taking into account the objectives of various service providers that
results in a \emph{multi-objective optimization} problem. In this paper, we
present a \emph{Cooperative Game Theory} (CGT) based framework for resource
sharing and allocation among different service providers with varying
objectives that form a coalition. We show that the resource sharing problem can
be modeled as an $N-$player \emph{canonical} cooperative game with
\emph{non-transferable utility} (NTU) and prove that the game is convex for
monotonic non-decreasing utilities. We propose an $\mathcal{O}({N})$ algorithm
that provides an allocation from the \emph{core}, hence guaranteeing
\emph{Pareto optimality}. We evaluate the performance of our proposed resource
sharing framework in a number of simulation settings and show that our proposed
framework improves user satisfaction and utility of service providers.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zafari_F/0/1/0/all/0/1&quot;&gt;Faheem Zafari&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Leung_K/0/1/0/all/0/1&quot;&gt;Kin K. Leung&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Towsley_D/0/1/0/all/0/1&quot;&gt;Don Towsley&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Basu_P/0/1/0/all/0/1&quot;&gt;Prithwish Basu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Swami_A/0/1/0/all/0/1&quot;&gt;Ananthram Swami&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00824">
<title>Training Object Detectors on Synthetic Images Containing Reflecting Materials. (arXiv:1904.00824v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1904.00824</link>
<description rdf:parseType="Literal">&lt;p&gt;One of the grand challenges of deep learning is the requirement to obtain
large labeled training data sets. While synthesized data sets can be used to
overcome this challenge, it is important that these data sets close the reality
gap, i.e., a model trained on synthetic image data is able to generalize to
real images. Whereas, the reality gap can be considered bridged in several
application scenarios, training on synthesized images containing reflecting
materials requires further research. Since the appearance of objects with
reflecting materials is dominated by the surrounding environment, this
interaction needs to be considered during training data generation. Therefore,
within this paper we examine the effect of reflecting materials in the context
of synthetic image generation for training object detectors. We investigate the
influence of rendering approach used for image synthesis, the effect of domain
randomization, as well as the amount of used training data. To be able to
compare our results to the state-of-the-art, we focus on indoor scenes as they
have been investigated extensively. Within this scenario, bathroom furniture is
a natural choice for objects with reflecting materials, for which we report our
findings on real and synthetic testing data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hartwig_S/0/1/0/all/0/1&quot;&gt;Sebastian Hartwig&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ropinski_T/0/1/0/all/0/1&quot;&gt;Timo Ropinski&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00825">
<title>Simple unity among the fundamental equations of science. (arXiv:1904.00825v1 [q-bio.PE])</title>
<link>http://arxiv.org/abs/1904.00825</link>
<description rdf:parseType="Literal">&lt;p&gt;The Price equation describes the change in populations. Change concerns some
value, such as biological fitness, information or physical work. The Price
equation reveals universal aspects for the nature of change, independently of
the meaning ascribed to values. By understanding those universal aspects, we
can see more clearly why fundamental mathematical results in different
disciplines often share a common form. We can also interpret more clearly the
meaning of key results within each discipline. For example, the mathematics of
natural selection in biology has a form closely related to information theory
and physical entropy. Does that mean that natural selection is about
information or entropy? Or do natural selection, information and entropy arise
as interpretations of a common underlying abstraction? The Price equation
suggests the latter. The Price equation achieves its abstract generality by
partitioning change into two terms. The first term naturally associates with
the direct forces that cause change. The second term naturally associates with
the changing frame of reference. In the Price equation&apos;s canonical form, total
change remains zero because the conservation of total probability requires that
all probabilities invariantly sum to one. Much of the shared common form for
the mathematics of different disciplines may arise from that seemingly trivial
invariance of total probability, which leads to the partitioning of total
change into equal and opposite components of the direct forces and the changing
frame of reference.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Frank_S/0/1/0/all/0/1&quot;&gt;Steven A. Frank&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00827">
<title>Categories with Families: Unityped, Simply Typed, and Dependently Typed. (arXiv:1904.00827v1 [cs.LO])</title>
<link>http://arxiv.org/abs/1904.00827</link>
<description rdf:parseType="Literal">&lt;p&gt;We show how the categorical logic of untyped, simply typed and dependently
typed lambda calculus can be structured around the notion of category with
family (cwf). To this end we introduce subcategories of simply typed cwfs
(scwfs), where types do not depend on variables, and unityped cwfs (ucwfs),
where there is only one type. We prove several equivalence and biequivalence
theorems between cwf-based notions and basic notions of categorical logic, such
as cartesian operads, Lawvere theories, categories with finite products and
limits, cartesian closed categories, and locally cartesian closed categories.
Some of these theorems depend on the restrictions of contextuality (in the
sense of Cartmell) or democracy (used by Clairambault and Dybjer for their
biequivalence theorems). Some theorems are equivalences between notions with
strict preservation of chosen structure. Others are biequivalences between
notions where properties are only preserved up to isomorphism. In addition to
this we discuss various constructions of initial ucwfs, scwfs, and cwfs with
extra structure.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Castellan_S/0/1/0/all/0/1&quot;&gt;Simon Castellan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Clairambault_P/0/1/0/all/0/1&quot;&gt;Pierre Clairambault&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dybjer_P/0/1/0/all/0/1&quot;&gt;Peter Dybjer&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00830">
<title>Depth-Aware Video Frame Interpolation. (arXiv:1904.00830v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1904.00830</link>
<description rdf:parseType="Literal">&lt;p&gt;Video frame interpolation aims to synthesize nonexistent frames in-between
the original frames. While significant advances have been made from the recent
deep convolutional neural networks, the quality of interpolation is often
reduced due to large object motion or occlusion. In this work, we propose a
video frame interpolation method which explicitly detects the occlusion by
exploring the depth information. Specifically, we develop a depth-aware flow
projection layer to synthesize intermediate flows that preferably sample closer
objects than farther ones. In addition, we learn hierarchical features to
gather contextual information from neighboring pixels. The proposed model then
warps the input frames, depth maps, and contextual features based on the
optical flow and local interpolation kernels for synthesizing the output frame.
Our model is compact, efficient, and fully differentiable. Quantitative and
qualitative results demonstrate that the proposed model performs favorably
against state-of-the-art frame interpolation methods on a wide variety of
datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bao_W/0/1/0/all/0/1&quot;&gt;Wenbo Bao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lai_W/0/1/0/all/0/1&quot;&gt;Wei-Sheng Lai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ma_C/0/1/0/all/0/1&quot;&gt;Chao Ma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1&quot;&gt;Xiaoyun Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gao_Z/0/1/0/all/0/1&quot;&gt;Zhiyong Gao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_M/0/1/0/all/0/1&quot;&gt;Ming-Hsuan Yang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00832">
<title>Non-RLL DC-Balance based on a Pre-scrambled Polar Encoder for Beacon-based Visible Light Communication Systems. (arXiv:1904.00832v1 [cs.IT])</title>
<link>http://arxiv.org/abs/1904.00832</link>
<description rdf:parseType="Literal">&lt;p&gt;Current flicker mitigation (or DC-balance) solutions based on run-length
limited (RLL) decoding algorithms are high in complexity, suffer from reduced
code rates, or are limited in application to hard-decoding forward error
correction (FEC) decoders. Fortunately, non-RLL DC-balance solutions can
overcome the drawbacks of RLL-based algorithms, but they meet some difficulties
in system latency, low code rate or inferior error-correction performance.
Recently, non-RLL flicker mitigation solution based on Polar code has proved to
be a most optimal approach due to its natural equal probabilities of short runs
of 1&apos;s and 0&apos;s with high error-correction performance. However, we found that
this solution can only maintain DC balance only when the data frame length is
sufficiently long. Therefore, these solutions are not suitable for using in
beacon-based visible light communication (VLC) systems, which usually transmit
ID information in small-size data frames. In this paper, we introduce a flicker
mitigation solution designed for beacon-based VLC systems that combines a
simple pre-scrambler with a (256;158) non-systematic polar encoder.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nguyen_D/0/1/0/all/0/1&quot;&gt;Duc-Phuc Nguyen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Le_D/0/1/0/all/0/1&quot;&gt;Dinh-Dung Le&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tran_T/0/1/0/all/0/1&quot;&gt;Thi-Hong Tran&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nakashima_Y/0/1/0/all/0/1&quot;&gt;Yasuhiko Nakashima&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00833">
<title>Liveness in Broadcast Networks. (arXiv:1904.00833v1 [cs.FL])</title>
<link>http://arxiv.org/abs/1904.00833</link>
<description rdf:parseType="Literal">&lt;p&gt;We study two liveness verification problems for broadcast networks, a system
model of identical clients communicating via message passing. The first problem
is liveness verification. It asks whether there is a computation such that one
of the clients visits a final state infinitely often. The complexity of the
problem has been open since 2010 when it was shown to be P-hard and solvable in
EXPSPACE. We close the gap by a polynomial-time algorithm. The algorithm relies
on a characterization of live computations in terms of paths in a suitable
graph, combined with a fixed-point iteration to efficiently check the existence
of such paths. The second problem is fair liveness verification. It asks for a
computation where all participating clients visit a final state infinitely
often. We adjust the algorithm to also solve fair liveness in polynomial time.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chini_P/0/1/0/all/0/1&quot;&gt;Peter Chini&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Meyer_R/0/1/0/all/0/1&quot;&gt;Roland Meyer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Saivasan_P/0/1/0/all/0/1&quot;&gt;Prakash Saivasan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00836">
<title>Multi-contact Phase Change Toggle Logic Device Utilizing Thermal Crosstalk. (arXiv:1904.00836v1 [cs.ET])</title>
<link>http://arxiv.org/abs/1904.00836</link>
<description rdf:parseType="Literal">&lt;p&gt;Phase change memory (PCM) is an emerging high speed, high density, high
endurance, and scalable non-volatile memory technology which utilizes the large
resistivity contrast between the amorphous and crystalline phases of
chalcogenide materials such as Ge2Sb2Te5 (GST). In addition to being used as a
standalone memory, there has been a growing interest in integration of PCM
devices on top of the CMOS layer for computation in memory and neuromorphic
computing. The large CMOS overhead for memory controllers is a limiting factor
for this purpose. Transferring functionality like routing, multiplexing, and
logic to the memory layer can substantially reduce the CMOS overhead, making it
possible to integrate 100s of GB of PCM storage on top of a conventional CPU.
In this work, we present computational analysis of a phase change device
concept that can perform toggle operations. The toggle functionality is
achieved using two physical mechanisms: (i) isolation of different read
contacts due to amorphization between different write contact pairs, and (ii)
thermal cross-talk between a molten region and a previously amorphized region.
Phase-change devices with six contacts can be implemented as toggle flip-flops,
multiplexer, or demultiplexer when interfaced with CMOS transistors. Here, we
demonstrate the operation of the device as a toggle flip-flop with 5
transistors, requiring ~50% of the footprint compared to conventional CMOS
alternatives, with the added advantage of non-volatility.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khan_R/0/1/0/all/0/1&quot;&gt;Raihan Sayeed Khan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kanan_N/0/1/0/all/0/1&quot;&gt;Nadim H. Kanan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Scoggin_J/0/1/0/all/0/1&quot;&gt;Jake Scoggin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Silva_H/0/1/0/all/0/1&quot;&gt;Helena Silva&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gokirmak_A/0/1/0/all/0/1&quot;&gt;Ali Gokirmak&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00838">
<title>Learning More with Less: GAN-based Medical Image Augmentation. (arXiv:1904.00838v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1904.00838</link>
<description rdf:parseType="Literal">&lt;p&gt;Accurate computer-assisted diagnosis using Convolutional Neural Networks
(CNNs) requires large-scale annotated training data, associated with expert
physicians&apos; time-consuming labor; thus, Data Augmentation (DA) using Generative
Adversarial Networks (GANs) is essential in Medical Imaging, since they can
synthesize additional annotated training data to handle small and fragmented
medical images from various scanners; those images are realistic but completely
different from the original ones, filling the data lack in the real image
distribution. As a tutorial, this paper introduces background on GAN-based
Medical Image Augmentation, along with tricks to achieve high
classification/object detection/segmentation performance using them, based on
our empirical experience and related work. Moreover, we show our first
GAN-based DA work using automatic bounding box annotation, for robust CNN-based
brain metastases detection on 256 x 256 MR images; GAN-based DA can boost 10%
sensitivity in diagnosis with a clinically acceptable amount of additional
False Positives, even with highly-rough and inconsistent bounding boxes.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Han_C/0/1/0/all/0/1&quot;&gt;Changhee Han&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Murao_K/0/1/0/all/0/1&quot;&gt;Kohei Murao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Satoh_S/0/1/0/all/0/1&quot;&gt;Shin&amp;#x27;ichi Satoh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nakayama_H/0/1/0/all/0/1&quot;&gt;Hideki Nakayama&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00839">
<title>Thyroid Cancer Malignancy Prediction From Whole Slide Cytopathology Images. (arXiv:1904.00839v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1904.00839</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider preoperative prediction of thyroid cancer based on
ultra-high-resolution whole-slide cytopathology images. Inspired by how human
experts perform diagnosis, our approach first identifies and classifies
diagnostic image regions containing informative thyroid cells, which only
comprise a tiny fraction of the entire image. These local estimates are then
aggregated into a single prediction of thyroid malignancy. Several unique
characteristics of thyroid cytopathology guide our deep-learning-based
approach. While our method is closely related to multiple-instance learning, it
deviates from these methods by using a supervised procedure to extract
diagnostically relevant regions. Moreover, we propose to simultaneously predict
thyroid malignancy, as well as a diagnostic score assigned by a human expert,
which further allows us to devise an improved training strategy. Experimental
results show that the proposed algorithm achieves performance comparable to
human experts, and demonstrate the potential of using the algorithm for
screening and as an assistive tool for the improved diagnosis of indeterminate
cases.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dov_D/0/1/0/all/0/1&quot;&gt;David Dov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kovalsky_S/0/1/0/all/0/1&quot;&gt;Shahar Kovalsky&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cohen_J/0/1/0/all/0/1&quot;&gt;Jonathan Cohen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Range_D/0/1/0/all/0/1&quot;&gt;Danielle Range&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Henao_R/0/1/0/all/0/1&quot;&gt;Ricardo Henao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Carin_L/0/1/0/all/0/1&quot;&gt;Lawrence Carin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00842">
<title>Deep, spatially coherent Inverse Sensor Models with Uncertainty Incorporation using the evidential Framework. (arXiv:1904.00842v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1904.00842</link>
<description rdf:parseType="Literal">&lt;p&gt;To perform high speed tasks, sensors of autonomous cars have to provide as
much information in as few time steps as possible. However, radars, one of the
sensor modalities autonomous cars heavily rely on, often only provide sparse,
noisy detections. These have to be accumulated over time to reach a high enough
confidence about the static parts of the environment. For radars, the state is
typically estimated by accumulating inverse detection models (IDMs). We employ
the recently proposed evidential convolutional neural networks which, in
contrast to IDMs, compute dense, spatially coherent inference of the
environment state. Moreover, these networks are able to incorporate sensor
noise in a principled way which we further extend to also incorporate model
uncertainty. We present experimental results that show This makes it possible
to obtain a denser environment perception in fewer time steps.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bauer_D/0/1/0/all/0/1&quot;&gt;Daniel Bauer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kuhnert_L/0/1/0/all/0/1&quot;&gt;Lars Kuhnert&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Eckstein_L/0/1/0/all/0/1&quot;&gt;Lutz Eckstein&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00850">
<title>Boundedness of Conjunctive Regular Path Queries. (arXiv:1904.00850v1 [cs.DB])</title>
<link>http://arxiv.org/abs/1904.00850</link>
<description rdf:parseType="Literal">&lt;p&gt;We study the boundedness problem for unions of conjunctive regular path
queries with inverses (UC2RPQs). This is the problem of, given a UC2RPQ,
checking whether it is equivalent to a union of conjunctive queries (UCQ). We
show the problem to be ExpSpace-complete, thus coinciding with the complexity
of containment for UC2RPQs. As a corollary, when a UC2RPQ is bounded, it is
equivalent to a UCQ of at most triple-exponential size, and in fact we show
that this bound is optimal. We also study better behaved classes of UC2RPQs,
namely acyclic UC2RPQs of bounded thickness, and strongly connected UCRPQs,
whose boundedness problem are, respectively, PSpace-complete and
$\Pi^p_2$-complete. Most upper bounds exploit results on limitedness for
distance automata, in particular extending the model with alternation and
two-wayness, which may be of independent interest.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Barcelo_P/0/1/0/all/0/1&quot;&gt;Pablo Barcel&amp;#xf3;&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Figueira_D/0/1/0/all/0/1&quot;&gt;Diego Figueira&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Romero_M/0/1/0/all/0/1&quot;&gt;Miguel Romero&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00853">
<title>Precise Detection in Densely Packed Scenes. (arXiv:1904.00853v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1904.00853</link>
<description rdf:parseType="Literal">&lt;p&gt;Man-made scenes can be densely packed, containing numerous objects, often
identical, positioned in close proximity. We show that precise object detection
in such scenes remains a challenging frontier even for state-of-the-art object
detectors. We propose a novel, deep-learning based method for precise object
detection, designed for such challenging settings. Our contributions include:
(1) A layer for estimating the Jaccard index as a detection quality score; (2)
a novel EM merging unit, which uses our quality scores to resolve detection
overlap ambiguities; finally, (3) an extensive, annotated data set, \dataset,
representing packed retail environments, released for training and testing
under such extreme settings. Detection tests on \dataset{} and counting tests
on the CARPK and PUCPR+ show our method to outperform existing state-of-the-art
with substantial margins. The code and data will be made available on
\url{www.github.com/eg4000/SKU110K_CVPR19}.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Goldman%2A_E/0/1/0/all/0/1&quot;&gt;Eran Goldman*&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Herzig%2A_R/0/1/0/all/0/1&quot;&gt;Roei Herzig*&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Eisenschtat%2A_A/0/1/0/all/0/1&quot;&gt;Aviv Eisenschtat*&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Goldberger_J/0/1/0/all/0/1&quot;&gt;Jacob Goldberger&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hassner_T/0/1/0/all/0/1&quot;&gt;Tal Hassner&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00859">
<title>A Novel Malware Detection System Based On Machine Learning and Binary Visualization. (arXiv:1904.00859v1 [cs.CR])</title>
<link>http://arxiv.org/abs/1904.00859</link>
<description rdf:parseType="Literal">&lt;p&gt;The continued evolution and diversity of malware constitutes a major threat
in modern systems. It is well proven that security defenses currently available
are ineffective to mitigate the skills and imagination of cyber-criminals
necessitating the development of novel solutions. Deep learning algorithms and
artificial intelligence (AI) are rapidly evolving with remarkable results in
many application areas. Following the advances of AI and recognizing the need
for efficient malware detection methods, this paper presents a new approach for
malware detection based on binary visualization and self-organizing incremental
neural networks. The proposed method&apos;s performance in detecting malicious
payloads in various file types was investigated and the experimental results
showed that a detection accuracy of 91.7% and 94.1% was achieved for ransomware
in .pdf and .doc files respectively. With respect to other formats of malicious
code and other file types, including binaries, the proposed method behaved well
with an incremental detection rate that allows efficiently detecting unknown
malware at real-time.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Baptista_I/0/1/0/all/0/1&quot;&gt;Irina Baptista&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shiaeles_S/0/1/0/all/0/1&quot;&gt;Stavros Shiaeles&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kolokotronis_N/0/1/0/all/0/1&quot;&gt;Nicholas Kolokotronis&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00863">
<title>DefectNET: multi-class fault detection on highly-imbalanced datasets. (arXiv:1904.00863v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1904.00863</link>
<description rdf:parseType="Literal">&lt;p&gt;As a data-driven method, the performance of deep convolutional neural
networks (CNN) relies heavily on training data. The prediction results of
traditional networks give a bias toward larger classes, which tend to be the
background in the semantic segmentation task. This becomes a major problem for
fault detection, where the targets appear very small on the images and vary in
both types and sizes. In this paper we propose a new network architecture,
DefectNet, that offers multi-class (including but not limited to) defect
detection on highly-imbalanced datasets. DefectNet consists of two parallel
paths, which are a fully convolutional network and a dilated convolutional
network to detect large and small objects respectively. We propose a hybrid
loss maximising the usefulness of a dice loss and a cross entropy loss, and we
also employ the leaky rectified linear unit (ReLU) to deal with rare occurrence
of some targets in training batches. The prediction results show that our
DefectNet outperforms state-of-the-art networks for detecting multi-class
defects with the average accuracy improvement of approximately 10% on a wind
turbine.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Anantrasirichai_N/0/1/0/all/0/1&quot;&gt;N. Anantrasirichai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bull_D/0/1/0/all/0/1&quot;&gt;David Bull&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00864">
<title>Tree Search Network for Sparse Regression. (arXiv:1904.00864v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1904.00864</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider the classical sparse regression problem of recovering a sparse
signal $x_0$ given a measurement vector $y = \Phi x_0+w$. We propose a tree
search algorithm driven by the deep neural network for sparse regression (TSN).
TSN improves the signal reconstruction performance of the deep neural network
designed for sparse regression by performing a tree search with pruning. It is
observed in both noiseless and noisy cases, TSN recovers synthetic and real
signals with lower complexity than a conventional tree search and is superior
to existing algorithms by a large margin for various types of the sensing
matrix $\Phi$, widely used in sparse regression.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_K/0/1/0/all/0/1&quot;&gt;Kyung-Su Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chung_S/0/1/0/all/0/1&quot;&gt;Sae-Young Chung&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00865">
<title>Non-linear aggregation of filters to improve image denoising. (arXiv:1904.00865v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1904.00865</link>
<description rdf:parseType="Literal">&lt;p&gt;We introduce a novel aggregation method to efficiently perform image
denoising. Preliminary filters are aggregated in a non-linear fashion, using a
new metric of pixel proximity based on how the pool of filters reaches a
consensus. The numerical performance of the method is illustrated and we show
that the aggregate significantly outperforms each of the preliminary filters.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Guedj_B/0/1/0/all/0/1&quot;&gt;Benjamin Guedj&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Rengot_J/0/1/0/all/0/1&quot;&gt;Juliette Rengot&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00868">
<title>Feasibility vs. Optimality in Distributed AC OPF - A Case Study Considering ADMM and ALADIN. (arXiv:1904.00868v1 [cs.SY])</title>
<link>http://arxiv.org/abs/1904.00868</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper investigates the role of feasible initial guesses and large
consensus-violation penalization in distributed optimization for Optimal Power
Flow (OPF) problems. Specifically, we discuss the behavior of the Alternating
Direction of Multipliers Method (ADMM). We show that in case of large
consensus-violation penalization ADMM might exhibit slow progress. We support
this observation by an analysis of the algorithmic properties of ADMM.
Furthermore, we illustrate our findings considering the IEEE 57 bus system and
we draw upon a comparison of ADMM and the Augmented Lagrangian Alternating
Direction Inexact Newton (ALADIN) method.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Engelmann_A/0/1/0/all/0/1&quot;&gt;Alexander Engelmann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Faulwasser_T/0/1/0/all/0/1&quot;&gt;Timm Faulwasser&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00876">
<title>Significance-aware Information Bottleneck for Domain Adaptive Semantic Segmentation. (arXiv:1904.00876v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1904.00876</link>
<description rdf:parseType="Literal">&lt;p&gt;For unsupervised domain adaptation problems, the strategy of aligning the two
domains in latent feature space through adversarial learning has achieved much
progress in image classification, but usually fails in semantic segmentation
tasks in which the latent representations are overcomplex. In this work, we
equip the adversarial network with a &quot;significance-aware information bottleneck
(SIB)&quot;, to address the above problem. The new network structure, called SIBAN,
enables a significance-aware feature purification before the adversarial
adaptation, which eases the feature alignment and stabilizes the adversarial
training course. In two domain adaptation tasks, i.e., GTA5 -&amp;gt; Cityscapes and
SYNTHIA -&amp;gt; Cityscapes, we validate that the proposed method can yield leading
results compared with other feature-space alternatives. Moreover, SIBAN can
even match the state-of-the-art output-space methods in segmentation accuracy,
while the latter are often considered to be better choices for domain adaptive
segmentation task.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Luo_Y/0/1/0/all/0/1&quot;&gt;Yawei Luo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_P/0/1/0/all/0/1&quot;&gt;Ping Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guan_T/0/1/0/all/0/1&quot;&gt;Tao Guan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_J/0/1/0/all/0/1&quot;&gt;Junqing Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1&quot;&gt;Yi Yang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00880">
<title>An Approach to Identity Management in Clouds without Trusted Third Parties. (arXiv:1904.00880v1 [cs.CR])</title>
<link>http://arxiv.org/abs/1904.00880</link>
<description rdf:parseType="Literal">&lt;p&gt;The management of sensitive data, including identity management (IDM), is an
important problem in cloud computing, fundamental for authentication and
fine-grained service access control. Our goal is creating an efficient and
robust IDM solution that addresses critical issues in cloud computing. The
proposed IDM scheme does not rely on trusted third parties (TTPs) or trusted
dealers. The scheme is a multiparty interactive solution that combines RSA
distributed key generation and attribute-based encryption. We believe that it
will be a robust IDM privacy-preserving solution in cloud computing, because it
has the following features: (i) protects sensitive data on untrusted hosts
using active bundle; (ii) supports the minimum disclosure property; (iii)
minimizes authentication overhead by providing single sign-on; (iv) supports
authentication with encrypted credentials; (v) avoids using trusted third
parties (TTPs_, incl. using TTPs for key management; (vi) supports revocation
and delegation of access right; and (vii) supports revocation of user
credentials. The scheme should also be efficient because it exploits
parallelism.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sarhan_A/0/1/0/all/0/1&quot;&gt;Akram Sarhan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lilien_L/0/1/0/all/0/1&quot;&gt;Leszek Lilien&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00887">
<title>Adversarial Defense by Restricting the Hidden Space of Deep Neural Networks. (arXiv:1904.00887v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1904.00887</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep neural networks are vulnerable to adversarial attacks, which can fool
them by adding minuscule perturbations to the input images. The robustness of
existing defenses suffers greatly under white-box attack settings, where an
adversary has full knowledge about the network and can iterate several times to
find strong perturbations. We observe that the main reason for the existence of
such perturbations is the close proximity of different class samples in the
learned feature space. This allows model decisions to be totally changed by
adding an imperceptible perturbation in the inputs. To counter this, we propose
to class-wise disentangle the intermediate feature representations of deep
networks. Specifically, we force the features for each class to lie inside a
convex polytope that is maximally separated from the polytopes of other
classes. In this manner, the network is forced to learn distinct and distant
decision regions for each class. We observe that this simple constraint on the
features greatly enhances the robustness of learned models, even against the
strongest white-box attacks, without degrading the classification performance
on clean images. We report extensive evaluations in both \textit{black-box} and
white-box attack scenarios and show significant gains in comparison to
state-of-the art defenses.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mustafa_A/0/1/0/all/0/1&quot;&gt;Aamir Mustafa&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khan_S/0/1/0/all/0/1&quot;&gt;Salman Khan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hayat_M/0/1/0/all/0/1&quot;&gt;Munawar Hayat&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Goecke_R/0/1/0/all/0/1&quot;&gt;Roland Goecke&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shen_J/0/1/0/all/0/1&quot;&gt;Jianging Shen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shao_L/0/1/0/all/0/1&quot;&gt;Ling Shao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00889">
<title>Key.Net: Keypoint Detection by Handcrafted and Learned CNN Filters. (arXiv:1904.00889v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1904.00889</link>
<description rdf:parseType="Literal">&lt;p&gt;We introduce a novel approach for keypoint detection task that combines
handcrafted and learned CNN filters within a shallow multi-scale architecture.
Handcrafted filters provide anchor structures for learned filters, which
localize, score and rank repeatable features. Scale-space representation is
used within the network to extract keypoints at different levels. We design a
loss function to detect robust features that exist across a range of scales and
to maximize the repeatability score. Our Key.Net model is trained on data
synthetically created from ImageNet and evaluated on HPatches benchmark.
Results show that our approach outperforms state-of-the-art detectors in terms
of repeatability, matching performance and complexity.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Laguna_A/0/1/0/all/0/1&quot;&gt;Axel Barroso Laguna&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Riba_E/0/1/0/all/0/1&quot;&gt;Edgar Riba&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ponsa_D/0/1/0/all/0/1&quot;&gt;Daniel Ponsa&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mikolajczyk_K/0/1/0/all/0/1&quot;&gt;Krystian Mikolajczyk&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00904">
<title>An Atomistic Machine Learning Package for Surface Science and Catalysis. (arXiv:1904.00904v1 [physics.chem-ph])</title>
<link>http://arxiv.org/abs/1904.00904</link>
<description rdf:parseType="Literal">&lt;p&gt;We present work flows and a software module for machine learning model
building in surface science and heterogeneous catalysis. This includes
fingerprinting atomic structures from 3D structure and/or connectivity
information, it includes descriptor selection methods and benchmarks, and it
includes active learning frameworks for atomic structure optimization,
acceleration of screening studies and for exploration of the structure space of
nano particles, which are all atomic structure problems relevant for surface
science and heterogeneous catalysis. Our overall goal is to provide a
repository to ease machine learning model building for catalysis, to advance
the models beyond the chemical intuition of the user and to increase autonomy
for exploration of chemical space.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Hansen_M/0/1/0/all/0/1&quot;&gt;Martin Hangaard Hansen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Torres_J/0/1/0/all/0/1&quot;&gt;Jos&amp;#xe9; A. Garrido Torres&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Jennings_P/0/1/0/all/0/1&quot;&gt;Paul C. Jennings&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Wang_Z/0/1/0/all/0/1&quot;&gt;Ziyun Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Boes_J/0/1/0/all/0/1&quot;&gt;Jacob R. Boes&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Mamun_O/0/1/0/all/0/1&quot;&gt;Osman G. Mamun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Bligaard_T/0/1/0/all/0/1&quot;&gt;Thomas Bligaard&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00905">
<title>ZETH: On Integrating Zerocash on Ethereum. (arXiv:1904.00905v1 [cs.CR])</title>
<link>http://arxiv.org/abs/1904.00905</link>
<description rdf:parseType="Literal">&lt;p&gt;Transaction privacy is a hard problem on an account-based blockchain such as
Ethereum. While Ben-Sasson et al. presented the Zerocash protocol [BCG+14] as a
decentralized anonymous payment (DAP) scheme standing on top of Bitcoin, no
study about the integration of such DAP on top of a ledger defined in the
account model was provided. In this paper we aim to fill this gap and propose
ZETH, an adaptation of Zerocash that can be deployed on top of Ethereum without
making any change to the base layer. Our study shows that not only ZETH could
be used to transfer Ether, the base currency of Ethereum, but it could also be
used to transfer other types of smart contract-based digital assets. We propose
an analysis of ZETH&apos;s privacy promises and argue that information leakages
intrinsic to the use of this protocol are controlled and well-defined, which
makes it a viable solution to support private transactions in the context of
public and permissioned chains.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rondelet_A/0/1/0/all/0/1&quot;&gt;Antoine Rondelet&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zajac_M/0/1/0/all/0/1&quot;&gt;Michal Zajac&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00906">
<title>Spherical U-Net on Cortical Surfaces: Methods and Applications. (arXiv:1904.00906v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1904.00906</link>
<description rdf:parseType="Literal">&lt;p&gt;Convolutional Neural Networks (CNNs) have been providing the state-of-the-art
performance for learning-related problems involving 2D/3D images in Euclidean
space. However, unlike in the Euclidean space, the shapes of many structures in
medical imaging have a spherical topology in a manifold space, e.g., brain
cortical or subcortical surfaces represented by triangular meshes, with large
inter-subject and intrasubject variations in vertex number and local
connectivity. Hence, there is no consistent neighborhood definition and thus no
straightforward convolution/transposed convolution operations for
cortical/subcortical surface data. In this paper, by leveraging the regular and
consistent geometric structure of the resampled cortical surface mapped onto
the spherical space, we propose a novel convolution filter analogous to the
standard convolution on the image grid. Accordingly, we develop corresponding
operations for convolution, pooling, and transposed convolution for spherical
surface data and thus construct spherical CNNs. Specifically, we propose the
Spherical U-Net architecture by replacing all operations in the standard U-Net
with their spherical operation counterparts. We then apply the Spherical U-Net
to two challenging and neuroscientifically important tasks in infant brains:
cortical surface parcellation and cortical attribute map development
prediction. Both applications demonstrate the competitive performance in the
accuracy, computational efficiency, and effectiveness of our proposed Spherical
U-Net, in comparison with the state-of-the-art methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_F/0/1/0/all/0/1&quot;&gt;Fenqiang Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xia_S/0/1/0/all/0/1&quot;&gt;Shunren Xia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1&quot;&gt;Zhengwang Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Duan_D/0/1/0/all/0/1&quot;&gt;Dingna Duan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1&quot;&gt;Li Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_W/0/1/0/all/0/1&quot;&gt;Weili Lin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gilmore_J/0/1/0/all/0/1&quot;&gt;John H Gilmore&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shen_D/0/1/0/all/0/1&quot;&gt;Dinggang Shen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_G/0/1/0/all/0/1&quot;&gt;Gang Li&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00912">
<title>The RGB-D Triathlon: Towards Agile Visual Toolboxes for Robots. (arXiv:1904.00912v1 [cs.RO])</title>
<link>http://arxiv.org/abs/1904.00912</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep networks have brought significant advances in robot perception, enabling
to improve the capabilities of robots in several visual tasks, ranging from
object detection and recognition to pose estimation, semantic scene
segmentation and many others. Still, most approaches typically address visual
tasks in isolation, resulting in overspecialized models which achieve strong
performances in specific applications but work poorly in other (often related)
tasks. This is clearly sub-optimal for a robot which is often required to
perform simultaneously multiple visual recognition tasks in order to properly
act and interact with the environment. This problem is exacerbated by the
limited computational and memory resources typically available onboard to a
robotic platform. The problem of learning flexible models which can handle
multiple tasks in a lightweight manner has recently gained attention in the
computer vision community and benchmarks supporting this research have been
proposed. In this work we study this problem in the robot vision context,
proposing a new benchmark, the RGB-D Triathlon, and evaluating state of the art
algorithms in this novel challenging scenario. We also define a new evaluation
protocol, better suited to the robot vision setting. Results shed light on the
strengths and weaknesses of existing approaches and on open issues, suggesting
directions for future research.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cermelli_F/0/1/0/all/0/1&quot;&gt;Fabio Cermelli&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mancini_M/0/1/0/all/0/1&quot;&gt;Massimiliano Mancini&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ricci_E/0/1/0/all/0/1&quot;&gt;Elisa Ricci&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Caputo_B/0/1/0/all/0/1&quot;&gt;Barbara Caputo&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00923">
<title>Robustness of 3D Deep Learning in an Adversarial Setting. (arXiv:1904.00923v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1904.00923</link>
<description rdf:parseType="Literal">&lt;p&gt;Understanding the spatial arrangement and nature of real-world objects is of
paramount importance to many complex engineering tasks, including autonomous
navigation. Deep learning has revolutionized state-of-the-art performance for
tasks in 3D environments; however, relatively little is known about the
robustness of these approaches in an adversarial setting. The lack of
comprehensive analysis makes it difficult to justify deployment of 3D deep
learning models in real-world, safety-critical applications. In this work, we
develop an algorithm for analysis of pointwise robustness of neural networks
that operate on 3D data. We show that current approaches presented for
understanding the resilience of state-of-the-art models vastly overestimate
their robustness. We then use our algorithm to evaluate an array of
state-of-the-art models in order to demonstrate their vulnerability to
occlusion attacks. We show that, in the worst case, these networks can be
reduced to 0% classification accuracy after the occlusion of at most 6.5% of
the occupied input space.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wicker_M/0/1/0/all/0/1&quot;&gt;Matthew Wicker&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kwiatkowska_M/0/1/0/all/0/1&quot;&gt;Marta Kwiatkowska&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00928">
<title>Exploring the Trade-Off between Privacy and Coordination in Millimeter Wave Spectrum Sharing. (arXiv:1904.00928v1 [eess.SP])</title>
<link>http://arxiv.org/abs/1904.00928</link>
<description rdf:parseType="Literal">&lt;p&gt;The synergetic gains of spectrum sharing and millimeter wave communication
networks have recently attracted attention, owing to the interference canceling
benefits of highly-directional beamforming in such systems. In principle,
fine-tuned coordinated scheduling and beamforming can drastically reduce
cross-operator interference. However, this goes at the expense of the exchange
of global channel state information, which is not realistic in particular when
considering inter-operator coordination. Indeed, such an exchange of
information is expensive in terms of backhaul infrastructure, and besides, it
raises sensitive privacy issues between otherwise competing operators. In this
paper, we expose the existence of a trade-off between coordination and privacy.
We propose an algorithm capable of balancing spectrum sharing performance with
privacy preservation based on the sharing of a low-rate beam-related
information. Such information is subject to a data obfuscation mechanism
borrowed from the digital security literature so as to control the privacy,
measured in terms of information-theoretical equivocation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Maschietti_F/0/1/0/all/0/1&quot;&gt;Flavio Maschietti&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Kerret_P/0/1/0/all/0/1&quot;&gt;Paul de Kerret&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Gesbert_D/0/1/0/all/0/1&quot;&gt;David Gesbert&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00929">
<title>Unsupervised Abbreviation Disambiguation Contextual disambiguation using word embeddings. (arXiv:1904.00929v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1904.00929</link>
<description rdf:parseType="Literal">&lt;p&gt;As abbreviations often have several distinct meanings, disambiguating their
intended meaning in context is important for Machine Reading tasks such as
document search, recommendation and question answering. Existing approaches
mostly rely on labelled examples of abbreviations and their correct long forms,
which is costly to generate and limits their applicability and flexibility.
Importantly, they need to be subjected to a full empirical evaluation, which is
cumbersome in practice.
&lt;/p&gt;
&lt;p&gt;In this paper, we present an entirely unsupervised abbreviation
disambiguation method (called UAD) that picks up abbreviation definitions from
text. Creating distinct tokens per meaning, we learn context representations as
word embeddings. We demonstrate how to further boost abbreviation
disambiguation performance by obtaining better context representations from
additional unstructured text. Our method is the first abbreviation
disambiguation approach which features a transparent model that allows
performance analysis without requiring full-scale evaluation, making it highly
relevant for real-world deployments.
&lt;/p&gt;
&lt;p&gt;In our thorough empirical evaluation, UAD achieves high performance on large
real world document data sets from different domains and outperforms both
baseline and state-of-the-art methods. UAD scales well and supports thousands
of abbreviations with many different meanings with a single model.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ciosici/0/1/0/all/0/1&quot;&gt;Ciosici&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Manuel/0/1/0/all/0/1&quot;&gt;Manuel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sommer/0/1/0/all/0/1&quot;&gt;Sommer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tobias/0/1/0/all/0/1&quot;&gt;Tobias&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Assent/0/1/0/all/0/1&quot;&gt;Assent&lt;/a&gt;, Ira</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00930">
<title>Lost in Interpretation: Predicting Untranslated Terminology in Simultaneous Interpretation. (arXiv:1904.00930v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1904.00930</link>
<description rdf:parseType="Literal">&lt;p&gt;Simultaneous interpretation, the translation of speech from one language to
another in real-time, is an inherently difficult and strenuous task. One of the
greatest challenges faced by interpreters is the accurate translation of
difficult terminology like proper names, numbers, or other entities.
Intelligent computer-assisted interpreting (CAI) tools that could analyze the
spoken word and detect terms likely to be untranslated by an interpreter could
reduce translation error and improve interpreter performance. In this paper, we
propose a task of predicting which terminology simultaneous interpreters will
leave untranslated, and examine methods that perform this task using supervised
sequence taggers. We describe a number of task-specific features explicitly
designed to indicate when an interpreter may struggle with translating a word.
Experimental results on a newly-annotated version of the NAIST Simultaneous
Translation Corpus (Shimizu et al., 2014) indicate the promise of our proposed
method.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vogler_N/0/1/0/all/0/1&quot;&gt;Nikolai Vogler&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Stewart_C/0/1/0/all/0/1&quot;&gt;Craig Stewart&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Neubig_G/0/1/0/all/0/1&quot;&gt;Graham Neubig&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00934">
<title>A More General Theory of Static Approximations for Conjunctive Queries. (arXiv:1904.00934v1 [cs.DB])</title>
<link>http://arxiv.org/abs/1904.00934</link>
<description rdf:parseType="Literal">&lt;p&gt;Conjunctive query (CQ) evaluation is NP-complete, but becomes tractable for
fragments of bounded hypertreewidth. Approximating a hard CQ by a query from
such a fragment can thus allow for an efficient approximate evaluation. While
underapproximations (i.e., approximations that return correct answers only) are
well-understood, the dual notion of overapproximations (i.e, approximations
that return complete - but not necessarily sound - answers), and also a more
general notion of approximation based on the symmetric difference of query
results, are almost unexplored. In fact, the decidability of the basic problems
of evaluation, identification, and existence of those approximations has been
open.
&lt;/p&gt;
&lt;p&gt;This article establishes a connection between overapproximations and
existential pebble games that allows for studying such problems systematically.
Building on this connection, it is shown that the evaluation and identification
problem for overapproximations can be solved in polynomial time. While the
general existence problem remains open, the problem is shown to be decidable in
2EXPTIME over the class of acyclic CQs and in PTIME for Boolean CQs over binary
schemata. Additionally we propose a more liberal notion of overapproximations
to remedy the known shortcoming that queries might not have an
overapproximation, and study how queries can be overapproximated in the
presence of tuple generating and equality generating dependencies.
&lt;/p&gt;
&lt;p&gt;The techniques are then extended to symmetric difference approximations and
used to provide several complexity results for the identification, existence,
and evaluation problem for this type of approximations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Barcelo_P/0/1/0/all/0/1&quot;&gt;Pablo Barcel&amp;#xf3;&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Romero_M/0/1/0/all/0/1&quot;&gt;Miguel Romero&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zeume_T/0/1/0/all/0/1&quot;&gt;Thomas Zeume&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00935">
<title>STYLE-ANALYZER: fixing code style inconsistencies with interpretable unsupervised algorithms. (arXiv:1904.00935v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1904.00935</link>
<description rdf:parseType="Literal">&lt;p&gt;Source code reviews are manual, time-consuming, and expensive. Human
involvement should be focused on analyzing the most relevant aspects of the
program, such as logic and maintainability, rather than amending style, syntax,
or formatting defects. Some tools with linting capabilities can format code
automatically and report various stylistic violations for supported programming
languages. They are based on rules written by domain experts, hence, their
configuration is often tedious, and it is impractical for the given set of
rules to cover all possible corner cases. Some machine learning-based solutions
exist, but they remain uninterpretable black boxes. This paper introduces
STYLE-ANALYZER, a new open source tool to automatically fix code formatting
violations using the decision tree forest model which adapts to each codebase
and is fully unsupervised. STYLE-ANALYZER is built on top of our novel assisted
code review framework, Lookout. It accurately mines the formatting style of
each analyzed Git repository and expresses the found format patterns with
compact human-readable rules. STYLE-ANALYZER can then suggest style
inconsistency fixes in the form of code review comments. We evaluate the output
quality and practical relevance of STYLE-ANALYZER by demonstrating that it can
reproduce the original style with high precision, measured on 19 popular
JavaScript projects, and by showing that it yields promising results in fixing
real style mistakes. STYLE-ANALYZER includes a web application to visualize how
the rules are triggered. We release STYLE-ANALYZER as a reusable and extendable
open source software package on GitHub for the benefit of the community.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Markovtsev_V/0/1/0/all/0/1&quot;&gt;Vadim Markovtsev&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Long_W/0/1/0/all/0/1&quot;&gt;Waren Long&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mougard_H/0/1/0/all/0/1&quot;&gt;Hugo Mougard&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Slavnov_K/0/1/0/all/0/1&quot;&gt;Konstantin Slavnov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bulychev_E/0/1/0/all/0/1&quot;&gt;Egor Bulychev&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00936">
<title>Experimental Comparison of Visual-Aided Odometry Methods for Rail Vehicles. (arXiv:1904.00936v1 [cs.RO])</title>
<link>http://arxiv.org/abs/1904.00936</link>
<description rdf:parseType="Literal">&lt;p&gt;Today, rail vehicle localization is based on infrastructure-side Balises
(beacons) together with on-board odometry to determine whether a rail segment
is occupied. Such a coarse locking leads to a sub-optimal usage of the rail
networks. New railway standards propose the use of moving blocks centered
around the rail vehicles to increase the capacity of the network. However, this
approach requires accurate and robust position and velocity estimation of all
vehicles. In this work, we investigate the applicability, challenges and
limitations of current visual and visual-inertial motion estimation frameworks
for rail applications. An evaluation against RTK-GPS ground truth is performed
on multiple datasets recorded in industrial, sub-urban, and forest
environments. Our results show that stereo visual-inertial odometry has a great
potential to provide a precise motion estimation because of its complementing
sensor modalities and shows superior performance in challenging situations
compared to other frameworks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tschopp_F/0/1/0/all/0/1&quot;&gt;Florian Tschopp&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schneider_T/0/1/0/all/0/1&quot;&gt;Thomas Schneider&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Palmer_A/0/1/0/all/0/1&quot;&gt;Andrew W. Palmer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nourani_Vatani_N/0/1/0/all/0/1&quot;&gt;Navid Nourani-Vatani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cadena_C/0/1/0/all/0/1&quot;&gt;Cesar Cadena&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Siegwart_R/0/1/0/all/0/1&quot;&gt;Roland Siegwart&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nieto_J/0/1/0/all/0/1&quot;&gt;Juan Nieto&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00937">
<title>Early Diagnosis of Pneumonia with Deep Learning. (arXiv:1904.00937v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1904.00937</link>
<description rdf:parseType="Literal">&lt;p&gt;Pneumonia has been one of the fatal diseases and has the potential to result
in severe consequences within a short period of time, due to the flow of fluid
in lungs, which leads to drowning. If not acted upon by drugs at the right
time, pneumonia may result in death of individuals. Therefore, the early
diagnosis is a key factor along the progress of the disease. This paper focuses
on the biological progress of pneumonia and its detection by x-ray imaging,
overviews the studies conducted on enhancing the level of diagnosis, and
presents the methodology and results of an automation of xray images based on
various parameters in order to detect the disease at very early stages. In this
study we propose our deep learning architecture for the classification task,
which is trained with modified images, through multiple steps of preprocessing.
Our classification method uses convolutional neural networks and residual
network architecture for classifying the images. Our findings yield an accuracy
of 78.73%, surpassing the previously top scoring accuracy of 76.8%.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Saul_C/0/1/0/all/0/1&quot;&gt;Can Jozef Saul&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Urey_D/0/1/0/all/0/1&quot;&gt;Deniz Yagmur Urey&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Taktakoglu_C/0/1/0/all/0/1&quot;&gt;Can Doruk Taktakoglu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00938">
<title>LUTNet: Rethinking Inference in FPGA Soft Logic. (arXiv:1904.00938v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1904.00938</link>
<description rdf:parseType="Literal">&lt;p&gt;Research has shown that deep neural networks contain significant redundancy,
and that high classification accuracies can be achieved even when weights and
activations are quantised down to binary values. Network binarisation on FPGAs
greatly increases area efficiency by replacing resource-hungry multipliers with
lightweight XNOR gates. However, an FPGA&apos;s fundamental building block, the
K-LUT, is capable of implementing far more than an XNOR: it can perform any
K-input Boolean operation. Inspired by this observation, we propose LUTNet, an
end-to-end hardware-software framework for the construction of area-efficient
FPGA-based neural network accelerators using the native LUTs as inference
operators. We demonstrate that the exploitation of LUT flexibility allows for
far heavier pruning than possible in prior works, resulting in significant area
savings while achieving comparable accuracy. Against the state-of-the-art
binarised neural network implementation, we achieve twice the area efficiency
for several standard network models when inferencing popular datasets. We also
demonstrate that even greater energy efficiency improvements are obtainable.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_E/0/1/0/all/0/1&quot;&gt;Erwei Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Davis_J/0/1/0/all/0/1&quot;&gt;James J. Davis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cheung_P/0/1/0/all/0/1&quot;&gt;Peter Y. K. Cheung&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Constantinides_G/0/1/0/all/0/1&quot;&gt;George A. Constantinides&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00942">
<title>Controlling for Biasing Signals in Images for Prognostic Models: Survival Predictions for Lung Cancer with Deep Learning. (arXiv:1904.00942v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1904.00942</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep learning has shown remarkable results for image analysis and is expected
to aid individual treatment decisions in health care. To achieve this, deep
learning methods need to be promoted from the level of mere associations to
being able to answer causal questions. We present a scenario with real-world
medical images (CT-scans of lung cancers) and simulated outcome data. Through
the sampling scheme, the images contain two distinct factors of variation that
represent a collider and a prognostic factor. We show that when this collider
can be quantified, unbiased individual prognosis predictions are attainable
with deep learning. This is achieved by (1) setting a dual task for the network
to predict both the outcome and the collider and (2) enforcing independence of
the activation distributions of the last layer with ordinary least squares. Our
method provides an example of combining deep learning and structural causal
models for unbiased individual prognosis predictions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Amsterdam_W/0/1/0/all/0/1&quot;&gt;Wouter A.C. van Amsterdam&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Eijkemans_M/0/1/0/all/0/1&quot;&gt;Marinus J.C. Eijkemans&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00943">
<title>Fully-Asynchronous Distributed Metropolis Sampler with Optimal Speedup. (arXiv:1904.00943v1 [cs.DS])</title>
<link>http://arxiv.org/abs/1904.00943</link>
<description rdf:parseType="Literal">&lt;p&gt;The Metropolis-Hastings algorithm is a fundamental Markov chain Monte Carlo
(MCMC) method for sampling and inference. With the advent of Big Data,
distributed and parallel variants of MCMC methods are attracting increased
attention. In this paper, we give a distributed algorithm that can correctly
simulate sequential single-site Metropolis chains without any bias in a fully
asynchronous message-passing model. Furthermore, if a natural Lipschitz
condition is satisfied by the Metropolis filters, our algorithm can simulate
$N$-step Metropolis chains within $O(N/n+\log n)$ rounds of asynchronous
communications, where $n$ is the number of variables. For sequential
single-site dynamics, whose mixing requires $\Omega(n\log n)$ steps, this
achieves an optimal linear speedup. For several well-studied important
graphical models, including proper graph coloring, hardcore model, and Ising
model, the condition for linear speedup is weaker than the respective
uniqueness (mixing) conditions.
&lt;/p&gt;
&lt;p&gt;The novel idea in our algorithm is to resolve updates in advance: the local
Metropolis filters can be executed correctly before the full information about
neighboring spins is available. This achieves optimal parallelism of Metropolis
processes without introducing any bias.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Feng_W/0/1/0/all/0/1&quot;&gt;Weiming Feng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hayes_T/0/1/0/all/0/1&quot;&gt;Thomas P. Hayes&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yin_Y/0/1/0/all/0/1&quot;&gt;Yitong Yin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00944">
<title>Retracing and assessing the CEP project. (arXiv:1904.00944v1 [cs.GL])</title>
<link>http://arxiv.org/abs/1904.00944</link>
<description rdf:parseType="Literal">&lt;p&gt;The last decade witnessed a renewed interest in the development of the
Italian computer industry and in the role of the Fifties pioneers in Rome,
Milan, Ivrea, and Pisa. The aim of the paper is to retrace some steps of the
CEP project, carried out by the University of Pisa in collaboration with
Olivetti, by reassessing the documents preserved in the University archives.
The project was a seminal enterprise for Italy, and among its accomplishments
it delivered in 1957 the first Italian computer. The mix of public sector
funding and industrial foretelling witnessed by the project is one of the
leading examples in Italy of best practices, and its success paved the way for
the birth of Computer Science in the country as an industry as well as a
scientific discipline.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cignoni_G/0/1/0/all/0/1&quot;&gt;Giovanni A. Cignoni&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gadducci_F/0/1/0/all/0/1&quot;&gt;Fabio Gadducci&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00946">
<title>Does the hiding mechanism for Stack Overflow comments work well? No!. (arXiv:1904.00946v1 [cs.SE])</title>
<link>http://arxiv.org/abs/1904.00946</link>
<description rdf:parseType="Literal">&lt;p&gt;Stack Overflow has accumulated millions of answers. Informative comments can
strengthen their associated answers (e.g., providing additional information).
Currently, Stack Overflow hides comments that are ranked beyond the top 5.
Stack Overflow aims to display more informative comments (i.e., the ones with
higher scores) and hide less informative ones using this mechanism. As a
result, 4.4 million comments are hidden under their answer threads. Therefore,
it is very important to understand how well the current comment hiding
mechanism works. In this study, we investigate whether the mechanism can
effectively deliver informative comments while hiding uninformative comments.
We find that: 1) Hidden comments are as informative as displayed comments; more
than half of the comments (both hidden and displayed) are informative (e.g.,
providing alternative answers, or pointing out flaws in their associated
answers). 2) The current comment hiding mechanism tends to rank and hide
comments based on their creation time instead of their score in most cases due
to the large amount of tie-scored comments (e.g., 87% of the comments have
0-score). 3) In 97.3% of answers that have hidden comments, at least one
comment is hidden while there is another comment with the same score is
displayed (i.e., we refer to such cases as unfairly hidden comments). Among
such unfairly hidden comments, the longest unfairly hidden comment is more
likely to be informative than the shortest unfairly displayed comments. Our
findings suggest that Stack Overflow should consider adjusting their current
comment hiding mechanism, e.g., displaying longer unfairly hidden comments to
replace shorter unfairly displayed comments. We also recommend that users
examine all comments, in case they would miss informative details such as
software obsolescence, code error reports, or notices of security vulnerability
in hidden comments.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1&quot;&gt;Haoxiang Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1&quot;&gt;Shaowei Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1&quot;&gt;Tse-Hsun Peter Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hassan_A/0/1/0/all/0/1&quot;&gt;Ahmed E. Hassan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00948">
<title>The Historical Perspective of Botnet tools. (arXiv:1904.00948v1 [cs.CY])</title>
<link>http://arxiv.org/abs/1904.00948</link>
<description rdf:parseType="Literal">&lt;p&gt;Bot as it is popularly called is an inherent attributes of botnet tool.
Botnet is a group of malicious tools acting as an entity. Furthermore, history
has it that the aim of what gave rise to botnet was the idea to simplify the
method of message exchange within networking platform. However, this has led to
several botnet tools ravaging the server environments in recent times. The
working principle of these botnet tools is to get client systems that are
vulnerable and thereafter, steal valuable credentials. This work is part of a
comprehensive research work into botnet detection mechanism but, on this paper
it primarily look at how botnet as threat tool began, the trend since inception
and as well as few approaches that have been used to curb it.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Osagie_M/0/1/0/all/0/1&quot;&gt;Maxwell Scale Uwadia Osagie&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Enagbonma_O/0/1/0/all/0/1&quot;&gt;Osatohanmwen Enagbonma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Inyang_A/0/1/0/all/0/1&quot;&gt;Amanda Iriagbonse Inyang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00952">
<title>Self-Supervised Robot In-hand Object Learning. (arXiv:1904.00952v1 [cs.RO])</title>
<link>http://arxiv.org/abs/1904.00952</link>
<description rdf:parseType="Literal">&lt;p&gt;In order to complete tasks in a new environment, robots must be able to
recognize unseen, unique objects. Fully supervised methods have made great
strides on the object segmentation task, but require many examples of each
object class and don&apos;t scale to unseen environments. In this work, we present a
method that acquires pixelwise object labels for manipulable in-hand objects
with no human supervision. Our two-step approach does a foreground-background
segmentation informed by robot kinematics then uses a self-recognition network
to segment the robot from the object in the foreground. We are able to achieve
49.4\% mIoU performance on a difficult and varied assortment of items.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Florence_V/0/1/0/all/0/1&quot;&gt;Victoria Florence&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Corso_J/0/1/0/all/0/1&quot;&gt;Jason J. Corso&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Griffin_B/0/1/0/all/0/1&quot;&gt;Brent Griffin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00954">
<title>Some variations on Lyndon words. (arXiv:1904.00954v1 [cs.DM])</title>
<link>http://arxiv.org/abs/1904.00954</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper we compare two finite words $u$ and $v$ by the lexicographical
order of the infinite words $u^\omega$ and $v^\omega$. Informally, we say that
we compare $u$ and $v$ by the infinite order. We show several properties of
Lyndon words expressed using this infinite order. The innovative aspect of this
approach is that it allows to take into account also non trivial conditions on
the prefixes of a word, instead that only on the suffixes. In particular, we
derive a result of Ufnarovskij [V. Ufnarovskij, &quot;Combinatorial and asymptotic
methods in algebra&quot;, 1995] that characterizes a Lyndon word as a word which is
greater, with respect to the infinite order, than all its prefixes. Motivated
by this result, we introduce the prefix standard permutation of a Lyndon word
and the corresponding (left) Cartesian tree. We prove that the left Cartesian
tree is equal to the left Lyndon tree, defined by the left standard
factorization of Viennot [G. Viennot, &quot;Alg\`ebres de Lie libres et mono\&quot;ides
libres&quot;, 1978]. This result is dual with respect to a theorem of Hohlweg and
Reutenauer [C. Hohlweg and C. Reutenauer, &quot;Lyndon words, permutations and
trees&quot;, 2003].
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dolce_F/0/1/0/all/0/1&quot;&gt;Francesco Dolce&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Restivo_A/0/1/0/all/0/1&quot;&gt;Antonio Restivo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Reutenauer_C/0/1/0/all/0/1&quot;&gt;Christophe Reutenauer&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00956">
<title>Guided Meta-Policy Search. (arXiv:1904.00956v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1904.00956</link>
<description rdf:parseType="Literal">&lt;p&gt;Reinforcement learning (RL) algorithms have demonstrated promising results on
complex tasks, yet often require impractical numbers of samples because they
learn from scratch. Meta-RL aims to address this challenge by leveraging
experience from previous tasks in order to more quickly solve new tasks.
However, in practice, these algorithms generally also require large amounts of
on-policy experience during the meta-training process, making them impractical
for use in many problems. To this end, we propose to learn a reinforcement
learning procedure through imitation of expert policies that solve
previously-seen tasks. This involves a nested optimization, with RL in the
inner loop and supervised imitation learning in the outer loop. Because the
outer loop imitation learning can be done with off-policy data, we can achieve
significant gains in meta-learning sample efficiency. In this paper, we show
how this general idea can be used both for meta-reinforcement learning and for
learning fast RL procedures from multi-task demonstration data. The former
results in an approach that can leverage policies learned for previous tasks
without significant amounts of on-policy data during meta-training, whereas the
latter is particularly useful in cases where demonstrations are easy for a
person to provide. Across a number of continuous control meta-RL problems, we
demonstrate significant improvements in meta-RL sample efficiency in comparison
to prior work as well as the ability to scale to domains with visual
observations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mendonca_R/0/1/0/all/0/1&quot;&gt;Russell Mendonca&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gupta_A/0/1/0/all/0/1&quot;&gt;Abhishek Gupta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kralev_R/0/1/0/all/0/1&quot;&gt;Rosen Kralev&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Abbeel_P/0/1/0/all/0/1&quot;&gt;Pieter Abbeel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Levine_S/0/1/0/all/0/1&quot;&gt;Sergey Levine&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Finn_C/0/1/0/all/0/1&quot;&gt;Chelsea Finn&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00962">
<title>Reducing BERT Pre-Training Time from 3 Days to 76 Minutes. (arXiv:1904.00962v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1904.00962</link>
<description rdf:parseType="Literal">&lt;p&gt;Large-batch training is key to speeding up deep neural network training in
large distributed systems. However, large-batch training is difficult because
it produces a generalization gap. Straightforward optimization often leads to
accuracy loss on the test set. BERT \cite{devlin2018bert} is a state-of-the-art
deep learning model that builds on top of deep bidirectional transformers for
language understanding. Previous large-batch training techniques do not perform
well for BERT when we scale the batch size (e.g. beyond 8192). BERT
pre-training also takes a long time to finish (around three days on 16 TPUv3
chips). To solve this problem, we propose the LAMB optimizer, which helps us to
scale the batch size to 65536 without losing accuracy. LAMB is a general
optimizer that works for both small and large batch sizes and does not need
hyper-parameter tuning besides the learning rate. The baseline BERT-Large model
needs 1 million iterations to finish pre-training, while LAMB with batch size
65536/32768 only needs 8599 iterations. We push the batch size to the memory
limit of a TPUv3 pod and can finish BERT training in 76 minutes.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+You_Y/0/1/0/all/0/1&quot;&gt;Yang You&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1&quot;&gt;Jing Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hseu_J/0/1/0/all/0/1&quot;&gt;Jonathan Hseu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Song_X/0/1/0/all/0/1&quot;&gt;Xiaodan Song&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Demmel_J/0/1/0/all/0/1&quot;&gt;James Demmel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hsieh_C/0/1/0/all/0/1&quot;&gt;Cho-Jui Hsieh&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00964">
<title>Complexity and Algorithms for Semipaired Domination in Graphs. (arXiv:1904.00964v1 [cs.DM])</title>
<link>http://arxiv.org/abs/1904.00964</link>
<description rdf:parseType="Literal">&lt;p&gt;For a graph $G=(V,E)$ with no isolated vertices, a set $D\subseteq V$ is
called a semipaired dominating set of G if $(i)$ $D$ is a dominating set of
$G$, and $(ii)$ $D$ can be partitioned into two element subsets such that the
vertices in each two element set are at distance at most two. The minimum
cardinality of a semipaired dominating set of $G$ is called the semipaired
domination number of $G$, and is denoted by $\gamma_{pr2}(G)$. The
\textsc{Minimum Semipaired Domination} problem is to find a semipaired
dominating set of $G$ of cardinality $\gamma_{pr2}(G)$. In this paper, we
initiate the algorithmic study of the \textsc{Minimum Semipaired Domination}
problem. We show that the decision version of the \textsc{Minimum Semipaired
Domination} problem is NP-complete for bipartite graphs and split graphs. On
the positive side, we present a linear-time algorithm to compute a minimum
cardinality semipaired dominating set of interval graphs and trees. We also
propose a $1+\ln(2\Delta+2)$-approximation algorithm for the \textsc{Minimum
Semipaired Domination} problem, where $\Delta$ denote the maximum degree of the
graph and show that the \textsc{Minimum Semipaired Domination} problem cannot
be approximated within $(1-\epsilon) \ln|V|$ for any $\epsilon &amp;gt; 0$ unless NP
$\subseteq$ DTIME$(|V|^{O(\log\log|V|)})$.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Henning_M/0/1/0/all/0/1&quot;&gt;Michael A. Henning&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pandey_A/0/1/0/all/0/1&quot;&gt;Arti Pandey&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tripathi_V/0/1/0/all/0/1&quot;&gt;Vikash Tripathi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00973">
<title>Recognising and evaluating the effectiveness of extortion in the Iterated Prisoner&apos;s Dilemma. (arXiv:1904.00973v1 [cs.GT])</title>
<link>http://arxiv.org/abs/1904.00973</link>
<description rdf:parseType="Literal">&lt;p&gt;Since the introduction of zero-determinant strategies, extortionate
strategies have received considerable interest. While an interesting class of
strategies, the definitions of extortionate strategies are algebraically rigid,
apply only to memory-one strategies, and require complete knowledge of a
strategy (memory-one cooperation probabilities). We describe a method to detect
extortionate behaviour from the history of play of a strategy. When applied to
a corpus of 204 strategies this method detects extortionate behaviour in
well-known extortionate strategies as well others that do not fit the algebraic
definition. The highest performing strategies in this corpus are able to
exhibit selectively extortionate behavior, cooperating with strong strategies
while exploiting weaker strategies, which no memory-one strategy can do. These
strategies emerged from an evolutionary selection process and their existence
contradicts widely-repeated folklore in the evolutionary game theory
literature: complex strategies can be extraordinarily effective,
zero-determinant strategies can be outperformed by non-zero determinant
strategies, and longer memory strategies are able to outperform short memory
strategies. Moreover, while resistance to extortion is critical for the
evolution of cooperation, the extortion of weak opponents need not prevent
cooperation between stronger opponents, and this adaptability may be crucial to
maintaining cooperation in the long run.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Knight_V/0/1/0/all/0/1&quot;&gt;Vincent A. Knight&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Harper_M/0/1/0/all/0/1&quot;&gt;Marc Harper&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Glynatsi_N/0/1/0/all/0/1&quot;&gt;Nikoleta E. Glynatsi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gillard_J/0/1/0/all/0/1&quot;&gt;Jonathan Gillard&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00976">
<title>Bisimulation for Feller-Dynkin Processes. (arXiv:1904.00976v1 [cs.LO])</title>
<link>http://arxiv.org/abs/1904.00976</link>
<description rdf:parseType="Literal">&lt;p&gt;Bisimulation is a concept that captures behavioural equivalence. It has been
studied extensively on nonprobabilistic systems and on discrete-time Markov
processes and on so-called continuous-time Markov chains. In the latter time is
continuous but the evolution still proceeds in jumps. We propose two
definitions of bisimulation on continuous-time stochastic processes where the
evolution is a \emph{flow} through time. We show that they are equivalent and
we show that when restricted to discrete-time, our concept of bisimulation
encompasses the standard discrete-time concept. The concept we introduce is not
a straightforward generalization of discrete-time concepts.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1&quot;&gt;Linan Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Clerc_F/0/1/0/all/0/1&quot;&gt;Florence Clerc&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Panangaden_P/0/1/0/all/0/1&quot;&gt;Prakash Panangaden&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00977">
<title>Sentiment analysis with genetically evolved Gaussian kernels. (arXiv:1904.00977v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1904.00977</link>
<description rdf:parseType="Literal">&lt;p&gt;Sentiment analysis consists of evaluating opinions or statements from the
analysis of text. Among the methods used to estimate the degree in which a text
expresses a given sentiment, are those based on Gaussian Processes. However,
traditional Gaussian Processes methods use a predefined kernel with
hyperparameters that can be tuned but whose structure can not be adapted. In
this paper, we propose the application of Genetic Programming for evolving
Gaussian Process kernels that are more precise for sentiment analysis. We use
use a very flexible representation of kernels combined with a multi-objective
approach that simultaneously considers two quality metrics and the
computational time spent by the kernels. Our results show that the algorithm
can outperform Gaussian Processes with traditional kernels for some of the
sentiment analysis tasks considered.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Roman_I/0/1/0/all/0/1&quot;&gt;I. Roman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mendiburu_A/0/1/0/all/0/1&quot;&gt;A. Mendiburu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Santana_R/0/1/0/all/0/1&quot;&gt;R. Santana&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lozano_J/0/1/0/all/0/1&quot;&gt;J. A. Lozano&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00979">
<title>Regional Homogeneity: Towards Learning Transferable Universal Adversarial Perturbations Against Defenses. (arXiv:1904.00979v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1904.00979</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper focuses on learning transferable adversarial examples specifically
against defense models (models to defense adversarial attacks). In particular,
we show that a simple universal perturbation can fool a series of
state-of-the-art defenses.
&lt;/p&gt;
&lt;p&gt;Adversarial examples generated by existing attacks are generally hard to
transfer to defense models. We observe the property of regional homogeneity in
adversarial perturbations and suggest that the defenses are less robust to
regionally homogeneous perturbations. Therefore, we propose an effective
transforming paradigm and a customized gradient transformer module to transform
existing perturbations into regionally homogeneous ones. Without explicitly
forcing the perturbations to be universal, we observe that a well-trained
gradient transformer module tends to output input-independent gradients (hence
universal) benefiting from the under-fitting phenomenon. Thorough experiments
demonstrate that our work significantly outperforms the prior art attacking
algorithms (either image-dependent or universal ones) by an average improvement
of 14.0% when attacking 9 defenses in the black-box setting. In addition to the
cross-model transferability, we also verify that regionally homogeneous
perturbations can well transfer across different vision tasks (attacking with
the semantic segmentation task and testing on the object detection task).
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1&quot;&gt;Yingwei Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bai_S/0/1/0/all/0/1&quot;&gt;Song Bai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xie_C/0/1/0/all/0/1&quot;&gt;Cihang Xie&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liao_Z/0/1/0/all/0/1&quot;&gt;Zhenyu Liao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shen_X/0/1/0/all/0/1&quot;&gt;Xiaohui Shen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yuille_A/0/1/0/all/0/1&quot;&gt;Alan L. Yuille&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00982">
<title>Automatic Nonrigid Histological Image Registration with Adaptive Multistep Algorithm. (arXiv:1904.00982v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1904.00982</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we present a short description of the method proposed to ANHIR
challenge organized jointly with the IEEE ISBI 2019 conference. We propose a
method consisting of preprocessing, initial alignment, nonrigid registration
algorithms and a method to automatically choose the best result. The method
turned out to be robust (99.792% robustness) and accurate (0.38% average median
rTRE). The main drawback of the proposed method is relatively high computation
time. However, this aspect can be easily improved by cleaning the code and
proposing a GPU implementation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wodzinski_M/0/1/0/all/0/1&quot;&gt;Marek Wodzinski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Skalski_A/0/1/0/all/0/1&quot;&gt;Andrzej Skalski&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00987">
<title>Convexity and monotonicity in nonlinear optimal control under uncertainty. (arXiv:1904.00987v1 [math.OC])</title>
<link>http://arxiv.org/abs/1904.00987</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider the problem of finite-horizon optimal control design under
uncertainty for imperfectly observed discrete-time systems with convex costs
and constraints. It is known that this problem can be cast as an
infinite-dimensional convex program when the dynamics and measurements are
linear, uncertainty is additive, and the risks associated with constraint
violations and excessive costs are measured in expectation or in the worst
case. In this paper, we extend this result to systems with convex or concave
dynamics, nonlinear measurements, more general uncertainty structures and other
coherent risk measures. In this setting, the optimal control problem can be
cast as an infinite-dimensional convex program if (1) the costs, constraints
and dynamics satisfy certain monotonicity properties, and (2) the measured
outputs can be reversibly `purified&apos; of the influence of the control inputs
through Q- or Youla-parameterization. The practical value of this result is
that the finite-dimensional subproblems arising in a variety of suboptimal
control methods, notably including model predictive control and the Q-design
procedure, are also convex for this class of nonlinear systems. Subproblems can
therefore be solved to global optimality using convenient modeling software and
efficient, reliable solvers. We illustrate these ideas in a numerical example.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Kircher_K/0/1/0/all/0/1&quot;&gt;Kevin J. Kircher&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Zhang_K/0/1/0/all/0/1&quot;&gt;K. Max Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00993">
<title>Equivariant Multi-View Networks. (arXiv:1904.00993v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1904.00993</link>
<description rdf:parseType="Literal">&lt;p&gt;Several approaches to 3D vision tasks process multiple views of the input
independently with deep neural networks pre-trained on natural images,
achieving view permutation invariance through a single round of pooling over
all views. We argue that this operation discards important information and
leads to subpar global descriptors. In this paper, we propose a group
convolutional approach to multiple view aggregation where convolutions are
performed over a discrete subgroup of the rotation group, enabling, thus, joint
reasoning over all views in an equivariant (instead of invariant) fashion, up
to the very last layer. We further develop this idea to operate on smaller
discrete homogeneous spaces of the rotation group, where a polar view
representation is used to maintain equivariance with only a fraction of the
number of input views. We set the new state of the art in several large scale
3D shape retrieval tasks, and show additional applications to panoramic scene
classification.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Esteves_C/0/1/0/all/0/1&quot;&gt;Carlos Esteves&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1&quot;&gt;Yinshuang Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Allen_Blanchette_C/0/1/0/all/0/1&quot;&gt;Christine Allen-Blanchette&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Daniilidis_K/0/1/0/all/0/1&quot;&gt;Kostas Daniilidis&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1904.00996">
<title>Distributed Ledger Technology for IoT: Parasite Chain Attacks. (arXiv:1904.00996v1 [cs.DC])</title>
<link>http://arxiv.org/abs/1904.00996</link>
<description rdf:parseType="Literal">&lt;p&gt;Directed Acyclic Graph (DAG) based Distributed Ledgers can be useful in a
number of applications in the IoT domain. A distributed ledger should serve as
an immutable and irreversible record of transactions, however, a DAG structure
is a more complicated mathematical object than its blockchain counterparts, and
as a result, providing guarantees of immutability and irreversibility is more
involved. In this paper, we analyse a commonly discussed attack scenario known
as a parasite chain attack for the IOTA Foundation DAG based ledger. We analyse
the efficacy of IOTA core MCMC algorithm using a matrix model and present an
extension which improves the ledger resistance to these attacks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cullen_A/0/1/0/all/0/1&quot;&gt;Andrew Cullen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ferraro_P/0/1/0/all/0/1&quot;&gt;Pietro Ferraro&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+King_C/0/1/0/all/0/1&quot;&gt;Christopher King&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shorten_R/0/1/0/all/0/1&quot;&gt;Robert Shorten&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/0801.3669">
<title>Merkle&apos;s Key Agreement Protocol is Optimal: An $O(n^2)$ Attack on any Key Agreement from Random Oracles. (arXiv:0801.3669v4 [cs.CC] UPDATED)</title>
<link>http://arxiv.org/abs/0801.3669</link>
<description rdf:parseType="Literal">&lt;p&gt;We prove that every key agreement protocol in the random oracle model in
which the honest users make at most $n$ queries to the oracle can be broken by
an adversary who makes $O(n^2)$ queries to the oracle. This improves on the
previous $\widetilde{\Omega}(n^6)$ query attack given by Impagliazzo and Rudich
(STOC &apos;89) and resolves an open question posed by them.
&lt;/p&gt;
&lt;p&gt;Our bound is optimal up to a constant factor since Merkle proposed a key
agreement protocol in 1974 that can be easily implemented with $n$ queries to a
random oracle and cannot be broken by any adversary who asks $o(n^2)$ queries.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Barak_B/0/1/0/all/0/1&quot;&gt;Boaz Barak&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mahmoody_M/0/1/0/all/0/1&quot;&gt;Mohammad Mahmoody&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/0801.3680">
<title>Lower Bounds on Signatures from Symmetric Primitives. (arXiv:0801.3680v3 [cs.CC] UPDATED)</title>
<link>http://arxiv.org/abs/0801.3680</link>
<description rdf:parseType="Literal">&lt;p&gt;We show that every construction of one-time signature schemes from a random
oracle achieves black-box security at most $2^{(1+o(1))q}$, where $q$ is the
total number of oracle queries asked by the key generation, signing, and
verification algorithms. That is, any such scheme can be broken with
probability close to $1$ by a (computationally unbounded) adversary making
$2^{(1+o(1))q}$ queries to the oracle. This is tight up to a constant factor in
the number of queries, since a simple modification of Lamport&apos;s one-time
signatures (Lamport &apos;79) achieves $2^{(0.812-o(1))q}$ black-box security using
$q$ queries to the oracle.
&lt;/p&gt;
&lt;p&gt;Our result extends (with a loss of a constant factor in the number of
queries) also to the random permutation and ideal-cipher oracles. Since the
symmetric primitives (e.g. block ciphers, hash functions, and message
authentication codes) can be constructed by a constant number of queries to the
mentioned oracles, as corollary we get lower bounds on the efficiency of
signature schemes from symmetric primitives when the construction is black-box.
This can be taken as evidence of an inherent efficiency gap between signature
schemes and symmetric primitives.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Barak_B/0/1/0/all/0/1&quot;&gt;Boaz Barak&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mahmoody_M/0/1/0/all/0/1&quot;&gt;Mohammad Mahmoody&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1308.3301">
<title>Undecidability of $L(\mathcal{A})=L(\mathcal{B})$ recognized by measure many 1-way quantum automata. (arXiv:1308.3301v10 [cs.FL] UPDATED)</title>
<link>http://arxiv.org/abs/1308.3301</link>
<description rdf:parseType="Literal">&lt;p&gt;Let $L_{&amp;gt;\lambda}(\mathcal{A})$ and $L_{\geq\lambda}(\mathcal{A})$ be the
languages recognized by {\em measure many 1-way quantum finite automata
(MMQFA)} (or,{\em enhanced 1-way quantum finite automata(EQFA)}) $\mathcal{A}$
with strict, resp. non-strict cut-point $\lambda$. We consider the languages
equivalence problem, showing that
&lt;/p&gt;
&lt;p&gt;\begin{itemize}
&lt;/p&gt;
&lt;p&gt;\item {both strict and non-strict languages equivalence are undecidable;}
&lt;/p&gt;
&lt;p&gt;\item {to do this, we provide an additional proof of the undecidability of
non-strict and strict emptiness of MMQFA(EQFA), and then reducing the languages
equivalence problem to emptiness problem;}
&lt;/p&gt;
&lt;p&gt;\item{Finally, some other Propositions derived from the above results are
collected.}
&lt;/p&gt;
&lt;p&gt;\end{itemize}
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_T/0/1/0/all/0/1&quot;&gt;Tianrong Lin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1409.6365">
<title>Lift &amp; Project Systems Performing on the Partial-Vertex-Cover Polytope. (arXiv:1409.6365v2 [cs.DS] UPDATED)</title>
<link>http://arxiv.org/abs/1409.6365</link>
<description rdf:parseType="Literal">&lt;p&gt;We study integrality gap (IG) lower bounds on strong LP and SDP relaxations
derived by the Sherali-Adams (SA), Lovasz-Schrijver-SDP (LS+), and
Sherali-Adams-SDP (SA+) lift-and-project (L&amp;amp;P) systems for the
t-Partial-Vertex-Cover (t-PVC) problem, a variation of the classic Vertex-Cover
problem in which only t edges need to be covered. t-PVC admits a
2-approximation using various algorithmic techniques, all relying on a natural
LP relaxation. Starting from this LP relaxation, our main results assert that
for every epsilon &amp;gt; 0, level-Theta(n) LPs or SDPs derived by all known L&amp;amp;P
systems that have been used for positive algorithmic results (but the Lasserre
hierarchy) have IGs at least (1-epsilon)n/t, where n is the number of vertices
of the input graph. Our lower bounds are nearly tight.
&lt;/p&gt;
&lt;p&gt;Our results show that restricted yet powerful models of computation derived
by many L&amp;amp;P systems fail to witness c-approximate solutions to t-PVC for any
constant c, and for t = O(n). This is one of the very few known examples of an
intractable combinatorial optimization problem for which LP-based algorithms
induce a constant approximation ratio, still lift-and-project LP and SDP
tightenings of the same LP have unbounded IGs.
&lt;/p&gt;
&lt;p&gt;We also show that the SDP that has given the best algorithm known for t-PVC
has integrality gap n/t on instances that can be solved by the level-1 LP
relaxation derived by the LS system. This constitutes another rare phenomenon
where (even in specific instances) a static LP outperforms an SDP that has been
used for the best approximation guarantee for the problem at hand. Finally, one
of our main contributions is that we make explicit of a new and simple
methodology of constructing solutions to LP relaxations that almost trivially
satisfy constraints derived by all SDP L&amp;amp;P systems known to be useful for
algorithmic positive results (except the La system).
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Georgiou_K/0/1/0/all/0/1&quot;&gt;Konstantinos Georgiou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jiang_A/0/1/0/all/0/1&quot;&gt;Andy Jiang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_E/0/1/0/all/0/1&quot;&gt;Edward Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Olave_A/0/1/0/all/0/1&quot;&gt;Astrid A. Olave&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Seong_I/0/1/0/all/0/1&quot;&gt;Ian Seong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Upadhyaya_T/0/1/0/all/0/1&quot;&gt;Twesh Upadhyaya&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1606.09589">
<title>The Changing Locus of Health Data Production and Use: Patient-Generated Health Data, Observations of Daily Living, and Personal Health Information Management. (arXiv:1606.09589v3 [cs.CY] UPDATED)</title>
<link>http://arxiv.org/abs/1606.09589</link>
<description rdf:parseType="Literal">&lt;p&gt;Despite the growing attention of researcher, healthcare managers and policy
makers, data gathering and information management practices are largely
untheorized areas. In this work are presented and discussed some early-stage
conceptualizations: Patient-Generated Health Data (PGHD), Observations of Daily
Living (ODLs) and Personal Health Information Management (PHIM). As I shall try
to demonstrate, these labels are not neutral rather they underpin quite
different perspectives with respect to health, patient-doctor relationship, and
the status of data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Piras_E/0/1/0/all/0/1&quot;&gt;Enrico Maria Piras&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1610.02336">
<title>Approximation Algorithms for Multi-Multiway Cut and Multicut Problems on Directed Graphs. (arXiv:1610.02336v5 [cs.DS] UPDATED)</title>
<link>http://arxiv.org/abs/1610.02336</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we present two approximation algorithms for the directed
multi-multiway cut and directed multicut problems. The so called region growing
paradigm \cite{1} is modified and used for these two cut problems on directed
graphs. By using this paradigm, we give for each problem an approximation
algorithm such that both algorithms have the approximate factor $O(k)$ the same
as the previous works done on these problems. However, the previous works need
to solve $k$ linear programming, whereas our algorithms require only one linear
programming. Therefore, our algorithms improve the running time of the previous
algorithms.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yarinezhad_R/0/1/0/all/0/1&quot;&gt;Ramin Yarinezhad&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hashemi_S/0/1/0/all/0/1&quot;&gt;Seyed Naser Hashemi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1701.03077">
<title>A General and Adaptive Robust Loss Function. (arXiv:1701.03077v9 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1701.03077</link>
<description rdf:parseType="Literal">&lt;p&gt;We present a generalization of the Cauchy/Lorentzian, Geman-McClure,
Welsch/Leclerc, generalized Charbonnier, Charbonnier/pseudo-Huber/L1-L2, and L2
loss functions. By introducing robustness as a continuous parameter, our loss
function allows algorithms built around robust loss minimization to be
generalized, which improves performance on basic vision tasks such as
registration and clustering. Interpreting our loss as the negative log of a
univariate density yields a general probability distribution that includes
normal and Cauchy distributions as special cases. This probabilistic
interpretation enables the training of neural networks in which the robustness
of the loss automatically adapts itself during training, which improves
performance on learning-based tasks such as generative image synthesis and
unsupervised monocular depth estimation, without requiring any manual parameter
tuning.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Barron_J/0/1/0/all/0/1&quot;&gt;Jonathan T. Barron&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1701.04695">
<title>Consistency Analysis for Massively Inconsistent Datasets in Bound-to-Bound Data Collaboration. (arXiv:1701.04695v3 [math.OC] UPDATED)</title>
<link>http://arxiv.org/abs/1701.04695</link>
<description rdf:parseType="Literal">&lt;p&gt;Bound-to-Bound Data Collaboration (B2BDC) provides a natural framework for
addressing both forward and inverse uncertainty quantification problems. In
this approach, QOI (quantity of interest) models are constrained by related
experimental observations with interval uncertainty. A collection of such
models and observations is termed a dataset and carves out a feasible region in
the parameter space. If a dataset has a nonempty feasible set, it is said to be
consistent. In real-world applications, it is often the case that collections
of experiments and observations are inconsistent. Revealing the source of this
inconsistency, i.e., identifying which models and/or observations are
problematic, is essential before a dataset can be used for prediction. To
address this issue, we introduce a constraint relaxation-based approach,
entitled the vector consistency measure, for investigating datasets with
numerous sources of inconsistency. The benefits of this vector consistency
measure over a previous method of consistency analysis are demonstrated in two
realistic gas combustion examples.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Hegde_A/0/1/0/all/0/1&quot;&gt;Arun Hegde&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Li_W/0/1/0/all/0/1&quot;&gt;Wenyu Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Oreluk_J/0/1/0/all/0/1&quot;&gt;James Oreluk&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Packard_A/0/1/0/all/0/1&quot;&gt;Andrew Packard&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Frenklach_M/0/1/0/all/0/1&quot;&gt;Michael Frenklach&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1706.03459">
<title>Optimal Auctions through Deep Learning. (arXiv:1706.03459v3 [cs.GT] UPDATED)</title>
<link>http://arxiv.org/abs/1706.03459</link>
<description rdf:parseType="Literal">&lt;p&gt;Designing an incentive compatible auction that maximizes expected revenue is
an intricate task. The single-item case was resolved in a seminal piece of work
by Myerson in 1981. Even after 30-40 years of intense research the problem
remains unsolved for seemingly simple multi-bidder, multi-item settings. In
this work, we initiate the exploration of the use of tools from deep learning
for the automated design of optimal auctions. We model an auction as a
multi-layer neural network, frame optimal auction design as a constrained
learning problem, and show how it can be solved using standard pipelines. We
prove generalization bounds and present extensive experiments, recovering
essentially all known analytical solutions for multi-item settings, and
obtaining novel mechanisms for settings in which the optimal mechanism is
unknown.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dutting_P/0/1/0/all/0/1&quot;&gt;Paul D&amp;#xfc;tting&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Feng_Z/0/1/0/all/0/1&quot;&gt;Zhe Feng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Narasimhan_H/0/1/0/all/0/1&quot;&gt;Harikrishna Narasimhan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Parkes_D/0/1/0/all/0/1&quot;&gt;David C. Parkes&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ravindranath_S/0/1/0/all/0/1&quot;&gt;Sai Srivatsa Ravindranath&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1706.04894">
<title>Finding Dominating Induced Matchings in $(S_{2,2,3})$-Free Graphs in Polynomial Time. (arXiv:1706.04894v4 [cs.DM] UPDATED)</title>
<link>http://arxiv.org/abs/1706.04894</link>
<description rdf:parseType="Literal">&lt;p&gt;Let $G=(V,E)$ be a finite undirected graph. An edge set $E&apos; \subseteq E$ is a
{\em dominating induced matching} ({\em d.i.m.}) in $G$ if every edge in $E$ is
intersected by exactly one edge of $E&apos;$. The \emph{Dominating Induced Matching}
(\emph{DIM}) problem asks for the existence of a d.i.m.\ in $G$; this problem
is also known as the \emph{Efficient Edge Domination} problem; it is the
Efficient Domination problem for line graphs. The DIM problem is \NP-complete
even for very restricted graph classes such as planar bipartite graphs with
maximum degree 3 and is solvable in linear time for $P_7$-free graphs, and in
polynomial time for $S_{1,2,4}$-free graphs as well as for $S_{2,2,2}$-free
graphs. In this paper, combining two distinct approaches, we solve it in
polynomial time for $S_{2,2,3}$-free graphs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Brandstadt_A/0/1/0/all/0/1&quot;&gt;Andreas Brandst&amp;#xe4;dt&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mosca_R/0/1/0/all/0/1&quot;&gt;Raffaele Mosca&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1707.08552">
<title>A Robust Multi-Batch L-BFGS Method for Machine Learning. (arXiv:1707.08552v2 [math.OC] UPDATED)</title>
<link>http://arxiv.org/abs/1707.08552</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper describes an implementation of the L-BFGS method designed to deal
with two adversarial situations. The first occurs in distributed computing
environments where some of the computational nodes devoted to the evaluation of
the function and gradient are unable to return results on time. A similar
challenge occurs in a multi-batch approach in which the data points used to
compute function and gradients are purposely changed at each iteration to
accelerate the learning process. Difficulties arise because L-BFGS employs
gradient differences to update the Hessian approximations, and when these
gradients are computed using different data points the updating process can be
unstable. This paper shows how to perform stable quasi-Newton updating in the
multi-batch setting, studies the convergence properties for both convex and
nonconvex functions, and illustrates the behavior of the algorithm in a
distributed computing platform on binary classification logistic regression and
neural network training problems that arise in machine learning.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Berahas_A/0/1/0/all/0/1&quot;&gt;Albert S. Berahas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Takac_M/0/1/0/all/0/1&quot;&gt;Martin Tak&amp;#xe1;&amp;#x10d;&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1708.00598">
<title>Controllable Generative Adversarial Network. (arXiv:1708.00598v5 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1708.00598</link>
<description rdf:parseType="Literal">&lt;p&gt;Recently introduced generative adversarial network (GAN) has been shown
numerous promising results to generate realistic samples. The essential task of
GAN is to control the features of samples generated from a random distribution.
While the current GAN structures, such as conditional GAN, successfully
generate samples with desired major features, they often fail to produce
detailed features that bring specific differences among samples. To overcome
this limitation, here we propose a controllable GAN (ControlGAN) structure. By
separating a feature classifier from a discriminator, the generator of
ControlGAN is designed to learn generating synthetic samples with the specific
detailed features. Evaluated with multiple image datasets, ControlGAN shows a
power to generate improved samples with well-controlled features. Furthermore,
we demonstrate that ControlGAN can generate intermediate features and opposite
features for interpolated and extrapolated input labels that are not used in
the training process. It implies that ControlGAN can significantly contribute
to the variety of generated samples.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_M/0/1/0/all/0/1&quot;&gt;Minhyeok Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Seok_J/0/1/0/all/0/1&quot;&gt;Junhee Seok&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1708.01706">
<title>Comparative Analysis and Framework Evaluating Mimicry-Resistant and Invisible Web Authentication Schemes. (arXiv:1708.01706v2 [cs.CR] UPDATED)</title>
<link>http://arxiv.org/abs/1708.01706</link>
<description rdf:parseType="Literal">&lt;p&gt;Many password alternatives for web authentication proposed over the years,
despite having different designs and objectives, all predominantly rely on the
knowledge of some secret. This motivates us, herein, to provide the first
detailed exploration of the integration of a fundamentally different element of
defense into the design of web authentication schemes: a mimicry-resistance
dimension. We analyze web authentication mechanisms with respect to new
usability and security properties related to mimicry-resistance (augmenting the
UDS framework), and in particular evaluate invisible techniques (those
requiring neither user actions, nor awareness) that provide some
mimicry-resistance (unlike those relying solely on static secrets), including
device fingerprinting schemes, PUFs (physically unclonable functions), and a
subset of Internet geolocation mechanisms.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Alaca_F/0/1/0/all/0/1&quot;&gt;Furkan Alaca&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Abdou_A/0/1/0/all/0/1&quot;&gt;AbdelRahman Abdou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Oorschot_P/0/1/0/all/0/1&quot;&gt;Paul C. van Oorschot&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1709.06965">
<title>Drawing Graphs on Few Circles and Few Spheres. (arXiv:1709.06965v3 [cs.CG] UPDATED)</title>
<link>http://arxiv.org/abs/1709.06965</link>
<description rdf:parseType="Literal">&lt;p&gt;Given a drawing of a graph, its \emph{visual complexity} is defined as the
number of geometrical entities in the drawing, for example, the number of
segments in a straight-line drawing or the number of arcs in a circular-arc
drawing (in 2D). Recently, Chaplick et al. [GD 2016] introduced a different
measure for the visual complexity, the \emph{affine cover number}, which is the
minimum number of lines (or planes) that together cover a crossing-free
straight-line drawing of a graph $G$ in 2D (3D). In this paper, we introduce
the \emph{spherical cover number}, which is the minimum number of circles (or
spheres) that together cover a crossing-free circular-arc drawing in 2D (or
3D). It turns out that spherical covers are sometimes significantly smaller
than affine covers. Moreover, there are highly symmetric graphs that have
symmetric optimum spherical covers but apparently no symmetric optimum affine
cover. For complete, complete bipartite, and platonic graphs, we analyze their
spherical cover numbers and compare them to their affine cover numbers as well
as their segment and arc numbers. We also link the spherical cover number to
other graph parameters such as chromatic number, treewidth, and linear
arboricity.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kryven_M/0/1/0/all/0/1&quot;&gt;Myroslav Kryven&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ravsky_A/0/1/0/all/0/1&quot;&gt;Alexander Ravsky&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wolff_A/0/1/0/all/0/1&quot;&gt;Alexander Wolff&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.00681">
<title>Extracting an English-Persian Parallel Corpus from Comparable Corpora. (arXiv:1711.00681v3 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/1711.00681</link>
<description rdf:parseType="Literal">&lt;p&gt;Parallel data are an important part of a reliable Statistical Machine
Translation (SMT) system. The more of these data are available, the better the
quality of the SMT system. However, for some language pairs such as
Persian-English, parallel sources of this kind are scarce. In this paper, a
bidirectional method is proposed to extract parallel sentences from English and
Persian document aligned Wikipedia. Two machine translation systems are
employed to translate from Persian to English and the reverse after which an IR
system is used to measure the similarity of the translated sentences. Adding
the extracted sentences to the training data of the existing SMT systems is
shown to improve the quality of the translation. Furthermore, the proposed
method slightly outperforms the one-directional approach. The extracted corpus
consists of about 200,000 sentences which have been sorted by their degree of
similarity calculated by the IR system and is freely available for public
access on the Web.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Karimi_A/0/1/0/all/0/1&quot;&gt;Akbar Karimi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ansari_E/0/1/0/all/0/1&quot;&gt;Ebrahim Ansari&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bigham_B/0/1/0/all/0/1&quot;&gt;Bahram Sadeghi Bigham&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.06705">
<title>Principal Boundary on Riemannian Manifolds. (arXiv:1711.06705v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1711.06705</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider the classification problem and focus on nonlinear methods for
classification on manifolds. For multivariate datasets lying on an embedded
nonlinear Riemannian manifold within the higher-dimensional ambient space, we
aim to acquire a classification boundary for the classes with labels, using the
intrinsic metric on the manifolds. Motivated by finding an optimal boundary
between the two classes, we invent a novel approach -- the principal boundary.
From the perspective of classification, the principal boundary is defined as an
optimal curve that moves in between the principal flows traced out from two
classes of data, and at any point on the boundary, it maximizes the margin
between the two classes. We estimate the boundary in quality with its
direction, supervised by the two principal flows. We show that the principal
boundary yields the usual decision boundary found by the support vector machine
in the sense that locally, the two boundaries coincide. Some optimality and
convergence properties of the random principal boundary and its population
counterpart are also shown. We illustrate how to find, use and interpret the
principal boundary with an application in real data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Yao_Z/0/1/0/all/0/1&quot;&gt;Zhigang Yao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zhang_Z/0/1/0/all/0/1&quot;&gt;Zhenyue Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.08268">
<title>Beyond saliency: understanding convolutional neural networks from saliency prediction on layer-wise relevance propagation. (arXiv:1712.08268v5 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1712.08268</link>
<description rdf:parseType="Literal">&lt;p&gt;Despite the tremendous achievements of deep convolutional neural networks
(CNNs) in many computer vision tasks, understanding how they actually work
remains a significant challenge. In this paper, we propose a novel two-step
understanding method, namely Salient Relevance (SR) map, which aims to shed
light on how deep CNNs recognize images and learn features from areas, referred
to as attention areas, therein. Our proposed method starts out with a
layer-wise relevance propagation (LRP) step which estimates a pixel-wise
relevance map over the input image. Following, we construct a context-aware
saliency map, SR map, from the LRP-generated map which predicts areas close to
the foci of attention instead of isolated pixels that LRP reveals. In human
visual system, information of regions is more important than of pixels in
recognition. Consequently, our proposed approach closely simulates human
recognition. Experimental results using the ILSVRC2012 validation dataset in
conjunction with two well-established deep CNN models, AlexNet and VGG-16,
clearly demonstrate that our proposed approach concisely identifies not only
key pixels but also attention areas that contribute to the underlying neural
network&apos;s comprehension of the given images. As such, our proposed SR map
constitutes a convenient visual interface which unveils the visual attention of
the network and reveals which type of objects the model has learned to
recognize after training. The source code is available at
https://github.com/Hey1Li/Salient-Relevance-Propagation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1&quot;&gt;Heyi Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tian_Y/0/1/0/all/0/1&quot;&gt;Yunke Tian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mueller_K/0/1/0/all/0/1&quot;&gt;Klaus Mueller&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1&quot;&gt;Xin Chen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.10431">
<title>Towards Efficient Data-flow Test Data Generation. (arXiv:1803.10431v2 [cs.SE] UPDATED)</title>
<link>http://arxiv.org/abs/1803.10431</link>
<description rdf:parseType="Literal">&lt;p&gt;Data-flow testing (DFT) aims to detect potential data interaction anomalies
by focusing on the points at which variables receive values and the points at
which these values are used. Such test objectives are referred as \emph{def-use
pairs}. However, the complexity of DFT still overwhelms the testers in
practice. To tackle this problem, we introduce a hybrid testing framework for
data-flow based test generation: (1) The core of our framework is symbolic
execution (SE), enhanced by a novel guided path exploration strategy to improve
testing performance; and (2) we systematically cast DFT as reachability
checking in software model checking (SMC) to complement SE, yielding practical
DFT that combines the two techniques&apos; strengths. We implemented our framework
for C programs on top of the state-of-the-art symbolic execution engine KLEE
and instantiated with three different software model checkers. Our evaluation
on the 28,354 def-use pairs collected from 33 open-source and industrial
program subjects shows (1) our SE-based approach can improve DFT performance by
15$\sim$48% in terms of testing time, compared with existing search strategies;
and (2) our combined approach can further reduce testing time by
20.1$\sim$93.6%, and improve data-flow coverage by 27.8$\sim$45.2% by
eliminating infeasible test objectives. Compared with the SMC-based approach
alone, our combined approach can also reduce testing time by 19.9$\sim$23.8%,
and improve data-flow coverage by 7$\sim$10%. This combined approach also
enables the cross-checking of each component for reliable and robust testing
results. We have made our testing framework and benchmarks publicly available
to facilitate future research.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Su_T/0/1/0/all/0/1&quot;&gt;Ting Su&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1&quot;&gt;Chengyu Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yan_Y/0/1/0/all/0/1&quot;&gt;Yichen Yan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fan_L/0/1/0/all/0/1&quot;&gt;Lingling Fan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pu_G/0/1/0/all/0/1&quot;&gt;Geguang Pu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1&quot;&gt;Yang Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fu_Z/0/1/0/all/0/1&quot;&gt;Zhoulai Fu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Su_Z/0/1/0/all/0/1&quot;&gt;Zhendong Su&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.00257">
<title>Real-time Progressive 3D Semantic Segmentation for Indoor Scene. (arXiv:1804.00257v4 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1804.00257</link>
<description rdf:parseType="Literal">&lt;p&gt;The widespread adoption of autonomous systems such as drones and assistant
robots has created a need for real-time high-quality semantic scene
segmentation. In this paper, we propose an efficient yet robust technique for
on-the-fly dense reconstruction and semantic segmentation of 3D indoor scenes.
To guarantee (near) real-time performance, our method is built atop an
efficient super-voxel clustering method and a conditional random field with
higher-order constraints from structural and object cues, enabling progressive
dense semantic segmentation without any precomputation. We extensively evaluate
our method on different indoor scenes including kitchens, offices, and bedrooms
in the SceneNN and ScanNet datasets and show that our technique consistently
produces state-of-the-art segmentation results in both qualitative and
quantitative experiments.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pham_Q/0/1/0/all/0/1&quot;&gt;Quang-Hieu Pham&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hua_B/0/1/0/all/0/1&quot;&gt;Binh-Son Hua&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nguyen_D/0/1/0/all/0/1&quot;&gt;Duc Thanh Nguyen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yeung_S/0/1/0/all/0/1&quot;&gt;Sai-Kit Yeung&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.01429">
<title>Layout-induced Video Representation for Recognizing Agent-in-Place Actions. (arXiv:1804.01429v3 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1804.01429</link>
<description rdf:parseType="Literal">&lt;p&gt;We address the recognition of agent-in-place actions, which are associated
with agents who perform them and places where they occur, in the context of
outdoor home surveillance. We introduce a representation of the geometry and
topology of scene layouts so that a network can generalize from the layouts
observed in the training set to unseen layouts in the test set. This
Layout-Induced Video Representation (LIVR) abstracts away low-level appearance
variance and encodes geometric and topological relationships of places in a
specific scene layout. LIVR partitions the semantic features of a video clip
into different places to force the network to learn place-based feature
descriptions; to predict the confidence of each action, LIVR aggregates
features from the place associated with an action and its adjacent places on
the scene layout. We introduce the Agent-in-Place Action dataset to show that
our method allows neural network models to generalize significantly better to
unseen scenes.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_R/0/1/0/all/0/1&quot;&gt;Ruichi Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1&quot;&gt;Hongcheng Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_A/0/1/0/all/0/1&quot;&gt;Ang Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zheng_J/0/1/0/all/0/1&quot;&gt;Jingxiao Zheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Morariu_V/0/1/0/all/0/1&quot;&gt;Vlad I. Morariu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Davis_L/0/1/0/all/0/1&quot;&gt;Larry S. Davis&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.02973">
<title>The Schulze Method of Voting. (arXiv:1804.02973v5 [cs.GT] UPDATED)</title>
<link>http://arxiv.org/abs/1804.02973</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a new single-winner election method (&quot;Schulze method&quot;) and prove
that it satisfies many academic criteria (e.g. monotonicity, reversal symmetry,
resolvability, independence of clones, Condorcet criterion, k-consistency,
polynomial runtime). We then generalize this method to proportional
representation by the single transferable vote (&quot;Schulze STV&quot;) and to methods
to calculate a proportional ranking (&quot;Schulze proportional ranking&quot;).
Furthermore, we propose a generalization of the Condorcet criterion to
multi-winner elections. This paper contains a large number of examples to
illustrate the proposed methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schulze_M/0/1/0/all/0/1&quot;&gt;Markus Schulze&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.07888">
<title>Stochastic Answer Networks for Natural Language Inference. (arXiv:1804.07888v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/1804.07888</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a stochastic answer network (SAN) to explore multi-step inference
strategies in Natural Language Inference. Rather than directly predicting the
results given the inputs, the model maintains a state and iteratively refines
its predictions. Our experiments show that SAN achieves the state-of-the-art
results on three benchmarks: Stanford Natural Language Inference (SNLI)
dataset, MultiGenre Natural Language Inference (MultiNLI) dataset and Quora
Question Pairs dataset.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1&quot;&gt;Xiaodong Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Duh_K/0/1/0/all/0/1&quot;&gt;Kevin Duh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1&quot;&gt;Jianfeng Gao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.00257">
<title>On The Design of a Novel Finite-Time Nonlinear Extended State Observer for Class of Nonlinear Systems with Mismatch Disturbances and Uncertainties. (arXiv:1805.00257v4 [cs.SY] UPDATED)</title>
<link>http://arxiv.org/abs/1805.00257</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, a novel finite - time Nonlinear Extended State Observer
(NLESO) is proposed and employed in Active Disturbance Rejection Control (ADRC)
to stabilize a nonlinear system against system&apos;s uncertainties and
discontinuous disturbances using output feedback technique. The first task was
to aggregate the uncertainties, disturbances, and any other undesired
nonlinearities in the system into a single term called the &quot;generalized
disturbance&quot;. Consequently, the ESO estimates the generalized disturbance and
cancel it from the input channel in an online fashion. A peaking phenomenon
that existed in Linear ESO (LESO) has been reduced significantly by adopting a
saturation - like nonlinear function in the proposed Nonlinear ESO (NLESO).
Stability analysis of the NLEO is studied using finite - time Lyapunov theory,
and the comparisons are presented over simulations on Permanent Magnet DC
(PMDC) motor to confirm the effectiveness of the proposed observer concerning
LESO.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ibraheem_I/0/1/0/all/0/1&quot;&gt;Ibraheem Kasim Ibraheem&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Humaidi_A/0/1/0/all/0/1&quot;&gt;Amjad J. Humaidi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.02628">
<title>PRADA: Protecting against DNN Model Stealing Attacks. (arXiv:1805.02628v5 [cs.CR] UPDATED)</title>
<link>http://arxiv.org/abs/1805.02628</link>
<description rdf:parseType="Literal">&lt;p&gt;Machine learning (ML) applications are increasingly prevalent. Protecting the
confidentiality of ML models becomes paramount for two reasons: (a) a model can
be a business advantage to its owner, and (b) an adversary may use a stolen
model to find transferable adversarial examples that can evade classification
by the original model. Access to the model can be restricted to be only via
well-defined prediction APIs. Nevertheless, prediction APIs still provide
enough information to allow an adversary to mount model extraction attacks by
sending repeated queries via the prediction API. In this paper, we describe new
model extraction attacks using novel approaches for generating synthetic
queries, and optimizing training hyperparameters. Our attacks outperform
state-of-the-art model extraction in terms of transferability of both targeted
and non-targeted adversarial examples (up to +29-44 percentage points, pp), and
prediction accuracy (up to +46 pp) on two datasets. We provide take-aways on
how to perform effective model extraction attacks. We then propose PRADA, the
first step towards generic and effective detection of DNN model extraction
attacks. It analyzes the distribution of consecutive API queries and raises an
alarm when this distribution deviates from benign behavior. We show that PRADA
can detect all prior model extraction attacks with no false positives.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Juuti_M/0/1/0/all/0/1&quot;&gt;Mika Juuti&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Szyller_S/0/1/0/all/0/1&quot;&gt;Sebastian Szyller&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Marchal_S/0/1/0/all/0/1&quot;&gt;Samuel Marchal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Asokan_N/0/1/0/all/0/1&quot;&gt;N. Asokan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.03472">
<title>Skeap &amp; Seap: Scalable Distributed Priority Queues for Constant and Arbitrary Priorities. (arXiv:1805.03472v4 [cs.DC] UPDATED)</title>
<link>http://arxiv.org/abs/1805.03472</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose two protocols for distributed priority queues (for simplicity
denoted &apos;heap&apos;) called SKEAP and SEAP. SKEAP realizes a distributed heap for a
constant amount of priorities and SEAP one for an arbitrary amount. Both
protocols build on an overlay, which induces an aggregation tree on top of
which heap operations are aggregated in batches, ensuring that our protocols
scale even for a high rate of incoming requests. As part of SEAP we provide a
novel distributed protocol for the $k$-selection problem that runs in $O(\log
n)$ rounds w.h.p. SKEAP guarantees sequential consistency for its heap
operations, while SEAP guarantees serializability. SKEAP and SEAP provide
logarithmic runtimes w.h.p. on all their operations with SEAP having to use
only $O(\log n)$ bit messages.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Feldmann_M/0/1/0/all/0/1&quot;&gt;Michael Feldmann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Scheideler_C/0/1/0/all/0/1&quot;&gt;Christian Scheideler&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.04882">
<title>Interdisciplinary collaboration in research networks: Empirical analysis of energy-related research in Greece. (arXiv:1805.04882v2 [cs.DL] UPDATED)</title>
<link>http://arxiv.org/abs/1805.04882</link>
<description rdf:parseType="Literal">&lt;p&gt;Technological innovation is intimately related to knowledge creation and
recombination. In this work we introduce a combined statistical and
network-based approach to study collaboration in scientific authorship. We
apply it to characterize recent research efforts in renewable energy technology
and its intersections with the domains of nanoscience and nanotechnology with
focus on materials, and electrical engineering and computer science in Greece
and its broader European and international environment as a case study. Using
our methods we attempt to illuminate the processes which underlie knowledge
creation and diversification in these research networks: a (positive)
relationship between expenditure on research and development and the extent and
diversity of team-based research at the intersections of the three domains is
established. Our specific findings collectively provide insights into the
collaboration structure and evolution of energy-related research activity in
Greece, while our methodology can be used for evidence-based design,
monitoring, and evaluation of interdisciplinary research programs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tritsaris_G/0/1/0/all/0/1&quot;&gt;Georgios A. Tritsaris&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Siddiqi_A/0/1/0/all/0/1&quot;&gt;Afreen Siddiqi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.06262">
<title>From Stochastic to Bit Stream Computing: Accurate Implementation of Arithmetic Circuits and Applications in Neural Networks. (arXiv:1805.06262v2 [cs.ET] UPDATED)</title>
<link>http://arxiv.org/abs/1805.06262</link>
<description rdf:parseType="Literal">&lt;p&gt;In this study, we propose a novel computing paradigm &quot;Bit Stream Computing&quot;
that is constructed on the logic used in stochastic computing, but does not
necessarily employ randomly or Binomially distributed bit streams as stochastic
computing does. Any type of streams can be used either stochastic or
deterministic. The proposed paradigm benefits from the area advantage of
stochastic logic and the accuracy advantage of conventional binary logic. We
implement accurate arithmetic multiplier and adder circuits, classified as
asynchronous or synchronous; we also consider their suitability of processing
successive streams. The proposed circuits are simulated both in gate level and
in transistor level with AMS 0.35um CMOS technology to show the circuits&apos;
potential for practical use. We thoroughly compare the proposed adders and
multipliers with their predecessors in the literature, individually and in a
neural network application. Comparisons made in terms of area and accuracy
clearly favor the proposed designs. We believe that this study opens up new
horizons for computing that enables us to implement much smaller yet accurate
arithmetic circuits compared to the conventional binary and stochastic ones.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vahapoglu_E/0/1/0/all/0/1&quot;&gt;Ensar Vahapoglu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Altun_M/0/1/0/all/0/1&quot;&gt;Mustafa Altun&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.12279">
<title>Bayesian Pose Graph Optimization via Bingham Distributions and Tempered Geodesic MCMC. (arXiv:1805.12279v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1805.12279</link>
<description rdf:parseType="Literal">&lt;p&gt;We introduce Tempered Geodesic Markov Chain Monte Carlo (TG-MCMC) algorithm
for initializing pose graph optimization problems, arising in various scenarios
such as SFM (structure from motion) or SLAM (simultaneous localization and
mapping). TG-MCMC is first of its kind as it unites asymptotically global
non-convex optimization on the spherical manifold of quaternions with posterior
sampling, in order to provide both reliable initial poses and uncertainty
estimates that are informative about the quality of individual solutions. We
devise rigorous theoretical convergence guarantees for our method and
extensively evaluate it on synthetic and real benchmark datasets. Besides its
elegance in formulation and theory, we show that our method is robust to
missing data, noise and the estimated uncertainties capture intuitive
properties of the data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Birdal_T/0/1/0/all/0/1&quot;&gt;Tolga Birdal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Simsekli_U/0/1/0/all/0/1&quot;&gt;Umut &amp;#x15e;im&amp;#x15f;ekli&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Eken_M/0/1/0/all/0/1&quot;&gt;M. Onur Eken&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ilic_S/0/1/0/all/0/1&quot;&gt;Slobodan Ilic&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.06575">
<title>RenderNet: A deep convolutional network for differentiable rendering from 3D shapes. (arXiv:1806.06575v3 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1806.06575</link>
<description rdf:parseType="Literal">&lt;p&gt;Traditional computer graphics rendering pipeline is designed for procedurally
generating 2D quality images from 3D shapes with high performance. The
non-differentiability due to discrete operations such as visibility computation
makes it hard to explicitly correlate rendering parameters and the resulting
image, posing a significant challenge for inverse rendering tasks. Recent work
on differentiable rendering achieves differentiability either by designing
surrogate gradients for non-differentiable operations or via an approximate but
differentiable renderer. These methods, however, are still limited when it
comes to handling occlusion, and restricted to particular rendering effects. We
present RenderNet, a differentiable rendering convolutional network with a
novel projection unit that can render 2D images from 3D shapes. Spatial
occlusion and shading calculation are automatically encoded in the network. Our
experiments show that RenderNet can successfully learn to implement different
shaders, and can be used in inverse rendering tasks to estimate shape, pose,
lighting and texture from a single image.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nguyen_Phuoc_T/0/1/0/all/0/1&quot;&gt;Thu Nguyen-Phuoc&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1&quot;&gt;Chuan Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Balaban_S/0/1/0/all/0/1&quot;&gt;Stephen Balaban&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1&quot;&gt;Yong-Liang Yang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.01455">
<title>Discriminative Feature Learning with Foreground Attention for Person Re-Identification. (arXiv:1807.01455v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1807.01455</link>
<description rdf:parseType="Literal">&lt;p&gt;The performance of person re-identification (Re-ID) has been seriously
effected by the large cross-view appearance variations caused by mutual
occlusions and background clutters. Hence learning a feature representation
that can adaptively emphasize the foreground persons becomes very critical to
solve the person Re-ID problem. In this paper, we propose a simple yet
effective foreground attentive neural network (FANN) to learn a discriminative
feature representation for person Re-ID, which can adaptively enhance the
positive side of foreground and weaken the negative side of background.
Specifically, a novel foreground attentive subnetwork is designed to drive the
network&apos;s attention, in which a decoder network is used to reconstruct the
binary mask by using a novel local regression loss function, and an encoder
network is regularized by the decoder network to focus its attention on the
foreground persons. The resulting feature maps of encoder network are further
fed into the body part subnetwork and feature fusion subnetwork to learn
discriminative features. Besides, a novel symmetric triplet loss function is
introduced to supervise feature learning, in which the intra-class distance is
minimized and the inter-class distance is maximized in each triplet unit,
simultaneously. Training our FANN in a multi-task learning framework, a
discriminative feature representation can be learned to find out the matched
reference to each probe among various candidates in the gallery. Extensive
experimental results on several public benchmark datasets are evaluated, which
have shown clear improvements of our method over the state-of-the-art
approaches.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_S/0/1/0/all/0/1&quot;&gt;Sanping Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1&quot;&gt;Jinjun Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Meng_D/0/1/0/all/0/1&quot;&gt;Deyu Meng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liang_Y/0/1/0/all/0/1&quot;&gt;Yudong Liang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gong_Y/0/1/0/all/0/1&quot;&gt;Yihong Gong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zheng_N/0/1/0/all/0/1&quot;&gt;Nanning Zheng&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.01989">
<title>Revisiting Perspective Information for Efficient Crowd Counting. (arXiv:1807.01989v3 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1807.01989</link>
<description rdf:parseType="Literal">&lt;p&gt;Crowd counting is the task of estimating people numbers in crowd images.
Modern crowd counting methods employ deep neural networks to estimate crowd
counts via crowd density regressions. A major challenge of this task lies in
the perspective distortion, which results in drastic person scale change in an
image. Density regression on the small person area is in general very hard. In
this work, we propose a perspective-aware convolutional neural network (PACNN)
for efficient crowd counting, which integrates the perspective information into
density regression to provide additional knowledge of the person scale change
in an image. Ground truth perspective maps are firstly generated for training;
PACNN is then specifically designed to predict multi-scale perspective maps,
and encode them as perspective-aware weighting layers in the network to
adaptively combine the outputs of multi-scale density maps. The weights are
learned at every pixel of the maps such that the final density combination is
robust to the perspective distortion. We conduct extensive experiments on the
ShanghaiTech, WorldExpo&apos;10, UCF_CC_50, and UCSD datasets, and demonstrate the
effectiveness and efficiency of PACNN over the state-of-the-art.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shi_M/0/1/0/all/0/1&quot;&gt;Miaojing Shi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1&quot;&gt;Zhaohui Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_C/0/1/0/all/0/1&quot;&gt;Chao Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_Q/0/1/0/all/0/1&quot;&gt;Qijun Chen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.04193">
<title>Distributed Variational Representation Learning. (arXiv:1807.04193v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1807.04193</link>
<description rdf:parseType="Literal">&lt;p&gt;The problem of distributed representation learning is one in which multiple
sources of information $X_1,\ldots,X_K$ are processed separately so as to learn
as much information as possible about some ground truth $Y$. We investigate
this problem from information-theoretic grounds, through a generalization of
Tishby&apos;s centralized Information Bottleneck (IB) method to the distributed
setting. Specifically, $K$ encoders, $K \geq 2$, compress their observations
$X_1,\ldots,X_K$ separately in a manner such that, collectively, the produced
representations preserve as much information as possible about $Y$. We study
both discrete memoryless (DM) and memoryless vector Gaussian data models. For
the discrete model, we establish a single-letter characterization of the
optimal tradeoff between complexity (or rate) and relevance (or information)
for a class of memoryless sources (the observations $X_1,\ldots,X_K$ being
conditionally independent given $Y$). For the vector Gaussian model, we provide
an explicit characterization of the optimal complexity-relevance tradeoff.
Furthermore, we develop a variational bound on the complexity-relevance
tradeoff which generalizes the evidence lower bound (ELBO) to the distributed
setting. We also provide two algorithms that allow to compute this bound: i) a
Blahut-Arimoto type iterative algorithm which enables to compute optimal
complexity-relevance encoding mappings by iterating over a set of
self-consistent equations, and ii) a variational inference type algorithm in
which the encoding mappings are parametrized by neural networks and the bound
approximated by Markov sampling and optimized with stochastic gradient descent.
Numerical results on synthetic and real datasets are provided to support the
efficiency of the approaches and algorithms developed in this paper.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Aguerri_I/0/1/0/all/0/1&quot;&gt;Inaki Estella Aguerri&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zaidi_A/0/1/0/all/0/1&quot;&gt;Abdellatif Zaidi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.06403">
<title>Iterative Joint Image Demosaicking and Denoising using a Residual Denoising Network. (arXiv:1807.06403v3 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1807.06403</link>
<description rdf:parseType="Literal">&lt;p&gt;Modern digital cameras rely on the sequential execution of separate image
processing steps to produce realistic images. The first two steps are usually
related to denoising and demosaicking where the former aims to reduce noise
from the sensor and the latter converts a series of light intensity readings to
color images. Modern approaches try to jointly solve these problems, i.e. joint
denoising-demosaicking which is an inherently ill-posed problem given that
two-thirds of the intensity information is missing and the rest are perturbed
by noise. While there are several machine learning systems that have been
recently introduced to solve this problem, the majority of them relies on
generic network architectures which do not explicitly take into account the
physical image model. In this work we propose a novel algorithm which is
inspired by powerful classical image regularization methods, large-scale
optimization, and deep learning techniques. Consequently, our derived iterative
optimization algorithm, which involves a trainable denoising network, has a
transparent and clear interpretation compared to other black-box data driven
approaches. Our extensive experimentation line demonstrates that our proposed
method outperforms any previous approaches for both noisy and noise-free data
across many different datasets. This improvement in reconstruction quality is
attributed to the rigorous derivation of an iterative solution and the
principled way we design our denoising network architecture, which as a result
requires fewer trainable parameters than the current state-of-the-art solution
and furthermore can be efficiently trained by using a significantly smaller
number of training data than existing deep demosaicking networks. Code and
results can be found at https://github.com/cig-skoltech/deep_demosaick
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kokkinos_F/0/1/0/all/0/1&quot;&gt;Filippos Kokkinos&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lefkimmiatis_S/0/1/0/all/0/1&quot;&gt;Stamatios Lefkimmiatis&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.11399">
<title>Who needs category theory?. (arXiv:1807.11399v2 [cs.LO] UPDATED)</title>
<link>http://arxiv.org/abs/1807.11399</link>
<description rdf:parseType="Literal">&lt;p&gt;In computer science, category theory remains a contentious issue, with
enthusiastic fans and a skeptical majority. Categories were introduced by
Samuel Eilenberg and Saunders Mac Lane as an auxiliary notion in their general
theory of natural equivalences. Here we argue that something like categories is
needed on a more basic level. As you work with operations on structures, it may
be necessary to coherently manipulate isomorphism (or more generally
homomorphism) witnesses for various properties of these operations, e.g.\
associativity, commutativity and distributivity. A working mathematician, to
use Mac Lane&apos;s term, is well advised to be aware of the coherent
witness-manipulation problem and to know that category theory or something like
it can provide an appropriate framework to address the problem. Of course, the
working mathematician in question may be a computer scientist or physicist.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Blass_A/0/1/0/all/0/1&quot;&gt;Andreas Blass&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gurevich_Y/0/1/0/all/0/1&quot;&gt;Yuri Gurevich&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1808.00327">
<title>Generative Adversarial Frontal View to Bird View Synthesis. (arXiv:1808.00327v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1808.00327</link>
<description rdf:parseType="Literal">&lt;p&gt;Environment perception is an important task with great practical value and
bird view is an essential part for creating panoramas of surrounding
environment. Due to the large gap and severe deformation between the frontal
view and bird view, generating a bird view image from a single frontal view is
challenging. To tackle this problem, we propose the BridgeGAN, i.e., a novel
generative model for bird view synthesis. First, an intermediate view, i.e.,
homography view, is introduced to bridge the large gap. Next, conditioned on
the three views (frontal view, homography view and bird view) in our task, a
multi-GAN based model is proposed to learn the challenging cross-view
translation. Extensive experiments conducted on a synthetic dataset have
demonstrated that the images generated by our model are much better than those
generated by existing methods, with more consistent global appearance and
sharper details. Ablation studies and discussions show its reliability and
robustness in some challenging cases.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_X/0/1/0/all/0/1&quot;&gt;Xinge Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yin_Z/0/1/0/all/0/1&quot;&gt;Zhichao Yin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shi_J/0/1/0/all/0/1&quot;&gt;Jianping Shi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1&quot;&gt;Hongsheng Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_D/0/1/0/all/0/1&quot;&gt;Dahua Lin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1808.03216">
<title>Data-driven polynomial chaos expansion for machine learning regression. (arXiv:1808.03216v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1808.03216</link>
<description rdf:parseType="Literal">&lt;p&gt;We present a regression technique for data-driven problems based on
polynomial chaos expansion (PCE). PCE is a popular technique in the field of
uncertainty quantification (UQ), where it is typically used to replace a
runnable but expensive computational model subject to random inputs with an
inexpensive-to-evaluate polynomial function. The metamodel obtained enables a
reliable estimation of the statistics of the output, provided that a suitable
probabilistic model of the input is available. Machine learning (ML) regression
is a research field that focuses on providing purely data-driven input-output
maps, with the focus on pointwise prediction accuracy. We show that a PCE
metamodel purely trained on data can yield pointwise predictions whose accuracy
is comparable to that of other ML regression models, such as neural networks
and support vector machines. The comparisons are performed on benchmark
datasets available from the literature. The methodology also enables the
quantification of the output uncertainties, and is robust to noise.
Furthermore, it enjoys additional desirable properties, such as good
performance for small training sets and simplicity of construction, with only
little parameter tuning required.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Torre_E/0/1/0/all/0/1&quot;&gt;E. Torre&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Marelli_S/0/1/0/all/0/1&quot;&gt;S. Marelli&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Embrechts_P/0/1/0/all/0/1&quot;&gt;P. Embrechts&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Sudret_B/0/1/0/all/0/1&quot;&gt;B. Sudret&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1808.05678">
<title>Optimization of MIMO Device-to-Device Networks via Matrix Fractional Programming: A Minorization-Maximization Approach. (arXiv:1808.05678v2 [cs.IT] UPDATED)</title>
<link>http://arxiv.org/abs/1808.05678</link>
<description rdf:parseType="Literal">&lt;p&gt;Interference management is a fundamental issue in device-to-device (D2D)
communications whenever the transmitter-and-receiver pairs are located in close
proximity and frequencies are fully reused, so active links may severely
interfere with each other. This paper devises an optimization strategy named
FPLinQ to coordinate the link scheduling decisions among the interfering links,
along with power control and beamforming. The key enabler is a novel
optimization method called matrix fractional programming (FP) that generalizes
previous scalar and vector forms of FP in allowing multiple data streams per
link. From a theoretical perspective, this paper provides a deeper
understanding of FP by showing a connection to the minorization-maximization
(MM) algorithm. From an application perspective, this paper shows that as
compared to the existing methods for coordinating scheduling in the D2D
network, such as FlashLinQ, ITLinQ, and ITLinQ+, the proposed FPLinQ approach
is more general in allowing multiple antennas at both the transmitters and the
receivers, and further in allowing arbitrary and multiple possible associations
between the devices via matching. Numerical results show that FPLinQ
significantly outperforms the previous state-of-the-art in a typical D2D
communication environment.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shen_K/0/1/0/all/0/1&quot;&gt;Kaiming Shen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_W/0/1/0/all/0/1&quot;&gt;Wei Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_L/0/1/0/all/0/1&quot;&gt;Licheng Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Palomar_D/0/1/0/all/0/1&quot;&gt;Daniel P. Palomar&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1808.07042">
<title>CoQA: A Conversational Question Answering Challenge. (arXiv:1808.07042v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/1808.07042</link>
<description rdf:parseType="Literal">&lt;p&gt;Humans gather information by engaging in conversations involving a series of
interconnected questions and answers. For machines to assist in information
gathering, it is therefore essential to enable them to answer conversational
questions. We introduce CoQA, a novel dataset for building Conversational
Question Answering systems. Our dataset contains 127k questions with answers,
obtained from 8k conversations about text passages from seven diverse domains.
The questions are conversational, and the answers are free-form text with their
corresponding evidence highlighted in the passage. We analyze CoQA in depth and
show that conversational questions have challenging phenomena not present in
existing reading comprehension datasets, e.g., coreference and pragmatic
reasoning. We evaluate strong conversational and reading comprehension models
on CoQA. The best system obtains an F1 score of 65.4%, which is 23.4 points
behind human performance (88.8%), indicating there is ample room for
improvement. We launch CoQA as a challenge to the community at
&lt;a href=&quot;http://stanfordnlp.github.io/coqa/&quot;&gt;this http URL&lt;/a&gt;
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Reddy_S/0/1/0/all/0/1&quot;&gt;Siva Reddy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_D/0/1/0/all/0/1&quot;&gt;Danqi Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Manning_C/0/1/0/all/0/1&quot;&gt;Christopher D. Manning&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1808.07747">
<title>On the Diversity of Uncoded OTFS Modulation in Doubly-Dispersive Channels. (arXiv:1808.07747v2 [cs.IT] UPDATED)</title>
<link>http://arxiv.org/abs/1808.07747</link>
<description rdf:parseType="Literal">&lt;p&gt;Orthogonal time frequency space (OTFS) is a 2-dimensional (2D) modulation
technique designed in the delay-Doppler domain. A key premise behind OTFS is
the transformation of a time varying multipath channel into an almost
non-fading 2D channel in delay-Doppler domain such that all symbols in a
transmission frame experience the same channel gain. It has been suggested in
the recent literature that OTFS can extract full diversity in the delay-Doppler
domain, where full diversity refers to the number of multipath components
separable in either the delay or Doppler dimension, but without a formal
analysis. In this paper, we present a formal analysis of the diversity achieved
by OTFS modulation along with supporting simulations. Specifically, we prove
that the asymptotic diversity order of OTFS (as SNR $\rightarrow \infty$) is
one. However, in the finite SNR regime, potential for a higher order diversity
is witnessed before the diversity one regime takes over. Also, the diversity
one regime starts at lower BER values for increased frame sizes. We also
propose a phase rotation scheme for OTFS using transcendental numbers. We show
that OTFS with this proposed scheme extracts the full diversity in the
delay-Doppler domain.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Surabhi_G/0/1/0/all/0/1&quot;&gt;G. D. Surabhi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Augustine_R/0/1/0/all/0/1&quot;&gt;Rose Mary Augustine&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chockalingam_A/0/1/0/all/0/1&quot;&gt;A. Chockalingam&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1808.08983">
<title>NeuralCubes: Deep Representations for Visual Data Exploration. (arXiv:1808.08983v2 [cs.DB] UPDATED)</title>
<link>http://arxiv.org/abs/1808.08983</link>
<description rdf:parseType="Literal">&lt;p&gt;Visual exploration of large multidimensional datasets has seen tremendous
progress in recent years, allowing users to express rich data queries that
produce informative visual summaries, all in real time. Techniques based on
data cubes are some of the most promising approaches. However, these techniques
usually require a large memory footprint for large datasets. To tackle this
problem, we present NeuralCubes: neural networks that predict results for
aggregate queries, similar to data cubes. NeuralCubes learns a function that
takes as input a given query, for instance, a geographic region and temporal
interval, and outputs the result of the query. The learned function serves as a
real-time, low-memory approximator for aggregation queries. NeuralCubes models
are small enough to be sent to the client side (e.g. the web browser for a
web-based application) for evaluation, enabling data exploration of large
datasets without database/network connection. We demonstrate the effectiveness
of NeuralCubes through extensive experiments on a variety of datasets and
discuss how NeuralCubes opens up opportunities for new types of visualization
and interaction.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1&quot;&gt;Zhe Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cashman_D/0/1/0/all/0/1&quot;&gt;Dylan Cashman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1&quot;&gt;Mingwei Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1&quot;&gt;Jixian Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Berger_M/0/1/0/all/0/1&quot;&gt;Matthew Berger&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Levine_J/0/1/0/all/0/1&quot;&gt;Joshua A. Levine&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chang_R/0/1/0/all/0/1&quot;&gt;Remco Chang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Scheidegger_C/0/1/0/all/0/1&quot;&gt;Carlos Scheidegger&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.01752">
<title>Survey on UAV Cellular Communications: Practical Aspects, Standardization Advancements, Regulation, and Security Challenges. (arXiv:1809.01752v2 [cs.NI] UPDATED)</title>
<link>http://arxiv.org/abs/1809.01752</link>
<description rdf:parseType="Literal">&lt;p&gt;The rapid growth of consumer Unmanned Aerial Vehicles (UAVs) is creating
promising new business opportunities for cellular operators. On the one hand,
UAVs can be connected to cellular networks as new types of user equipment,
therefore generating significant revenues for the operators that can guarantee
their stringent service requirements. On the other hand, UAVs offer the
unprecedented opportunity to realize UAV-mounted flying base stations that can
dynamically reposition themselves to boost coverage, spectral efficiency, and
user quality of experience. Indeed, the standardization bodies are currently
exploring possibilities for serving commercial UAVs with cellular networks.
Industries are beginning to trial early prototypes of flying base stations or
user equipments, while academia is in full swing researching mathematical and
algorithmic solutions to address interesting new problems arising from flying
nodes in cellular networks. In this article, we provide a comprehensive survey
of all of these developments promoting smooth integration of UAVs into cellular
networks. Specifically, we survey (i) the types of consumer UAVs currently
available off-the-shelf, (ii) the interference issues and potential solutions
addressed by standardization bodies for serving aerial users with the existing
terrestrial base stations, (iii) the challenges and opportunities for assisting
cellular communications with UAV-based flying relays and base stations, (iv)
the ongoing prototyping and test bed activities, (v) the new regulations being
developed to manage the commercial use of UAVs, and (vi) the cyber-physical
security of UAV-assisted cellular communications.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fotouhi_A/0/1/0/all/0/1&quot;&gt;Azade Fotouhi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qiang_H/0/1/0/all/0/1&quot;&gt;Haoran Qiang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ding_M/0/1/0/all/0/1&quot;&gt;Ming Ding&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hassan_M/0/1/0/all/0/1&quot;&gt;Mahbub Hassan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Giordano_L/0/1/0/all/0/1&quot;&gt;Lorenzo Galati Giordano&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Garcia_Rodriguez_A/0/1/0/all/0/1&quot;&gt;Adrian Garcia-Rodriguez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yuan_J/0/1/0/all/0/1&quot;&gt;Jinhong Yuan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.02156">
<title>Object Hallucination in Image Captioning. (arXiv:1809.02156v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/1809.02156</link>
<description rdf:parseType="Literal">&lt;p&gt;Despite continuously improving performance, contemporary image captioning
models are prone to &quot;hallucinating&quot; objects that are not actually in a scene.
One problem is that standard metrics only measure similarity to ground truth
captions and may not fully capture image relevance. In this work, we propose a
new image relevance metric to evaluate current models with veridical visual
labels and assess their rate of object hallucination. We analyze how captioning
model architectures and learning objectives contribute to object hallucination,
explore when hallucination is likely due to image misclassification or language
priors, and assess how well current sentence metrics capture object
hallucination. We investigate these questions on the standard image captioning
benchmark, MSCOCO, using a diverse set of models. Our analysis yields several
interesting findings, including that models which score best on standard
sentence metrics do not always have lower hallucination and that models which
hallucinate more tend to make errors driven by language priors.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rohrbach_A/0/1/0/all/0/1&quot;&gt;Anna Rohrbach&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hendricks_L/0/1/0/all/0/1&quot;&gt;Lisa Anne Hendricks&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Burns_K/0/1/0/all/0/1&quot;&gt;Kaylee Burns&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Darrell_T/0/1/0/all/0/1&quot;&gt;Trevor Darrell&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Saenko_K/0/1/0/all/0/1&quot;&gt;Kate Saenko&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.02341">
<title>A Fast Anderson-Chebyshev Mixing Method for Nonlinear Optimization. (arXiv:1809.02341v2 [math.OC] UPDATED)</title>
<link>http://arxiv.org/abs/1809.02341</link>
<description rdf:parseType="Literal">&lt;p&gt;Anderson mixing (or Anderson acceleration) is an efficient acceleration
method for fixed point iterations $x_{t+1}=G(x_t)$, e.g., gradient descent can
be viewed as iteratively applying the operation $G(x) = x-\alpha\nabla f(x)$.
It is known that Anderson mixing is quite efficient in practice and can be
viewed as an extension of Krylov subspace methods for nonlinear problems. In
this paper, we show that Anderson mixing with Chebyshev polynomial parameters
can achieve the optimal convergence rate
$O(\sqrt{\kappa}\ln\frac{1}{\epsilon})$, which improves the previous result
$O(\kappa\ln\frac{1}{\epsilon})$ provided by [Toth and Kelley, 2015] for
quadratic functions. Then, we provide a convergence analysis for minimizing
general nonlinear problems. Besides, if the hyperparameters (e.g., the
Lipschitz smooth parameter $L$) are not available, we propose a guessing
algorithm for guessing them dynamically and also prove a similar convergence
rate. Finally, the experimental results demonstrate that the proposed
Anderson-Chebyshev mixing method converges significantly faster than other
algorithms, e.g., vanilla gradient descent (GD), Nesterov&apos;s Accelerated GD.
Also, these algorithms combined with the proposed guessing algorithm (guessing
the hyperparameters dynamically) achieve much better performance.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Li_Z/0/1/0/all/0/1&quot;&gt;Zhize Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Li_J/0/1/0/all/0/1&quot;&gt;Jian Li&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.03551">
<title>Unicyclic Strong Permutations. (arXiv:1809.03551v2 [cs.CR] UPDATED)</title>
<link>http://arxiv.org/abs/1809.03551</link>
<description rdf:parseType="Literal">&lt;p&gt;For positive integers $n$ and $k$ such that $0\leq k\leq n-1$, we study some
properties of a certain kind of permutations $\sigma$ over
$\mathbb{F}_{2}^{n}$. The permutation $\sigma$ is given as the composition of
intermediate permutations $\sigma_{k}$ of a specific form. The properties that
hold simultaneously are: (1) the algebraic degree of $\sigma_{k}$ is $n-1$; (2)
the permutations $\sigma_{k}$ are unicyclic; (3) the number of terms of the
algebraic normal form of each $\sigma_{k}$ is at least $2^{n-1}$. We call these
unicyclic strong permutations. In this paper, we provide a construction for
unicyclic strong permutations. We also notice a dichotomy about the cycle
structure of $\sigma$ between odd and even values of $n\leq 30$. For the
composition $\sigma$, we also study empirically the differential uniformity for
all values of $n\leq 16$ and notice that in almost all cases it never exceeds
$6$. For the specific cases of $n=17$ and $n=19$, we report counts of the
number of equal entries of their difference table and linear approximation
table.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gravel_C/0/1/0/all/0/1&quot;&gt;Claude Gravel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Panario_D/0/1/0/all/0/1&quot;&gt;Daniel Panario&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Thomson_D/0/1/0/all/0/1&quot;&gt;David Thomson&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.05725">
<title>Completely Uncoupled User Association Algorithms for State Dependent Wireless Networks. (arXiv:1809.05725v2 [cs.SY] UPDATED)</title>
<link>http://arxiv.org/abs/1809.05725</link>
<description rdf:parseType="Literal">&lt;p&gt;We study a distributed user association algorithm for a heterogeneous
wireless network with the objective of maximizing the sum of the utilities (on
the received throughput of wireless users). We consider a state dependent
wireless network, where the rate achieved by the users are a function of their
user associations as well as the state of the system. We consider three
different scenarios depending on the state evolution and the users$\text{&apos;}$
knowledge of the system state. In this context, we present completely uncoupled
user association algorithms for utility maximization where the users$\text{&apos;}$
association is entirely a function of its past associations and its received
throughput. In particular, the user is oblivious to the association of the
other users in the network. Using the theory of perturbed Markov chains, we
show the optimality of our algorithms under appropriate scenarios.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ramakrishnan_S/0/1/0/all/0/1&quot;&gt;S. Ramakrishnan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ramaiyan_V/0/1/0/all/0/1&quot;&gt;Venkatesh Ramaiyan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Naveen_K/0/1/0/all/0/1&quot;&gt;K. P. Naveen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.06180">
<title>Probabilistic DL Reasoning with Pinpointing Formulas: A Prolog-based Approach. (arXiv:1809.06180v3 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1809.06180</link>
<description rdf:parseType="Literal">&lt;p&gt;When modeling real world domains we have to deal with information that is
incomplete or that comes from sources with different trust levels. This
motivates the need for managing uncertainty in the Semantic Web. To this
purpose, we introduced a probabilistic semantics, named DISPONTE, in order to
combine description logics with probability theory. The probability of a query
can be then computed from the set of its explanations by building a Binary
Decision Diagram (BDD). The set of explanations can be found using the tableau
algorithm, which has to handle non-determinism. Prolog, with its efficient
handling of non-determinism, is suitable for implementing the tableau
algorithm. TRILL and TRILLP are systems offering a Prolog implementation of the
tableau algorithm. TRILLP builds a pinpointing formula, that compactly
represents the set of explanations and can be directly translated into a BDD.
Both reasoners were shown to outperform state-of-the-art DL reasoners. In this
paper, we present an improvement of TRILLP, named TORNADO, in which the BDD is
directly built during the construction of the tableau, further speeding up the
overall inference process. An experimental comparison shows the effectiveness
of TORNADO. All systems can be tried online in the TRILL on SWISH web
application at &lt;a href=&quot;http://trill.ml.unife.it/.&quot;&gt;this http URL&lt;/a&gt;
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zese_R/0/1/0/all/0/1&quot;&gt;Riccardo Zese&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cota_G/0/1/0/all/0/1&quot;&gt;Giuseppe Cota&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lamma_E/0/1/0/all/0/1&quot;&gt;Evelina Lamma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bellodi_E/0/1/0/all/0/1&quot;&gt;Elena Bellodi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Riguzzi_F/0/1/0/all/0/1&quot;&gt;Fabrizio Riguzzi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.06963">
<title>Multi-task Learning with Sample Re-weighting for Machine Reading Comprehension. (arXiv:1809.06963v3 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/1809.06963</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a multi-task learning framework to learn a joint Machine Reading
Comprehension (MRC) model that can be applied to a wide range of MRC tasks in
different domains. Inspired by recent ideas of data selection in machine
translation, we develop a novel sample re-weighting scheme to assign
sample-specific weights to the loss. Empirical study shows that our approach
can be applied to many existing MRC models. Combined with contextual
representations from pre-trained language models (such as ELMo), we achieve new
state-of-the-art results on a set of MRC benchmark datasets. We release our
code at https://github.com/xycforgithub/MultiTask-MRC.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1&quot;&gt;Yichong Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1&quot;&gt;Xiaodong Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shen_Y/0/1/0/all/0/1&quot;&gt;Yelong Shen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1&quot;&gt;Jingjing Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1&quot;&gt;Jianfeng Gao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.07764">
<title>Global and Local Consistent Wavelet-domain Age Synthesis. (arXiv:1809.07764v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1809.07764</link>
<description rdf:parseType="Literal">&lt;p&gt;Age synthesis is a challenging task due to the complicated and non-linear
transformation in human aging process. Aging information is usually reflected
in local facial parts, such as wrinkles at the eye corners. However, these
local facial parts contribute less in previous GAN based methods for age
synthesis. To address this issue, we propose a Wavelet-domain Global and Local
Consistent Age Generative Adversarial Network (WaveletGLCA-GAN), in which one
global specific network and three local specific networks are integrated
together to capture both global topology information and local texture details
of human faces. Different from the most existing methods that modeling age
synthesis in image-domain, we adopt wavelet transform to depict the textual
information in frequency-domain. %Moreover, to achieve accurate age generation
under the premise of preserving the identity information, age estimation
network and face verification network are employed. Moreover, five types of
losses are adopted: 1) adversarial loss aims to generate realistic wavelets; 2)
identity preserving loss aims to better preserve identity information; 3) age
preserving loss aims to enhance the accuracy of age synthesis; 4) pixel-wise
loss aims to preserve the background information of the input face; 5) the
total variation regularization aims to remove ghosting artifacts. Our method is
evaluated on three face aging datasets, including CACD2000, Morph and FG-NET.
Qualitative and quantitative experiments show the superiority of the proposed
method over other state-of-the-arts.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_P/0/1/0/all/0/1&quot;&gt;Peipei Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hu_Y/0/1/0/all/0/1&quot;&gt;Yibo Hu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+He_R/0/1/0/all/0/1&quot;&gt;Ran He&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_Z/0/1/0/all/0/1&quot;&gt;Zhenan Sun&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.09478">
<title>Taking A Closer Look at Domain Shift: Category-level Adversaries for Semantics Consistent Domain Adaptation. (arXiv:1809.09478v3 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1809.09478</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider the problem of unsupervised domain adaptation in semantic
segmentation. The key in this campaign consists in reducing the domain shift,
i.e., enforcing the data distributions of the two domains to be similar. A
popular strategy is to align the marginal distribution in the feature space
through adversarial learning. However, this global alignment strategy does not
consider the local category-level feature distribution. A possible consequence
of the global movement is that some categories which are originally well
aligned between the source and target may be incorrectly mapped. To address
this problem, this paper introduces a category-level adversarial network,
aiming to enforce local semantic consistency during the trend of global
alignment. Our idea is to take a close look at the category-level data
distribution and align each class with an adaptive adversarial loss.
Specifically, we reduce the weight of the adversarial loss for category-level
aligned features while increasing the adversarial force for those poorly
aligned. In this process, we decide how well a feature is category-level
aligned between source and target by a co-training approach. In two domain
adaptation tasks, i.e., GTA5 -&amp;gt; Cityscapes and SYNTHIA -&amp;gt; Cityscapes, we
validate that the proposed method matches the state of the art in segmentation
accuracy.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Luo_Y/0/1/0/all/0/1&quot;&gt;Yawei Luo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zheng_L/0/1/0/all/0/1&quot;&gt;Liang Zheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guan_T/0/1/0/all/0/1&quot;&gt;Tao Guan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_J/0/1/0/all/0/1&quot;&gt;Junqing Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1&quot;&gt;Yi Yang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1810.00495">
<title>Hybrid Noise Removal in Hyperspectral Imagery With a Spatial-Spectral Gradient Network. (arXiv:1810.00495v3 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1810.00495</link>
<description rdf:parseType="Literal">&lt;p&gt;The existence of hybrid noise in hyperspectral images (HSIs) severely
degrades the data quality, reduces the interpretation accuracy of HSIs, and
restricts the subsequent HSIs applications. In this paper, the spatial-spectral
gradient network (SSGN) is presented for mixed noise removal in HSIs. The
proposed method employs a spatial-spectral gradient learning strategy, in
consideration of the unique spatial structure directionality of sparse noise
and spectral differences with additional complementary information for better
extracting intrinsic and deep features of HSIs. Based on a fully cascaded
multi-scale convolutional network, SSGN can simultaneously deal with the
different types of noise in different HSIs or spectra by the use of the same
model. The simulated and real-data experiments undertaken in this study
confirmed that the proposed SSGN performs better at mixed noise removal than
the other state-of-the-art HSI denoising algorithms, in evaluation indices,
visual assessments, and time consumption.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1&quot;&gt;Qiang Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yuan_Q/0/1/0/all/0/1&quot;&gt;Qiangqiang Yuan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1&quot;&gt;Jie Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1&quot;&gt;Xinxin Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shen_H/0/1/0/all/0/1&quot;&gt;Huanfeng Shen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1&quot;&gt;Liangpei Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1810.01405">
<title>GrAMME: Semi-Supervised Learning using Multi-layered Graph Attention Models. (arXiv:1810.01405v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1810.01405</link>
<description rdf:parseType="Literal">&lt;p&gt;Modern data analysis pipelines are becoming increasingly complex due to the
presence of multi-view information sources. While graphs are effective in
modeling complex relationships, in many scenarios a single graph is rarely
sufficient to succinctly represent all interactions, and hence multi-layered
graphs have become popular. Though this leads to richer representations,
extending solutions from the single-graph case is not straightforward.
Consequently, there is a strong need for novel solutions to solve classical
problems, such as node classification, in the multi-layered case. In this
paper, we consider the problem of semi-supervised learning with multi-layered
graphs. Though deep network embeddings, e.g. DeepWalk, are widely adopted for
community discovery, we argue that feature learning with random node
attributes, using graph neural networks, can be more effective. To this end, we
propose to use attention models for effective feature learning, and develop two
novel architectures, GrAMME-SG and GrAMME-Fusion, that exploit the inter-layer
dependencies for building multi-layered graph embeddings. Using empirical
studies on several benchmark datasets, we evaluate the proposed approaches and
demonstrate significant performance improvements in comparison to
state-of-the-art network embedding strategies. The results also show that using
simple random features is an effective choice, even in cases where explicit
node attributes are not available.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Shanthamallu_U/0/1/0/all/0/1&quot;&gt;Uday Shankar Shanthamallu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Thiagarajan_J/0/1/0/all/0/1&quot;&gt;Jayaraman J. Thiagarajan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Song_H/0/1/0/all/0/1&quot;&gt;Huan Song&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Spanias_A/0/1/0/all/0/1&quot;&gt;Andreas Spanias&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1810.03450">
<title>Active Learning for New Domains in Natural Language Understanding. (arXiv:1810.03450v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/1810.03450</link>
<description rdf:parseType="Literal">&lt;p&gt;We explore active learning (AL) for improving the accuracy of new domains in
a natural language understanding (NLU) system. We propose an algorithm called
Majority-CRF that uses an ensemble of classification models to guide the
selection of relevant utterances, as well as a sequence labeling model to help
prioritize informative examples. Experiments with three domains show that
Majority-CRF achieves 6.6%-9% relative error rate reduction compared to random
sampling with the same annotation budget, and statistically significant
improvements compared to other AL approaches. Additionally, case studies with
human-in-the-loop AL on six new domains show 4.6%-9% improvement on an existing
NLU system.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Peshterliev_S/0/1/0/all/0/1&quot;&gt;Stanislav Peshterliev&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kearney_J/0/1/0/all/0/1&quot;&gt;John Kearney&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jagannatha_A/0/1/0/all/0/1&quot;&gt;Abhyuday Jagannatha&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kiss_I/0/1/0/all/0/1&quot;&gt;Imre Kiss&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Matsoukas_S/0/1/0/all/0/1&quot;&gt;Spyros Matsoukas&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1810.03980">
<title>Explicit optimal-length locally repairable codes of distance 5. (arXiv:1810.03980v2 [cs.IT] UPDATED)</title>
<link>http://arxiv.org/abs/1810.03980</link>
<description rdf:parseType="Literal">&lt;p&gt;Locally repairable codes (LRCs) have received significant recent attention as
a method of designing data storage systems robust to server failure. Optimal
LRCs offer the ideal trade-off between minimum distance and locality, a measure
of the cost of repairing a single codeword symbol. For optimal LRCs with
minimum distance greater than or equal to 5, block length is bounded by a
polynomial function of alphabet size. In this paper, we give explicit
constructions of optimal-length (in terms of alphabet size), optimal LRCs with
minimum distance equal to 5.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Beemer_A/0/1/0/all/0/1&quot;&gt;Allison Beemer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Coatney_R/0/1/0/all/0/1&quot;&gt;Ryan Coatney&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guruswami_V/0/1/0/all/0/1&quot;&gt;Venkatesan Guruswami&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lopez_H/0/1/0/all/0/1&quot;&gt;Hiram H. L&amp;#xf3;pez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pinero_F/0/1/0/all/0/1&quot;&gt;Fernando Pi&amp;#xf1;ero&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1810.06985">
<title>Non-computability of human intelligence. (arXiv:1810.06985v6 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1810.06985</link>
<description rdf:parseType="Literal">&lt;p&gt;We revisit the question (most famously) initiated by Turing: can human
intelligence be completely modelled by a Turing machine? To give away the
ending we show here that the answer is \emph{no}, assuming a certain weak
soundness hypothesis. More specifically we show that at least some meaningful
thought processes of the brain cannot be Turing computable. In particular some
physical processes are not Turing computable, which is not entirely expected.
There are some similarities of our argument with the well known Lucas-Penrose
argument, but we work purely on the level of Turing machines, and do not use
G\&quot;odel&apos;s incompleteness theorem. Instead we construct directly and use a weak
analogue of a G\&quot;odel statement for a certain system which involves our human,
this allows us to side-step some meta-logical issues with their argument.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Savelyev_Y/0/1/0/all/0/1&quot;&gt;Yasha Savelyev&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1810.08276">
<title>FPT algorithms to recognize well covered graphs. (arXiv:1810.08276v4 [cs.DS] UPDATED)</title>
<link>http://arxiv.org/abs/1810.08276</link>
<description rdf:parseType="Literal">&lt;p&gt;Given a graph $G$, let $vc(G)$ and $vc^+(G)$ be the sizes of a minimum and a
maximum minimal vertex covers of $G$, respectively. We say that $G$ is well
covered if $vc(G)=vc^+(G)$ (that is, all minimal vertex covers have the same
size). Determining if a graph is well covered is a coNP-complete problem. In
this paper, we obtain $O^*(2^{vc})$-time and $O^*(1.4656^{vc^+})$-time
algorithms to decide well coveredness, improving results of Boria et. al.
(2015). Moreover, using crown decomposition, we show that such problems admit
kernels having linear number of vertices. In 2018, Alves et. al. (2018) proved
that recognizing well covered graphs is coW[2]-hard when the independence
number $\alpha(G)=n-vc(G)$ is the parameter. Contrasting with such
coW[2]-hardness, we present an FPT algorithm to decide well coveredness when
$\alpha(G)$ and the degeneracy of the input graph $G$ are aggregate parameters.
Finally, we use the primeval decomposition technique to obtain a linear time
algorithm for extended $P_4$-laden graphs and $(q,q-4)$-graphs, which is FPT
parameterized by $q$, improving results of Klein et al (2013).
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Araujo_R/0/1/0/all/0/1&quot;&gt;Rafael Araujo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Costa_E/0/1/0/all/0/1&quot;&gt;Eurinardo Costa&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Klein_S/0/1/0/all/0/1&quot;&gt;Sulamita Klein&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sampaio_R/0/1/0/all/0/1&quot;&gt;Rudini Sampaio&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Souza_U/0/1/0/all/0/1&quot;&gt;Ueverton S. Souza&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1810.08380">
<title>Formalizing computability theory via partial recursive functions. (arXiv:1810.08380v2 [cs.LO] UPDATED)</title>
<link>http://arxiv.org/abs/1810.08380</link>
<description rdf:parseType="Literal">&lt;p&gt;We present an extension to the $\mathtt{mathlib}$ library of the Lean theorem
prover formalizing the foundations of computability theory. We use primitive
recursive functions and partial recursive functions as the main objects of
study, and we use a constructive encoding of partial functions such that they
are executable when the programs in question provably halt. Main theorems
include the construction of a universal partial recursive function and a proof
of the undecidability of the halting problem. Type class inference provides a
transparent way to supply G\&quot;{o}del numberings where needed and encapsulate the
encoding details.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Carneiro_M/0/1/0/all/0/1&quot;&gt;Mario Carneiro&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1810.10121">
<title>nGraph-HE: A Graph Compiler for Deep Learning on Homomorphically Encrypted Data. (arXiv:1810.10121v2 [cs.CR] UPDATED)</title>
<link>http://arxiv.org/abs/1810.10121</link>
<description rdf:parseType="Literal">&lt;p&gt;Homomorphic encryption (HE)--the ability to perform computations on encrypted
data--is an attractive remedy to increasing concerns about data privacy in the
field of machine learning. However, building models that operate on ciphertext
is currently labor-intensive and requires simultaneous expertise in deep
learning, cryptography, and software engineering. Deep learning frameworks,
together with recent advances in graph compilers, have greatly accelerated the
training and deployment of deep learning models to a variety of computing
platforms. Here, we introduce nGraph-HE, an extension of the nGraph deep
learning compiler, which allows data scientists to deploy trained models with
popular frameworks like TensorFlow, MXNet and PyTorch directly, while simply
treating HE as another hardware target. This combination of frameworks and
graph compilers greatly simplifies the development of privacy-preserving
machine learning systems, provides a clean abstraction barrier between deep
learning and HE, allows HE libraries to exploit HE-specific graph
optimizations, and comes at a low cost in runtime overhead versus native HE
operations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Boemer_F/0/1/0/all/0/1&quot;&gt;Fabian Boemer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lao_Y/0/1/0/all/0/1&quot;&gt;Yixing Lao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wierzynski_C/0/1/0/all/0/1&quot;&gt;Casimir Wierzynski&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1810.11829">
<title>On preserving non-discrimination when combining expert advice. (arXiv:1810.11829v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1810.11829</link>
<description rdf:parseType="Literal">&lt;p&gt;We study the interplay between sequential decision making and avoiding
discrimination against protected groups, when examples arrive online and do not
follow distributional assumptions. We consider the most basic extension of
classical online learning: &quot;Given a class of predictors that are individually
non-discriminatory with respect to a particular metric, how can we combine them
to perform as well as the best predictor, while preserving non-discrimination?&quot;
Surprisingly we show that this task is unachievable for the prevalent notion of
&quot;equalized odds&quot; that requires equal false negative rates and equal false
positive rates across groups. On the positive side, for another notion of
non-discrimination, &quot;equalized error rates&quot;, we show that running separate
instances of the classical multiplicative weights algorithm for each group
achieves this guarantee. Interestingly, even for this notion, we show that
algorithms with stronger performance guarantees than multiplicative weights
cannot preserve non-discrimination.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Blum_A/0/1/0/all/0/1&quot;&gt;Avrim Blum&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gunasekar_S/0/1/0/all/0/1&quot;&gt;Suriya Gunasekar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lykouris_T/0/1/0/all/0/1&quot;&gt;Thodoris Lykouris&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Srebro_N/0/1/0/all/0/1&quot;&gt;Nathan Srebro&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1810.11968">
<title>Sensitivity of $\ell_{1}$ minimization to parameter choice. (arXiv:1810.11968v2 [cs.IT] UPDATED)</title>
<link>http://arxiv.org/abs/1810.11968</link>
<description rdf:parseType="Literal">&lt;p&gt;The use of generalized LASSO is a common technique for recovery of structured
high-dimensional signals. Each generalized LASSO program has a governing
parameter whose optimal value depends on properties of the data. At this
optimal value, compressed sensing theory explains why LASSO programs recover
structured high-dimensional signals with minimax order-optimal error.
Unfortunately in practice, the optimal choice is generally unknown and must be
estimated. Thus, we investigate stability of each LASSO program with respect to
its governing parameter. Our goal is to aid the practitioner in answering the
following question: given real data, which LASSO program should be used? We
take a step towards answering this by analyzing the case where the measurement
matrix is identity (the so-called proximal denoising setup) and we use
$\ell_{1}$ regularization. For each LASSO program, we specify settings in which
that program is provably unstable with respect to its governing parameter. We
support our analysis with detailed numerical simulations. For example, there
are settings where a 0.1% underestimate of a LASSO parameter can increase the
error significantly; and a 50% underestimate can cause the error to increase by
a factor of $10^{9}$.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Berk_A/0/1/0/all/0/1&quot;&gt;Aaron Berk&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Plan_Y/0/1/0/all/0/1&quot;&gt;Yaniv Plan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yilmaz_O/0/1/0/all/0/1&quot;&gt;&amp;#xd6;zg&amp;#xfc;r Yilmaz&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1810.13137">
<title>Introducing SPAIN (SParse Audio INpainter). (arXiv:1810.13137v3 [cs.SD] UPDATED)</title>
<link>http://arxiv.org/abs/1810.13137</link>
<description rdf:parseType="Literal">&lt;p&gt;A novel sparsity-based algorithm for audio inpainting is proposed by
translating the SPADE algorithm by Kiti\&apos;c et. al.---the state-of-the-art for
audio declipping---into the task of audio inpainting. SPAIN (SParse Audio
INpainter) comes in synthesis and analysis variants. Experiments show that both
A-SPAIN and S-SPAIN outperform other sparsity-based inpainting algorithms and
that A-SPAIN performs on a par with the state-of-the-art method based on linear
prediction.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mokry_O/0/1/0/all/0/1&quot;&gt;Ond&amp;#x159;ej Mokr&amp;#xfd;&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zaviska_P/0/1/0/all/0/1&quot;&gt;Pavel Z&amp;#xe1;vi&amp;#x161;ka&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rajmic_P/0/1/0/all/0/1&quot;&gt;Pavel Rajmic&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vesely_V/0/1/0/all/0/1&quot;&gt;V&amp;#xed;t&amp;#x11b;zslav Vesel&amp;#xfd;&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1811.01233">
<title>Deep Ad-hoc Beamforming. (arXiv:1811.01233v3 [cs.SD] UPDATED)</title>
<link>http://arxiv.org/abs/1811.01233</link>
<description rdf:parseType="Literal">&lt;p&gt;Although deep learning based speech enhancement methods have demonstrated
good performance in adverse acoustic environments, their performance is
strongly affected by the distance between the speech source and the microphones
since speech signals fade quickly during the propagation. To address the above
problem, we propose \textit{deep ad-hoc beamforming}---a deep-learning-based
multichannel speech enhancement method with ad-hoc microphone arrays. It serves
for scenarios where the microphones are placed randomly in a room and work
collaboratively. Its core idea is to reweight the estimated speech signals with
a sparsity constraint when conducting adaptive beamforming, where the weights
produced by a neural network are the estimates of some predefined propagation
cost, and the sparsity constraint is to filter out the microphones that are too
far away from both the speech source and the majority of the ad-hoc microphone
array. We conducted an extensive experiment in a scenario where the location of
the speech source is far-field, random, and blind to the microphones. Results
show that our method outperforms referenced deep-learning-based speech
enhancement methods by a large margin.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1&quot;&gt;Xiao-Lei Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1811.01248">
<title>Compressed Multiple Pattern Matching. (arXiv:1811.01248v2 [cs.DS] UPDATED)</title>
<link>http://arxiv.org/abs/1811.01248</link>
<description rdf:parseType="Literal">&lt;p&gt;Given $d$ strings over the alphabet $\{0,1,\ldots,\sigma{-}1\}$, the
classical Aho--Corasick data structure allows us to find all $occ$ occurrences
of the strings in any text $T$ in $O(|T| + occ)$ time using $O(m\log m)$ bits
of space, where $m$ is the number of edges in the trie containing the strings.
Fix any constant $\varepsilon \in (0, 2)$. We describe a compressed solution
for the problem that, provided $\sigma \le m^\delta$ for a constant $\delta &amp;lt;
1$, works in $O(|T| \frac{1}{\varepsilon} \log\frac{1}{\varepsilon} + occ)$
time, which is $O(|T| + occ)$ since $\varepsilon$ is constant, and occupies
$mH_k + 1.443 m + \varepsilon m + O(d\log\frac{m}{d})$ bits of space, for all
$0 \le k \le \max\{0,\alpha\log_\sigma m - 2\}$ simultaneously, where $\alpha
\in (0,1)$ is an arbitrary constant and $H_k$ is the $k$th-order empirical
entropy of the trie. Hence, we reduce the $3.443m$ term in the space bounds of
previously best succinct solutions to $(1.443 + \varepsilon)m$, thus solving an
open problem posed by Belazzougui. Further, we notice that $L =
\log\binom{\sigma (m+1)}{m} - O(\log(\sigma m))$ is a worst-case space lower
bound for any solution of the problem and, for $d = o(m)$ and constant
$\varepsilon$, our approach allows to achieve $L + \varepsilon m$ bits of
space, which gives an evidence that, for $d = o(m)$, the space of our data
structure is theoretically optimal up to the $\varepsilon m$ additive term and
it is hardly possible to eliminate the term $1.443m$. In addition, we refine
the space analysis of previous works by proposing a more appropriate definition
for $H_k$. We also simplify the construction for practice adapting the fixed
block compression boosting technique, then implement our data structure, and
conduct a number of experiments showing that it is comparable to the state of
the art in terms of time and is superior in space.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kosolobov_D/0/1/0/all/0/1&quot;&gt;Dmitry Kosolobov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sivukhin_N/0/1/0/all/0/1&quot;&gt;Nikita Sivukhin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1811.04713">
<title>Gauges, Loops, and Polynomials for Partition Functions of Graphical Models. (arXiv:1811.04713v5 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1811.04713</link>
<description rdf:parseType="Literal">&lt;p&gt;Graphical models (GM) represent multivariate and generally not normalized
probability distributions. Computing the normalization factor, called the
partition function (PF), is the main inference challenge relevant to multiple
statistical and optimization applications. The problem is of an exponential
complexity with respect to the number of variables. In this manuscript, aimed
at approximating the PF, we consider Multi-Graph Models (MGMs) where binary
variables and multivariable factors are associated with edges and nodes,
respectively, of an undirected multi-graph. We suggest a new methodology for
analysis and computations that combines the Gauge Function (GF) technique with
the technique from the field of real stable polynomials. We show that the GF,
representing a single-out term in a finite sum expression for the PF which
achieves extremum at the so-called Belief-Propagation (BP) gauge, has a natural
polynomial representation in terms of gauges/variables associated with edges of
the multi-graph. Moreover, GF can be used to recover the PF through a sequence
of transformations allowing appealing algebraic and graphical interpretations.
Algebraically, one step in the sequence consists in application of a
differential operator over gauges associated with an edge. Graphically, the
sequence is interpreted as a repetitive elimination/contraction of edges
resulting in MGMs on decreasing in size (number of edges) graphs with the same
PF as in the original MGM. Even though complexity of computing factors in the
sequence of derived MGMs and respective GFs grow exponentially with the number
of eliminated edges, polynomials associated with the new factors remain
bi-stable if the original factors have this property. Moreover, we show that BP
estimations in the sequence do not decrease, each low-bounding the PF.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chertkov_M/0/1/0/all/0/1&quot;&gt;Michael Chertkov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chernyak_V/0/1/0/all/0/1&quot;&gt;Vladimir Chernyak&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Maximov_Y/0/1/0/all/0/1&quot;&gt;Yury Maximov&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1811.04815">
<title>Automatic kidney segmentation in ultrasound images using subsequent boundary distance regression and pixelwise classification networks. (arXiv:1811.04815v3 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1811.04815</link>
<description rdf:parseType="Literal">&lt;p&gt;It remains challenging to automatically segment kidneys in clinical
ultrasound (US) images due to the kidneys&apos; varied shapes and image intensity
distributions, although semi-automatic methods have achieved promising
performance. In this study, we propose subsequent boundary distance regression
and pixel classification networks to segment the kidneys, informed by the fact
that the kidney boundaries have relatively homogenous texture patterns across
images. Particularly, we first use deep neural networks pre-trained for
classification of natural images to extract high-level image features from US
images, then these features are used as input to learn kidney boundary distance
maps using a boundary distance regression network, and finally the predicted
boundary distance maps are classified as kidney pixels or non-kidney pixels
using a pixel classification network in an end-to-end learning fashion. We also
adopted a data-augmentation method based on kidney shape registration to
generate enriched training data from a small number of US images with manually
segmented kidney labels. Experimental results have demonstrated that our method
could effectively improve the performance of automatic kidney segmentation,
significantly better than deep learning-based pixel classification networks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yin_S/0/1/0/all/0/1&quot;&gt;Shi Yin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Peng_Q/0/1/0/all/0/1&quot;&gt;Qinmu Peng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1&quot;&gt;Hongming Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1&quot;&gt;Zhengqiang Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+You_X/0/1/0/all/0/1&quot;&gt;Xinge You&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Furth_S/0/1/0/all/0/1&quot;&gt;Susan L. Furth&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tasian_G/0/1/0/all/0/1&quot;&gt;Gregory E. Tasian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fan_Y/0/1/0/all/0/1&quot;&gt;Yong Fan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1811.06397">
<title>Offline Biases in Online Platforms: a Study of Diversity and Homophily in Airbnb. (arXiv:1811.06397v2 [cs.SI] UPDATED)</title>
<link>http://arxiv.org/abs/1811.06397</link>
<description rdf:parseType="Literal">&lt;p&gt;How diverse are sharing economy platforms? Are they fair marketplaces, where
all participants operate on a level playing field, or are they large-scale
online aggregators of offline human biases? Often portrayed as easy-to-access
digital spaces whose participants receive equal opportunities, such platforms
have recently come under fire due to reports of discriminatory behaviours among
their users, and have been associated with gentrification phenomena that
exacerbate preexisting inequalities along racial lines. In this paper, we focus
on the Airbnb sharing economy platform, and analyse the diversity of its user
base across five large cities. We find it to be predominantly young, female,
and white. Notably, we find this to be true even in cities with a diverse
racial composition. We then introduce a method based on the statistical
analysis of networks to quantify behaviours of homophily, heterophily and
avoidance between Airbnb hosts and guests. Depending on cities and property
types, we do find signals of such behaviours relating both to race and gender.
We use these findings to provide platform design recommendations, aimed at
exposing and possibly reducing the biases we detect, in support of a more
inclusive growth of sharing economy platforms.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Koh_V/0/1/0/all/0/1&quot;&gt;Victoria Koh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1&quot;&gt;Weihua Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Livan_G/0/1/0/all/0/1&quot;&gt;Giacomo Livan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Capra_L/0/1/0/all/0/1&quot;&gt;Licia Capra&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1811.08982">
<title>Polarity Loss for Zero-shot Object Detection. (arXiv:1811.08982v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1811.08982</link>
<description rdf:parseType="Literal">&lt;p&gt;Zero-shot object detection is an emerging research topic that aims to
recognize and localize previously &apos;unseen&apos; objects. This setting gives rise to
several unique challenges, e.g., highly imbalanced positive vs. negative
instance ratio, ambiguity between background and unseen classes and the proper
alignment between visual and semantic concepts. Here, we propose an end-to-end
deep learning framework underpinned by a novel loss function that seeks to
properly align the visual and semantic cues for improved zero-shot learning. We
call our objective the &apos;Polarity loss&apos; because it explicitly maximizes the gap
between positive and negative predictions. Such a margin maximizing formulation
is not only important for visual-semantic alignment but it also resolves the
ambiguity between background and unseen objects. Our approach is inspired by
the embodiment theories in cognitive science, that claim human semantic
understanding to be grounded in past experiences (seen objects), related
linguistic concepts (word dictionary) and the perception of the physical world
(visual imagery). To this end, we learn to attend to a dictionary of related
semantic concepts that eventually refines the noisy semantic embeddings and
helps establish a better synergy between visual and semantic domains. Our
extensive results on MS-COCO and Pascal VOC datasets show as high as 14x mAP
improvement over state of the art.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rahman_S/0/1/0/all/0/1&quot;&gt;Shafin Rahman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khan_S/0/1/0/all/0/1&quot;&gt;Salman Khan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Barnes_N/0/1/0/all/0/1&quot;&gt;Nick Barnes&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1811.09751">
<title>Characterizing and Avoiding Negative Transfer. (arXiv:1811.09751v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1811.09751</link>
<description rdf:parseType="Literal">&lt;p&gt;When labeled data is scarce for a specific target task, transfer learning
often offers an effective solution by utilizing data from a related source
task. However, when transferring knowledge from a less related source, it may
inversely hurt the target performance, a phenomenon known as negative transfer.
Despite its pervasiveness, negative transfer is usually described in an
informal manner, lacking rigorous definition, careful analysis, or systematic
treatment. This paper proposes a formal definition of negative transfer and
analyzes three important aspects thereof. Stemming from this analysis, a novel
technique is proposed to circumvent negative transfer by filtering out
unrelated source data. Based on adversarial networks, the technique is highly
generic and can be applied to a wide range of transfer learning algorithms. The
proposed approach is evaluated on six state-of-the-art deep transfer methods
via experiments on four benchmark datasets with varying levels of difficulty.
Empirically, the proposed method consistently improves the performance of all
baseline methods and largely avoids negative transfer, even when the source
data is degenerate.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1&quot;&gt;Zirui Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dai_Z/0/1/0/all/0/1&quot;&gt;Zihang Dai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Poczos_B/0/1/0/all/0/1&quot;&gt;Barnab&amp;#xe1;s P&amp;#xf3;czos&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Carbonell_J/0/1/0/all/0/1&quot;&gt;Jaime Carbonell&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1811.09845">
<title>Tell, Draw, and Repeat: Generating and modifying images based on continual linguistic instruction. (arXiv:1811.09845v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1811.09845</link>
<description rdf:parseType="Literal">&lt;p&gt;Conditional text-to-image generation is an active area of research, with many
possible applications. Existing research has primarily focused on generating a
single image from available conditioning information in one step. One practical
extension beyond one-step generation is a system that generates an image
iteratively, conditioned on ongoing linguistic input or feedback. This is
significantly more challenging than one-step generation tasks, as such a system
must understand the contents of its generated images with respect to the
feedback history, the current feedback, as well as the interactions among
concepts present in the feedback history. In this work, we present a recurrent
image generation model which takes into account both the generated output up to
the current step as well as all past instructions for generation. We show that
our model is able to generate the background, add new objects, and apply simple
transformations to existing objects. We believe our approach is an important
step toward interactive generation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+El_Nouby_A/0/1/0/all/0/1&quot;&gt;Alaaeldin El-Nouby&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sharma_S/0/1/0/all/0/1&quot;&gt;Shikhar Sharma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schulz_H/0/1/0/all/0/1&quot;&gt;Hannes Schulz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hjelm_D/0/1/0/all/0/1&quot;&gt;Devon Hjelm&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Asri_L/0/1/0/all/0/1&quot;&gt;Layla El Asri&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kahou_S/0/1/0/all/0/1&quot;&gt;Samira Ebrahimi Kahou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bengio_Y/0/1/0/all/0/1&quot;&gt;Yoshua Bengio&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Taylor_G/0/1/0/all/0/1&quot;&gt;Graham W.Taylor&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1811.10322">
<title>On the Relationship Between Inference and Data Privacy in Decentralized IoT Networks. (arXiv:1811.10322v2 [cs.IT] UPDATED)</title>
<link>http://arxiv.org/abs/1811.10322</link>
<description rdf:parseType="Literal">&lt;p&gt;In a decentralized Internet of Things (IoT) network, a fusion center receives
information from multiple sensors to infer a public hypothesis of interest. To
prevent the fusion center from abusing the sensor information, each sensor
sanitizes its local observation using a local privacy mapping, which is
designed to achieve both inference privacy of a private hypothesis and data
privacy of the sensor raw observations. Various inference and data privacy
metrics have been proposed in the literature. We introduce the concepts of
privacy implication and non-guarantee to study the relationships between these
privacy metrics. We propose an optimization framework in which both local
differential privacy (data privacy) and information privacy (inference privacy)
metrics are incorporated. In the parametric case where sensor observations&apos;
distributions are known \emph{a priori}, we propose a two-stage local privacy
mapping at each sensor, and show that such an architecture is able to achieve
information privacy and local differential privacy to within the predefined
budgets. For the nonparametric case where sensor distributions are unknown, we
adopt an empirical optimization approach. Simulation and experiment results
demonstrate that our proposed approaches allow the fusion center to accurately
infer the public hypothesis while protecting both inference and data privacy.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_M/0/1/0/all/0/1&quot;&gt;Meng Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tay_W/0/1/0/all/0/1&quot;&gt;Wee Peng Tay&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1811.10983">
<title>GarNet: A Two-stream Network for Fast and Accurate 3D Cloth Draping. (arXiv:1811.10983v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1811.10983</link>
<description rdf:parseType="Literal">&lt;p&gt;While Physics-Based Simulation (PBS) can accurately drape a 3D garment on a
3D body, it remains too costly for real-time applications, such as virtual
try-on. By contrast, inference in a deep network, requiring a single forward
pass, is much faster. Taking advantage of this, we propose a novel architecture
to fit a 3D garment template to a 3D body. Specifically, we build upon the
recent progress in 3D point cloud processing with deep networks to extract
garment features at varying levels of detail, including point-wise, patch-wise
and global features. We fuse these features with those extracted in parallel
from the 3D body, so as to model the cloth-body interactions. The resulting
two-stream architecture, which we call as GarNet, is trained using a loss
function inspired by physics-based modeling, and delivers visually plausible
garment shapes whose 3D points are, on average, less than 1 cm away from those
of a PBS method, while running 100 times faster. Moreover, the proposed method
can model various garment types with different cutting patterns when parameters
of those patterns are given as input to the network.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gundogdu_E/0/1/0/all/0/1&quot;&gt;Erhan Gundogdu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Constantin_V/0/1/0/all/0/1&quot;&gt;Victor Constantin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Seifoddini_A/0/1/0/all/0/1&quot;&gt;Amrollah Seifoddini&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dang_M/0/1/0/all/0/1&quot;&gt;Minh Dang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Salzmann_M/0/1/0/all/0/1&quot;&gt;Mathieu Salzmann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fua_P/0/1/0/all/0/1&quot;&gt;Pascal Fua&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1811.11205">
<title>You Look Twice: GaterNet for Dynamic Filter Selection in CNNs. (arXiv:1811.11205v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1811.11205</link>
<description rdf:parseType="Literal">&lt;p&gt;The concept of conditional computation for deep nets has been proposed
previously to improve model performance by selectively using only parts of the
model conditioned on the sample it is processing. In this paper, we investigate
input-dependent dynamic filter selection in deep convolutional neural networks
(CNNs). The problem is interesting because the idea of forcing different parts
of the model to learn from different types of samples may help us acquire
better filters in CNNs, improve the model generalization performance and
potentially increase the interpretability of model behavior. We propose a novel
yet simple framework called GaterNet, which involves a backbone and a gater
network. The backbone network is a regular CNN that performs the major
computation needed for making a prediction, while a global gater network is
introduced to generate binary gates for selectively activating filters in the
backbone network based on each input. Extensive experiments on CIFAR and
ImageNet datasets show that our models consistently outperform the original
models with a large margin. On CIFAR-10, our model also improves upon
state-of-the-art results.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1&quot;&gt;Zhourong Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1&quot;&gt;Yang Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bengio_S/0/1/0/all/0/1&quot;&gt;Samy Bengio&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Si_S/0/1/0/all/0/1&quot;&gt;Si Si&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1811.11431">
<title>ESPNetv2: A Light-weight, Power Efficient, and General Purpose Convolutional Neural Network. (arXiv:1811.11431v3 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1811.11431</link>
<description rdf:parseType="Literal">&lt;p&gt;We introduce a light-weight, power efficient, and general purpose
convolutional neural network, ESPNetv2, for modeling visual and sequential
data. Our network uses group point-wise and depth-wise dilated separable
convolutions to learn representations from a large effective receptive field
with fewer FLOPs and parameters. The performance of our network is evaluated on
four different tasks: (1) object classification, (2) semantic segmentation, (3)
object detection, and (4) language modeling. Experiments on these tasks,
including image classification on the ImageNet and language modeling on the
PenTree bank dataset, demonstrate the superior performance of our method over
the state-of-the-art methods. Our network outperforms ESPNet by 4-5% and has
2-4x fewer FLOPs on the PASCAL VOC and the Cityscapes dataset. Compared to
YOLOv2 on the MS-COCO object detection, ESPNetv2 delivers 4.4% higher accuracy
with 6x fewer FLOPs. Our experiments show that ESPNetv2 is much more power
efficient than existing state-of-the-art efficient methods including
ShuffleNets and MobileNets. Our code is open-source and available at
https://github.com/sacmehta/ESPNetv2
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mehta_S/0/1/0/all/0/1&quot;&gt;Sachin Mehta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rastegari_M/0/1/0/all/0/1&quot;&gt;Mohammad Rastegari&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shapiro_L/0/1/0/all/0/1&quot;&gt;Linda Shapiro&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hajishirzi_H/0/1/0/all/0/1&quot;&gt;Hannaneh Hajishirzi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1811.12019">
<title>Large-Scale Distributed Second-Order Optimization Using Kronecker-Factored Approximate Curvature for Deep Convolutional Neural Networks. (arXiv:1811.12019v5 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1811.12019</link>
<description rdf:parseType="Literal">&lt;p&gt;Large-scale distributed training of deep neural networks suffer from the
generalization gap caused by the increase in the effective mini-batch size.
Previous approaches try to solve this problem by varying the learning rate and
batch size over epochs and layers, or some ad hoc modification of the batch
normalization. We propose an alternative approach using a second-order
optimization method that shows similar generalization capability to first-order
methods, but converges faster and can handle larger mini-batches. To test our
method on a benchmark where highly optimized first-order methods are available
as references, we train ResNet-50 on ImageNet. We converged to 75% Top-1
validation accuracy in 35 epochs for mini-batch sizes under 16,384, and
achieved 75% even with a mini-batch size of 131,072, which took only 978
iterations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Osawa_K/0/1/0/all/0/1&quot;&gt;Kazuki Osawa&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tsuji_Y/0/1/0/all/0/1&quot;&gt;Yohei Tsuji&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ueno_Y/0/1/0/all/0/1&quot;&gt;Yuichiro Ueno&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Naruse_A/0/1/0/all/0/1&quot;&gt;Akira Naruse&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yokota_R/0/1/0/all/0/1&quot;&gt;Rio Yokota&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Matsuoka_S/0/1/0/all/0/1&quot;&gt;Satoshi Matsuoka&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1811.12104">
<title>Towards Human-Friendly Referring Expression Generation. (arXiv:1811.12104v3 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1811.12104</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper addresses the generation of referring expressions that not only
refer to objects correctly but also let humans find them quickly. As a target
becomes relatively less salient, identifying referred objects itself becomes
more difficult. However, the existing studies regarded all sentences that refer
to objects correctly as equally good, ignoring whether they are easily
understood by humans. If the target is not salient, humans utilize
relationships with the salient contexts around it to help listeners to
comprehend it better. To derive this information from human annotations, our
model is designed to extract information from the inside and outside of the
target. Moreover, we regard that sentences that are easily understood are those
that are comprehended correctly and quickly by humans. We optimized this by
using the time required to locate the referred objects by humans and their
accuracies. To evaluate our system, we created a new referring expression
dataset whose images were acquired from Grand Theft Auto V (GTA V), limiting
targets to persons. Experimental results show the effectiveness of our
approach. Our code and dataset are available at
https://github.com/mikittt/Human-Friendly-REG.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tanaka_M/0/1/0/all/0/1&quot;&gt;Mikihiro Tanaka&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Itamochi_T/0/1/0/all/0/1&quot;&gt;Takayuki Itamochi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Narioka_K/0/1/0/all/0/1&quot;&gt;Kenichi Narioka&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sato_I/0/1/0/all/0/1&quot;&gt;Ikuro Sato&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ushiku_Y/0/1/0/all/0/1&quot;&gt;Yoshitaka Ushiku&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Harada_T/0/1/0/all/0/1&quot;&gt;Tatsuya Harada&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1812.00202">
<title>Traversing the Continuous Spectrum of Image Retrieval with Deep Dynamic Models. (arXiv:1812.00202v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1812.00202</link>
<description rdf:parseType="Literal">&lt;p&gt;We introduce the first work to tackle the image retrieval problem as a
continuous operation. While the proposed approaches in the literature can be
roughly categorized into two main groups: category- and instance-based
retrieval, in this work we show that the retrieval task is much richer and more
complex. Image similarity goes beyond this discrete vantage point and spans a
continuous spectrum among the classical operating points of category and
instance similarity. However, current retrieval models are static and incapable
of exploring this rich structure of the retrieval space since they are trained
and evaluated with a single operating point as a target objective. Hence, we
introduce a novel retrieval model that for a given query is capable of
producing a dynamic embedding that can target an arbitrary point along the
continuous retrieval spectrum. Our model disentangles the visual signal of a
query image into its basic components of categorical and attribute information.
Furthermore, using a continuous control parameter our model learns to
reconstruct a dynamic embedding of the query by mixing these components with
different proportions to target a specific point along the retrieval simplex.
We demonstrate our idea in a comprehensive evaluation of the proposed model and
highlight the advantages of our approach against a set of well-established
discrete retrieval models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Al_Halah_Z/0/1/0/all/0/1&quot;&gt;Ziad Al-Halah&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lehrmann_A/0/1/0/all/0/1&quot;&gt;Andreas M. Lehrmann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sigal_L/0/1/0/all/0/1&quot;&gt;Leonid Sigal&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1812.00408">
<title>A Dataset and Benchmark for Large-scale Multi-modal Face Anti-spoofing. (arXiv:1812.00408v3 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1812.00408</link>
<description rdf:parseType="Literal">&lt;p&gt;Face anti-spoofing is essential to prevent face recognition systems from a
security breach. Much of the progresses have been made by the availability of
face anti-spoofing benchmark datasets in recent years. However, existing face
anti-spoofing benchmarks have limited number of subjects ($\le\negmedspace170$)
and modalities ($\leq\negmedspace2$), which hinder the further development of
the academic community. To facilitate face anti-spoofing research, we introduce
a large-scale multi-modal dataset, namely CASIA-SURF, which is the largest
publicly available dataset for face anti-spoofing in terms of both subjects and
visual modalities. Specifically, it consists of $1,000$ subjects with $21,000$
videos and each sample has $3$ modalities (i.e., RGB, Depth and IR). We also
provide a measurement set, evaluation protocol and training/validation/testing
subsets, developing a new benchmark for face anti-spoofing. Moreover, we
present a new multi-modal fusion method as baseline, which performs feature
re-weighting to select the more informative channel features while suppressing
the less useful ones for each modal. Extensive experiments have been conducted
on the proposed dataset to verify its significance and generalization
capability. The dataset is available at
https://sites.google.com/qq.com/chalearnfacespoofingattackdete
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1&quot;&gt;Shifeng Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1&quot;&gt;Xiaobo Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_A/0/1/0/all/0/1&quot;&gt;Ajian Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_C/0/1/0/all/0/1&quot;&gt;Chenxu Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wan_J/0/1/0/all/0/1&quot;&gt;Jun Wan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Escalera_S/0/1/0/all/0/1&quot;&gt;Sergio Escalera&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shi_H/0/1/0/all/0/1&quot;&gt;Hailin Shi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1&quot;&gt;Zezheng Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1&quot;&gt;Stan Z. Li&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1812.01243">
<title>Decomposed Attention: Self-Attention with Linear Complexities. (arXiv:1812.01243v4 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1812.01243</link>
<description rdf:parseType="Literal">&lt;p&gt;Recent works have been applying self-attention to various fields in computer
vision and natural language processing. However, the memory and computational
demands of existing self-attention operations grow quadratically with the
spatiotemporal size of the input. This prohibits the application of
self-attention on large inputs, e.g., long sequences, high-definition images,
or large videos. To remedy this drawback, this paper proposes a novel
decomposed attention (DA) module with substantially less memory and
computational consumption. The resource-efficiency allows more widespread and
flexible application. Empirical evaluations on object recognition demonstrated
the effectiveness of these advantages. DA-augmented models achieved
state-of-the-art performance for object recognition on MS-COCO 2017 and
significant improvement for image classification on ImageNet. Further, the
resource-efficiency of DA democratizes self-attention to fields where the
prohibitively high costs have been preventing its application. The
state-of-the-art result for stereo depth estimation on the Scene Flow dataset
exemplified this.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shen_Z/0/1/0/all/0/1&quot;&gt;Zhuoran Shen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1&quot;&gt;Mingyuan Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yi_S/0/1/0/all/0/1&quot;&gt;Shuai Yi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yan_J/0/1/0/all/0/1&quot;&gt;Junjie Yan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_H/0/1/0/all/0/1&quot;&gt;Haiyu Zhao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1812.01659">
<title>Learning to Sample. (arXiv:1812.01659v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1812.01659</link>
<description rdf:parseType="Literal">&lt;p&gt;Processing large point clouds is a challenging task. Therefore, the data is
often sampled to a size that can be processed more easily. The question is how
to sample the data? A popular sampling technique is Farthest Point Sampling
(FPS). However, FPS is agnostic to a downstream application (classification,
retrieval, etc.). The underlying assumption seems to be that minimizing the
farthest point distance, as done by FPS, is a good proxy to other objective
functions.
&lt;/p&gt;
&lt;p&gt;We show that it is better to learn how to sample. To do that, we propose a
deep network to simplify 3D point clouds. The network, termed S-NET, takes a
point cloud and produces a smaller point cloud that is optimized for a
particular task. The simplified point cloud is not guaranteed to be a subset of
the original point cloud. Therefore, we match it to a subset of the original
points in a post-processing step. We contrast our approach with FPS by
experimenting on two standard data sets and show significantly better results
for a variety of applications. Our code is publicly available at:
https://github.com/orendv/learning_to_sample
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dovrat_O/0/1/0/all/0/1&quot;&gt;Oren Dovrat&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lang_I/0/1/0/all/0/1&quot;&gt;Itai Lang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Avidan_S/0/1/0/all/0/1&quot;&gt;Shai Avidan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1812.01687">
<title>PointCloud Saliency Maps. (arXiv:1812.01687v4 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1812.01687</link>
<description rdf:parseType="Literal">&lt;p&gt;3D point-cloud recognition with PointNet and its variants has received
remarkable progress. A missing ingredient, however, is the ability to
automatically evaluate point-wise importance w.r.t.\! classification
performance, which is usually reflected by a saliency map. A saliency map is an
important tool as it allows one to perform further processes on point-cloud
data. In this paper, we propose a novel way of characterizing critical points
and segments to build point-cloud saliency maps. Our method assigns each point
a score reflecting its contribution to the model-recognition loss. The saliency
map explicitly explains which points are the key for model recognition.
Furthermore, aggregations of highly-scored points indicate important
segments/subsets in a point-cloud. Our motivation for constructing a saliency
map is by point dropping, which is a non-differentiable operator. To overcome
this issue, we approximate point-dropping with a differentiable procedure of
shifting points towards the cloud centroid. Consequently, each saliency score
can be efficiently measured by the corresponding gradient of the loss w.r.t the
point under the spherical coordinates. Extensive evaluations on several
state-of-the-art point-cloud recognition models, including PointNet, PointNet++
and DGCNN, demonstrate the veracity and generality of our proposed saliency
map. Code for experiments is released on
\url{https://github.com/tianzheng4/PointCloud-Saliency-Maps}.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zheng_T/0/1/0/all/0/1&quot;&gt;Tianhang Zheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1&quot;&gt;Changyou Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yuan_J/0/1/0/all/0/1&quot;&gt;Junsong Yuan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1&quot;&gt;Bo Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ren_K/0/1/0/all/0/1&quot;&gt;Kui Ren&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1812.02532">
<title>On the stability analysis of deep neural network representations of an optimal state-feedback. (arXiv:1812.02532v3 [cs.NE] UPDATED)</title>
<link>http://arxiv.org/abs/1812.02532</link>
<description rdf:parseType="Literal">&lt;p&gt;Recent work have shown how the optimal state-feedback, obtained as the
solution to the Hamilton-Jacobi-Bellman equations, can be approximated for
several nonlinear, deterministic systems by deep neural networks. When
imitation (supervised) learning is used to train the neural network on optimal
state-action pairs, for instance as derived by applying Pontryagin&apos;s theory of
optimal processes, the resulting model is referred here as the guidance and
control network. In this work, we analyze the stability of nonlinear and
deterministic systems controlled by such networks. We then propose a method
utilising differential algebraic techniques and high-order Taylor maps to gain
information on the stability of the neurocontrolled state trajectories. We
exemplify the proposed methods in the case of the two-dimensional dynamics of a
quadcopter controlled to reach the origin and we study how different
architectures of the guidance and control network affect the stability of the
target equilibrium point and the stability margins to time delay. Moreover, we
show how to study the robustness to initial conditions of a nominal trajectory,
using a Taylor representation of the neurocontrolled neighbouring trajectories.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Izzo_D/0/1/0/all/0/1&quot;&gt;Dario Izzo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tailor_D/0/1/0/all/0/1&quot;&gt;Dharmesh Tailor&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vasileiou_T/0/1/0/all/0/1&quot;&gt;Thomas Vasileiou&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1812.03050">
<title>Graph Cut Segmentation Methods Revisited with a Quantum Algorithm. (arXiv:1812.03050v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1812.03050</link>
<description rdf:parseType="Literal">&lt;p&gt;The design and performance of computer vision algorithms are greatly
influenced by the hardware on which they are implemented. CPUs, multi-core
CPUs, FPGAs and GPUs have inspired new algorithms and enabled existing ideas to
be realized. This is notably the case with GPUs, which has significantly
changed the landscape of computer vision research through deep learning. As the
end of Moores law approaches, researchers and hardware manufacturers are
exploring alternative hardware computing paradigms. Quantum computers are a
very promising alternative and offer polynomial or even exponential speed-ups
over conventional computing for some problems. This paper presents a novel
approach to image segmentation that uses new quantum computing hardware.
Segmentation is formulated as a graph cut problem that can be mapped to the
quantum approximate optimization algorithm (QAOA). This algorithm can be
implemented on current and near-term quantum computers. Encouraging results are
presented on artificial and medical imaging data. This represents an important,
practical step towards leveraging quantum computers for computer vision.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tse_L/0/1/0/all/0/1&quot;&gt;Lisa Tse&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mountney_P/0/1/0/all/0/1&quot;&gt;Peter Mountney&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Klein_P/0/1/0/all/0/1&quot;&gt;Paul Klein&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Severini_S/0/1/0/all/0/1&quot;&gt;Simone Severini&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1812.04081">
<title>Chat-crowd: A Dialog-based Platform for Visual Layout Composition. (arXiv:1812.04081v3 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/1812.04081</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper we introduce Chat-crowd, an interactive environment for visual
layout composition via conversational interactions. Chat-crowd supports
multiple agents with two conversational roles: agents who play the role of a
designer are in charge of placing objects in an editable canvas according to
instructions or commands issued by agents with a director role. The system can
be integrated with crowdsourcing platforms for both synchronous and
asynchronous data collection and is equipped with comprehensive quality
controls on the performance of both types of agents. We expect that this system
will be useful to build multimodal goal-oriented dialog tasks that require
spatial and geometric reasoning.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cascante_Bonilla_P/0/1/0/all/0/1&quot;&gt;Paola Cascante-Bonilla&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yin_X/0/1/0/all/0/1&quot;&gt;Xuwang Yin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ordonez_V/0/1/0/all/0/1&quot;&gt;Vicente Ordonez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Feng_S/0/1/0/all/0/1&quot;&gt;Song Feng&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1812.04368">
<title>Exploiting Kernel Sparsity and Entropy for Interpretable CNN Compression. (arXiv:1812.04368v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1812.04368</link>
<description rdf:parseType="Literal">&lt;p&gt;Compressing convolutional neural networks (CNNs) has received ever-increasing
research focus. However, most existing CNN compression methods do not interpret
their inherent structures to distinguish the implicit redundancy. In this
paper, we investigate the problem of CNN compression from a novel interpretable
perspective. The relationship between the input feature maps and 2D kernels is
revealed in a theoretical framework, based on which a kernel sparsity and
entropy (KSE) indicator is proposed to quantitate the feature map importance in
a feature-agnostic manner to guide model compression. Kernel clustering is
further conducted based on the KSE indicator to accomplish high-precision CNN
compression. KSE is capable of simultaneously compressing each layer in an
efficient way, which is significantly faster compared to previous data-driven
feature map pruning methods. We comprehensively evaluate the compression and
speedup of the proposed method on CIFAR-10, SVHN and ImageNet 2012. Our method
demonstrates superior performance gains over previous ones. In particular, it
achieves 4.7 \times FLOPs reduction and 2.9 \times compression on ResNet-50
with only a Top-5 accuracy drop of 0.35% on ImageNet 2012, which significantly
outperforms state-of-the-art methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1&quot;&gt;Yuchao Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_S/0/1/0/all/0/1&quot;&gt;Shaohui Lin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1&quot;&gt;Baochang Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1&quot;&gt;Jianzhuang Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Doermann_D/0/1/0/all/0/1&quot;&gt;David Doermann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1&quot;&gt;Yongjian Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_F/0/1/0/all/0/1&quot;&gt;Feiyue Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ji_R/0/1/0/all/0/1&quot;&gt;Rongrong Ji&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1812.04478">
<title>Socratrees: Make Discussions Great Again. (arXiv:1812.04478v2 [cs.HC] UPDATED)</title>
<link>http://arxiv.org/abs/1812.04478</link>
<description rdf:parseType="Literal">&lt;p&gt;Terms like &apos;misinformation&apos;, &apos;fake news&apos;, and &apos;echo chambers&apos; permeate
current discussions on the state of the Internet. We believe a lack of
technological support to evaluate, contest, and reason about information
online---as opposed to merely disseminating it---lies at the root of these
problems. Several argument technologies support such functionality, but have
seen limited use outside of niche communities. Most research systems
overemphasize argument analysis, standing in stark contrast with the informal
dialectical nature of everyday argumentation. Conversely, non-academic systems
overlook important implications for design which can be derived from theory. In
this paper, we present the design of a system aiming to strike a balance
between the two. Informatron is a website for collaborative argumentative
discussion targeting layman users, but includes sophisticated community
guidelines and novel features inspired by informal logic; we argue these are
key to scaling up argumentation. Based on a six-week-long evaluation and
subsequent survey sent out to all active users, we conclude that while
contributing to arguments remains a complex task, most users learned to do so
effectively with minimal guidance and all recognized that structure improves
online discussion and results in a clearer overview of arguments.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jeuris_S/0/1/0/all/0/1&quot;&gt;Steven Jeuris&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1812.05866">
<title>Evolutionary Neural Architecture Search for Image Restoration. (arXiv:1812.05866v2 [cs.NE] UPDATED)</title>
<link>http://arxiv.org/abs/1812.05866</link>
<description rdf:parseType="Literal">&lt;p&gt;Convolutional neural network (CNN) architectures have traditionally been
explored by human experts in a manual search process that is time-consuming and
ineffectively explores the massive space of potential solutions. Neural
architecture search (NAS) methods automatically search the space of neural
network hyperparameters in order to find optimal task-specific architectures.
NAS methods have discovered CNN architectures that achieve state-of-the-art
performance in image classification among other tasks, however the application
of NAS to image-to-image regression problems such as image restoration is
sparse. This paper proposes a NAS method that performs computationally
efficient evolutionary search of a minimally constrained network architecture
search space. The performance of architectures discovered by the proposed
method is evaluated on a variety of image restoration tasks applied to the
ImageNet64x64 dataset, and compared with human-engineered CNN architectures.
The best neural architectures discovered using only 2 GPU-hours of evolutionary
search exhibit comparable performance to the human-engineered baseline
architecture.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wyk_G/0/1/0/all/0/1&quot;&gt;Gerard Jacques van Wyk&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bosman_A/0/1/0/all/0/1&quot;&gt;Anna Sergeevna Bosman&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1812.07045">
<title>EventNet: Asynchronous Recursive Event Processing. (arXiv:1812.07045v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1812.07045</link>
<description rdf:parseType="Literal">&lt;p&gt;Event cameras are bio-inspired vision sensors that mimic retinas to
asynchronously report per-pixel intensity changes rather than outputting an
actual intensity image at regular intervals. This new paradigm of image sensor
offers significant potential advantages; namely, sparse and non-redundant data
representation. Unfortunately, however, most of the existing artificial neural
network architectures, such as a CNN, require dense synchronous input data, and
therefore, cannot make use of the sparseness of the data. We propose EventNet,
a neural network designed for real-time processing of asynchronous event
streams in a recursive and event-wise manner. EventNet models dependence of the
output on tens of thousands of causal events recursively using a novel temporal
coding scheme. As a result, at inference time, our network operates in an
event-wise manner that is realized with very few sum-of-the-product
operations---look-up table and temporal feature aggregation---which enables
processing of 1 mega or more events per second on standard CPU. In experiments
using real data, we demonstrated the real-time performance and robustness of
our framework.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sekikawa_Y/0/1/0/all/0/1&quot;&gt;Yusuke Sekikawa&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hara_K/0/1/0/all/0/1&quot;&gt;Kosuke Hara&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Saito_H/0/1/0/all/0/1&quot;&gt;Hideo Saito&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1812.09526">
<title>On Functional Aggregate Queries with Additive Inequalities. (arXiv:1812.09526v2 [cs.DB] UPDATED)</title>
<link>http://arxiv.org/abs/1812.09526</link>
<description rdf:parseType="Literal">&lt;p&gt;Motivated by fundamental applications in databases and relational machine
learning, we formulate and study the problem of answering functional aggregate
queries (FAQ) in which some of the input factors are defined by a collection of
additive inequalities between variables. We refer to these queries as FAQ-AI
for short.
&lt;/p&gt;
&lt;p&gt;To answer FAQ-AI in the Boolean semiring, we define relaxed tree
decompositions and relaxed submodular and fractional hypertree width
parameters. We show that an extension of the InsideOut algorithm using
Chazelle&apos;s geometric data structure for solving the semigroup range search
problem can answer Boolean FAQ-AI in time given by these new width parameters.
This new algorithm achieves lower complexity than known solutions for FAQ-AI.
It also recovers some known results in database query answering.
&lt;/p&gt;
&lt;p&gt;Our second contribution is a relaxation of the set of polymatroids that gives
rise to the counting version of the submodular width, denoted by #subw. This
new width is sandwiched between the submodular and the fractional hypertree
widths. Any FAQ and FAQ-AI over one semiring can be answered in time
proportional to #subw and respectively to the relaxed version of #subw.
&lt;/p&gt;
&lt;p&gt;We present three applications of our FAQ-AI framework to relational machine
learning: k-means clustering, training linear support vector machines, and
training models using non-polynomial loss. These optimization problems can be
solved over a database asymptotically faster than computing the join of the
database relations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khamis_M/0/1/0/all/0/1&quot;&gt;Mahmoud Abo Khamis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Curtin_R/0/1/0/all/0/1&quot;&gt;Ryan R. Curtin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Moseley_B/0/1/0/all/0/1&quot;&gt;Benjamin Moseley&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ngo_H/0/1/0/all/0/1&quot;&gt;Hung Q. Ngo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nguyen_X/0/1/0/all/0/1&quot;&gt;XuanLong Nguyen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Olteanu_D/0/1/0/all/0/1&quot;&gt;Dan Olteanu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schleich_M/0/1/0/all/0/1&quot;&gt;Maximilian Schleich&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1812.09658">
<title>Learning finite-dimensional coding schemes with nonlinear reconstruction maps. (arXiv:1812.09658v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1812.09658</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper generalizes the Maurer--Pontil framework of finite-dimensional
lossy coding schemes to the setting where a high-dimensional random vector is
mapped to an element of a compact set of latent representations in a
lower-dimensional Euclidean space, and the reconstruction map belongs to a
given class of nonlinear maps. Under this setup, which encompasses a broad
class of unsupervised representation learning problems, we establish a
connection to approximate generative modeling under structural constraints
using the tools from the theory of optimal transportation. Next, we consider
problem of learning a coding scheme on the basis of a finite collection of
training samples and present generalization bounds that hold with high
probability. We then illustrate the general theory in the setting where the
reconstruction maps are implemented by deep neural nets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Lee_J/0/1/0/all/0/1&quot;&gt;Jaeho Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Raginsky_M/0/1/0/all/0/1&quot;&gt;Maxim Raginsky&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1812.10956">
<title>Salient Object Detection via High-to-Low Hierarchical Context Aggregation. (arXiv:1812.10956v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1812.10956</link>
<description rdf:parseType="Literal">&lt;p&gt;Recent progress on salient object detection mainly aims at exploiting how to
effectively integrate convolutional side-output features in convolutional
neural networks (CNN). Based on this, most of the existing state-of-the-art
saliency detectors design complex network structures to fuse the side-output
features of the backbone feature extraction networks. However, should the
fusion strategies be more and more complex for accurate salient object
detection? In this paper, we observe that the contexts of a natural image can
be well expressed by a high-to-low self-learning of side-output convolutional
features. As we know, the contexts of an image usually refer to the global
structures, and the top layers of CNN usually learn to convey global
information. On the other hand, it is difficult for the intermediate
side-output features to express contextual information. Here, we design an
hourglass network with intermediate supervision to learn contextual features in
a high-to-low manner. The learned hierarchical contexts are aggregated to
generate the hybrid contextual expression for an input image. At last, the
hybrid contextual features can be used for accurate saliency estimation. We
extensively evaluate our method on six challenging saliency datasets, and our
simple method achieves state-of-the-art performance under various evaluation
metrics. Code will be released upon paper acceptance.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1&quot;&gt;Yun Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qiu_Y/0/1/0/all/0/1&quot;&gt;Yu Qiu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1&quot;&gt;Le Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bian_J/0/1/0/all/0/1&quot;&gt;JiaWang Bian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nie_G/0/1/0/all/0/1&quot;&gt;Guang-Yu Nie&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cheng_M/0/1/0/all/0/1&quot;&gt;Ming-Ming Cheng&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1901.01062">
<title>Detecting and Diagnosing Energy Issues for Mobile Applications. (arXiv:1901.01062v2 [cs.SE] UPDATED)</title>
<link>http://arxiv.org/abs/1901.01062</link>
<description rdf:parseType="Literal">&lt;p&gt;Energy efficiency is an important criterion to judge the quality of mobile
apps, but one third of our randomly sampled apps suffer from energy issues that
can quickly drain battery power. To understand these issues, we conducted an
empirical study on 27 well-maintained apps such as Chrome and Firefox, whose
issue tracking systems are publicly accessible. Our study revealed that the
main root causes of energy issues include unnecessary workload and excessively
frequent operations. Surprisingly, these issues are beyond the application of
present technology on energy issue detection. We also found that 20.6% of
energy issues can only manifest themselves under specific contexts such as poor
network performance, but such contexts are again neglected by present
technology. Therefore, we proposed a novel testing framework for detecting
energy issues in real-world apps. Our framework examines apps with
well-designed input sequences and runtime contexts. To identify the root causes
mentioned above, we employed a machine learning algorithm to cluster the
workloads and further evaluate their necessity. For the issues concealed by the
specific contexts, we carefully set up several execution contexts to pinpoint
them. More importantly, we developed leading edge technology, e.g.
pre-designing input sequences with potential energy overuse and tuning tests
on-the-fly, to achieve high efficacy in detecting energy issues. A large-scale
evaluation shows that 91.6% issues detected in our test were previously unknown
to developers. On average, these issues double the energy costs of the apps.
Furthermore, our test achieves a low number of false positives. Finally, we
show how our test reports can help developers fix the issues.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1&quot;&gt;Xueliang Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1&quot;&gt;Yuming Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+liu_Y/0/1/0/all/0/1&quot;&gt;Yepang liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gallagher_J/0/1/0/all/0/1&quot;&gt;John P. Gallagher&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_K/0/1/0/all/0/1&quot;&gt;Kaishun Wu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1901.01751">
<title>Generative Adversarial Networks for Financial Trading Strategies Fine-Tuning and Combination. (arXiv:1901.01751v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1901.01751</link>
<description rdf:parseType="Literal">&lt;p&gt;Systematic trading strategies are algorithmic procedures that allocate assets
aiming to optimize a certain performance criterion. To obtain an edge in a
highly competitive environment, the analyst needs to proper fine-tune its
strategy, or discover how to combine weak signals in novel alpha creating
manners. Both aspects, namely fine-tuning and combination, have been
extensively researched using several methods, but emerging techniques such as
Generative Adversarial Networks can have an impact into such aspects.
Therefore, our work proposes the use of Conditional Generative Adversarial
Networks (cGANs) for trading strategies calibration and aggregation. To this
purpose, we provide a full methodology on: (i) the training and selection of a
cGAN for time series data; (ii) how each sample is used for strategies
calibration; and (iii) how all generated samples can be used for ensemble
modelling. To provide evidence that our approach is well grounded, we have
designed an experiment with multiple trading strategies, encompassing 579
assets. We compared cGAN with an ensemble scheme and model validation methods,
both suited for time series. Our results suggest that cGANs are a suitable
alternative for strategies calibration and combination, providing
outperformance when the traditional techniques fail to generate any alpha.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Koshiyama_A/0/1/0/all/0/1&quot;&gt;Adriano Koshiyama&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Firoozye_N/0/1/0/all/0/1&quot;&gt;Nick Firoozye&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Treleaven_P/0/1/0/all/0/1&quot;&gt;Philip Treleaven&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1901.01874">
<title>Mutual Context Network for Jointly Estimating Egocentric Gaze and Actions. (arXiv:1901.01874v3 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1901.01874</link>
<description rdf:parseType="Literal">&lt;p&gt;In this work, we address two coupled tasks of gaze prediction and action
recognition in egocentric videos by exploring their mutual context. Our
assumption is that in the procedure of performing a manipulation task, what a
person is doing determines where the person is looking at, and the gaze point
reveals gaze and non-gaze regions which contain important and complementary
information about the undergoing action. We propose a novel mutual context
network (MCN) that jointly learns action-dependent gaze prediction and
gaze-guided action recognition in an end-to-end manner. Experiments on public
egocentric video datasets demonstrate that our MCN achieves state-of-the-art
performance of both gaze prediction and action recognition.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1&quot;&gt;Yifei Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1&quot;&gt;Zhenqiang Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cai_M/0/1/0/all/0/1&quot;&gt;Minjie Cai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sato_Y/0/1/0/all/0/1&quot;&gt;Yoichi Sato&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1901.02182">
<title>Comments on &quot;Deep Neural Networks with Random Gaussian Weights: A Universal Classification Strategy?&quot;. (arXiv:1901.02182v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1901.02182</link>
<description rdf:parseType="Literal">&lt;p&gt;In a recently published paper [1], it is shown that deep neural networks
(DNNs) with random Gaussian weights preserve the metric structure of the data,
with the property that the distance shrinks more when the angle between the two
data points is smaller. We agree that the random projection setup considered in
[1] preserves distances with a high probability. But as far as we are
concerned, the relation between the angle of the data points and the output
distances is quite the opposite, i.e., smaller angles result in a weaker
distance shrinkage. This leads us to conclude that Theorem 3 and Figure 5 in
[1] are not accurate. Hence the usage of random Gaussian weights in DNNs cannot
provide an ability of universal classification or treating in-class and
out-of-class data separately. Consequently, the behavior of networks consisting
of random Gaussian weights only is not useful to explain how DNNs achieve
state-of-art results in a large variety of problems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Gulcu_T/0/1/0/all/0/1&quot;&gt;Talha Cihad Gulcu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Gungor_A/0/1/0/all/0/1&quot;&gt;Alper Gungor&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1901.02808">
<title>Bounding the minimal number of generators of groups of cellular automata. (arXiv:1901.02808v3 [math.GR] UPDATED)</title>
<link>http://arxiv.org/abs/1901.02808</link>
<description rdf:parseType="Literal">&lt;p&gt;For a group $G$ and a finite set $A$, denote by $\text{CA}(G;A)$ the monoid
of all cellular automata over $A^G$ and by $\text{ICA}(G;A)$ its group of
units. We study the minimal cardinality of a generating set, known as the rank,
of $\text{ICA}(G;A)$. In the first part, when $G$ is a finite group, we give
upper bounds for the rank in terms of the number of conjugacy classes of
subgroups of $G$. The case when $G$ is a finite cyclic group has been studied
before, so here we focus on the cases when $G$ is a finite dihedral group or a
finite Dedekind group. In the second part, we find a basic lower bound for the
rank of $\text{ICA}(G;A)$ when $G$ is a finite group, and we apply this to show
that, for any infinite abelian group $H$, the monoid $\text{CA}(H;A)$ is not
finitely generated. The same is true for various kinds of infinite groups, so
we ask if there exists an infinite group $H$ such that $\text{CA}(H;A)$ is
finitely generated.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Castillo_Ramirez_A/0/1/0/all/0/1&quot;&gt;Alonso Castillo-Ramirez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Sanchez_Alvarez_M/0/1/0/all/0/1&quot;&gt;Miguel Sanchez-Alvarez&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1901.03146">
<title>Cosine-similarity penalty to discriminate sound classes in weakly-supervised sound event detection. (arXiv:1901.03146v3 [cs.SD] UPDATED)</title>
<link>http://arxiv.org/abs/1901.03146</link>
<description rdf:parseType="Literal">&lt;p&gt;The design of new methods and models when only weakly-labeled data are
available is of paramount importance in order to reduce the costs of manual
annotation and the considerable human effort associated with it. In this work,
we address Sound Event Detection in the case where a weakly annotated dataset
is available for training. The weak annotations provide tags of audio events
but do not provide temporal boundaries. The objective is twofold: 1) audio
tagging, i.e. multi-label classification at recording level, 2) sound event
detection, i.e. localization of the event boundaries within the recordings.
This work focuses mainly on the second objective. We explore an approach
inspired by Multiple Instance Learning, in which we train a convolutional
recurrent neural network to give predictions at frame-level, using a custom
loss function based on the weak labels and the statistics of the frame-based
predictions. Since some sound classes cannot be distinguished with this
approach, we improve the method by penalizing similarity between the
predictions of the positive classes during training. On the test set used in
the DCASE 2018 challenge, consisting of 288 recordings and 10 sound classes,
the addition of a penalty resulted in a localization F-score of 34.75%, and
brought 10% relative improvement compared to not using the penalty. Our best
model achieved a 26.20% F-score on the DCASE-2018 official Eval subset close to
the 10-system ensemble approach that ranked second in the challenge with a
29.9% F-score.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pellegrini_T/0/1/0/all/0/1&quot;&gt;Thomas Pellegrini&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cances_L/0/1/0/all/0/1&quot;&gt;L&amp;#xe9;o Cances&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1901.04106">
<title>3D Trajectory Optimization in Rician Fading for UAV-Enabled Data Harvesting. (arXiv:1901.04106v3 [cs.IT] UPDATED)</title>
<link>http://arxiv.org/abs/1901.04106</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we consider a UAV-enabled WSN where a flying UAV is employed
to collect data from multiple sensor nodes (SNs). Our objective is to maximize
the minimum average data collection rate from all SNs subject to a prescribed
reliability constraint for each SN by jointly optimizing the UAV communication
scheduling and three-dimensional (3D) trajectory. Different from the existing
works that assume the simplified line-of-sight (LoS) UAV-ground channels, we
consider the more practically accurate angle-dependent Rician fading channels
between the UAV and SNs with the Rician factors determined by the corresponding
UAV-SN elevation angles. However, the formulated optimization problem is
intractable due to the lack of a closed-form expression for a key parameter
termed effective fading power that characterizes the achievable rate given the
reliability requirement in terms of outage probability. To tackle this
difficulty, we first approximate the parameter by a logistic (&apos;S&apos; shape)
function with respect to the 3D UAV trajectory by using the data regression
method. Then the original problem is reformulated to an approximate form,
which, however, is still challenging to solve due to its non-convexity. As
such, we further propose an efficient algorithm to derive its suboptimal
solution by using the block coordinate descent technique, which iteratively
optimizes the communication scheduling, the UAV&apos;s horizontal trajectory, and
its vertical trajectory. The latter two subproblems are shown to be non-convex,
while locally optimal solutions are obtained for them by using the successive
convex approximation technique. Last, extensive numerical results are provided
to evaluate the performance of the proposed algorithm and draw new insights on
the 3D UAV trajectory under the Rician fading as compared to conventional LoS
channel models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+You_C/0/1/0/all/0/1&quot;&gt;Changsheng You&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1&quot;&gt;Rui Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1901.04452">
<title>FoundationDB Record Layer: A Multi-Tenant Structured Datastore. (arXiv:1901.04452v2 [cs.DB] UPDATED)</title>
<link>http://arxiv.org/abs/1901.04452</link>
<description rdf:parseType="Literal">&lt;p&gt;The FoundationDB Record Layer is an open source library that provides a
record-oriented data store with semantics similar to a relational database
implemented on top of FoundationDB, an ordered, transactional key-value store.
The Record Layer provides a lightweight, highly extensible way to store
structured data. It offers schema management and a rich set of query and
indexing facilities, some of which are not usually found in traditional
relational databases, such as nested record types, indexes on commit versions,
and indexes that span multiple record types. The Record Layer is stateless and
built for massive multi-tenancy, encapsulating and isolating all of a tenant&apos;s
state, including indexes, into a separate logical database. We demonstrate how
the Record Layer is used by CloudKit, Apple&apos;s cloud backend service, to provide
powerful abstractions to applications serving hundreds of millions of users.
CloudKit uses the Record Layer to host billions of independent databases, many
with a common schema. Features provided by the Record Layer enable CloudKit to
provide richer APIs and stronger semantics with reduced maintenance overhead
and improved scalability.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chrysafis_C/0/1/0/all/0/1&quot;&gt;Christos Chrysafis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Collins_B/0/1/0/all/0/1&quot;&gt;Ben Collins&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dugas_S/0/1/0/all/0/1&quot;&gt;Scott Dugas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dunkelberger_J/0/1/0/all/0/1&quot;&gt;Jay Dunkelberger&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ehsan_M/0/1/0/all/0/1&quot;&gt;Moussa Ehsan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gray_S/0/1/0/all/0/1&quot;&gt;Scott Gray&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Grieser_A/0/1/0/all/0/1&quot;&gt;Alec Grieser&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Herrnstadt_O/0/1/0/all/0/1&quot;&gt;Ori Herrnstadt&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lev_Ari_K/0/1/0/all/0/1&quot;&gt;Kfir Lev-Ari&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_T/0/1/0/all/0/1&quot;&gt;Tao Lin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+McMahon_M/0/1/0/all/0/1&quot;&gt;Mike McMahon&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schiefer_N/0/1/0/all/0/1&quot;&gt;Nicholas Schiefer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shraer_A/0/1/0/all/0/1&quot;&gt;Alexander Shraer&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1901.04846">
<title>Soil Texture Classification with 1D Convolutional Neural Networks based on Hyperspectral Data. (arXiv:1901.04846v3 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1901.04846</link>
<description rdf:parseType="Literal">&lt;p&gt;Soil texture is important for many environmental processes. In this paper, we
study the classification of soil texture based on hyperspectral data. We
develop and implement three 1-dimensional (1D) convolutional neural networks
(CNN): the LucasCNN, the LucasResNet which contains an identity block as
residual network, and the LucasCoordConv with an additional coordinates layer.
Furthermore, we modify two existing 1D CNN approaches for the presented
classification task. The code of all five CNN approaches is available on GitHub
(Riese, 2019). We evaluate the performance of the CNN approaches and compare
them to a random forest classifier. Thereby, we rely on the freely available
LUCAS topsoil dataset. The CNN approach with the least depth turns out to be
the best performing classifier. The LucasCoordConv achieves the best
performance regarding the average accuracy. In future work, we can further
enhance the introduced LucasCNN, LucasResNet and LucasCoordConv and include
additional variables of the rich LUCAS dataset.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Riese_F/0/1/0/all/0/1&quot;&gt;Felix M. Riese&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Keller_S/0/1/0/all/0/1&quot;&gt;Sina Keller&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1901.06587">
<title>Fitting ReLUs via SGD and Quantized SGD. (arXiv:1901.06587v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1901.06587</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper we focus on the problem of finding the optimal weights of the
shallowest of neural networks consisting of a single Rectified Linear Unit
(ReLU). These functions are of the form $\mathbf{x}\rightarrow
\max(0,\langle\mathbf{w},\mathbf{x}\rangle)$ with $\mathbf{w}\in\mathbb{R}^d$
denoting the weight vector. We focus on a planted model where the inputs are
chosen i.i.d. from a Gaussian distribution and the labels are generated
according to a planted weight vector. We first show that mini-batch stochastic
gradient descent when suitably initialized, converges at a geometric rate to
the planted model with a number of samples that is optimal up to numerical
constants. Next we focus on a parallel implementation where in each iteration
the mini-batch gradient is calculated in a distributed manner across multiple
processors and then broadcast to a master or all other processors. To reduce
the communication cost in this setting we utilize a Quanitzed Stochastic
Gradient Scheme (QSGD) where the partial gradients are quantized. Perhaps
unexpectedly, we show that QSGD maintains the fast convergence of SGD to a
globally optimal model while significantly reducing the communication cost. We
further corroborate our numerical findings via various experiments including
distributed implementations over Amazon EC2.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kalan_S/0/1/0/all/0/1&quot;&gt;Seyed Mohammadreza Mousavi Kalan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Soltanolkotabi_M/0/1/0/all/0/1&quot;&gt;Mahdi Soltanolkotabi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Avestimehr_A/0/1/0/all/0/1&quot;&gt;A. Salman Avestimehr&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1901.07226">
<title>Coexistence of Age and Throughput Optimizing Networks: A Game Theoretic Approach. (arXiv:1901.07226v3 [cs.GT] UPDATED)</title>
<link>http://arxiv.org/abs/1901.07226</link>
<description rdf:parseType="Literal">&lt;p&gt;Real-time monitoring applications have Internet-of-Things (IoT) devices sense
and communicate information (status updates) to a monitoring facility. Such
applications desire the status updates available at the monitor to be fresh and
would like to minimize the age of delivered updates. Networks of such devices
may share wireless spectrum with WiFi networks. Often, they use a CSMA/CA based
medium access similar to WiFi. However, unlike them, a WiFi network would like
to provide high throughputs for its users. We model the coexistence of such
networks as a repeated game with two players, an age optimizing network (AON)
and a throughput optimizing network (TON), where an AON aims to minimize the
age of updates and a TON seeks to maximize throughput. We define the stage
game, parameterized by the average age of the AON at the beginning of the
stage, and derive its mixed strategy Nash equilibrium (MSNE). We study the
evolution of the equilibrium strategies over time, when players play the MSNE
in each stage, and the resulting average discounted payoffs of the networks. It
turns out that it is more favorable for a TON to share spectrum with an AON in
comparison to sharing with another TON. The key to this lies in the MSNE
strategy of the AON that occasionally refrains all its nodes from transmitting
during a stage. Such stages allow the TON competition free access to the
medium.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gopal_S/0/1/0/all/0/1&quot;&gt;Sneihil Gopal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kaul_S/0/1/0/all/0/1&quot;&gt;Sanjit K. Kaul&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chaturvedi_R/0/1/0/all/0/1&quot;&gt;Rakesh Chaturvedi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1901.07675">
<title>A New CGAN Technique for Constrained Topology Design Optimization. (arXiv:1901.07675v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1901.07675</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper presents a new conditional GAN (named convex relaxing CGAN or
crCGAN) to replicate the conventional constrained topology optimization
algorithms in an extremely effective and efficient process. The proposed crCGAN
consists of a generator and a discriminator, both of which are deep
convolutional neural networks (CNN) and the topology design constraint can be
conditionally set to both the generator and discriminator. In order to improve
the training efficiency and accuracy due to the dependency between the training
images and the condition, a variety of crCGAN formulation are introduced to
relax the non-convex design space. These new formulations were evaluated and
validated via a series of comprehensive experiments. Moreover, a minibatch
discrimination technique was introduced in the crCGAN training process to
stabilize the convergence and avoid the mode collapse problems. Additional
verifications were conducted using the state-of-the-art MNIST digits and
CIFAR-10 images conditioned by class labels. The experimental evaluations
clearly reveal that the new objective formulation with the minibatch
discrimination training provides not only the accuracy but also the consistency
of the designs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shen_M/0/1/0/all/0/1&quot;&gt;M.-H. Herman Shen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1&quot;&gt;Liang Chen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1901.11512">
<title>Minimizing Negative Transfer of Knowledge in Multivariate Gaussian Processes: A Scalable and Regularized Approach. (arXiv:1901.11512v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1901.11512</link>
<description rdf:parseType="Literal">&lt;p&gt;Recently there has been an increasing interest in the multivariate Gaussian
process (MGP) which extends the Gaussian process (GP) to deal with multiple
outputs. One approach to construct the MGP and account for non-trivial
commonalities amongst outputs employs a convolution process (CP). The CP is
based on the idea of sharing latent functions across several convolutions.
Despite the elegance of the CP construction, it provides new challenges that
need yet to be tackled. First, even with a moderate number of outputs, model
building is extremely prohibitive due to the huge increase in computational
demands and number of parameters to be estimated. Second, the negative transfer
of knowledge may occur when some outputs do not share commonalities. In this
paper we address these issues. We propose a regularized pairwise modeling
approach for the MGP established using CP. The key feature of our approach is
to distribute the estimation of the full multivariate model into a group of
bivariate GPs which are individually built. Interestingly pairwise modeling
turns out to possess unique characteristics, which allows us to tackle the
challenge of negative transfer through penalizing the latent function that
facilitates information sharing in each bivariate model. Predictions are then
made through combining predictions from the bivariate models within a Bayesian
framework. The proposed method has excellent scalability when the number of
outputs is large and minimizes the negative transfer of knowledge between
uncorrelated outputs. Statistical guarantees for the proposed method are
studied and its advantageous features are demonstrated through numerical
studies.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kontar_R/0/1/0/all/0/1&quot;&gt;Raed Kontar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Raskutti_G/0/1/0/all/0/1&quot;&gt;Garvesh Raskutti&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zhou_S/0/1/0/all/0/1&quot;&gt;Shiyu Zhou&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1902.00629">
<title>Non-asymptotic Analysis of Biased Stochastic Approximation Scheme. (arXiv:1902.00629v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1902.00629</link>
<description rdf:parseType="Literal">&lt;p&gt;Stochastic approximation (SA) is a key method used in statistical learning.
Recently, its non-asymptotic convergence analysis has been considered in many
papers. However, most of the prior analyses are made under restrictive
assumptions such as unbiased gradient estimates and convex objective function,
which significantly limit their applications to sophisticated tasks such as
online and reinforcement learning. These restrictions are all essentially
relaxed in this work. In particular, we analyze a general SA scheme to minimize
a non-convex, smooth objective function. We consider update procedure whose
drift term depends on a state-dependent Markov chain and the mean field is not
necessarily of gradient type, covering approximate second-order method and
allowing asymptotic bias for the one-step updates. We illustrate these settings
with the online EM algorithm and the policy-gradient method for average reward
maximization in reinforcement learning.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Karimi_B/0/1/0/all/0/1&quot;&gt;Belhal Karimi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Miasojedow_B/0/1/0/all/0/1&quot;&gt;Blazej Miasojedow&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Moulines_E/0/1/0/all/0/1&quot;&gt;Eric Moulines&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wai_H/0/1/0/all/0/1&quot;&gt;Hoi-To Wai&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1902.03223">
<title>Non-Stationary Streaming PCA. (arXiv:1902.03223v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1902.03223</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider the problem of streaming principal component analysis (PCA) when
the observations are noisy and generated in a non-stationary environment. Given
$T$, $p$-dimensional noisy observations sampled from a non-stationary variant
of the spiked covariance model, our goal is to construct the best linear
$k$-dimensional subspace of the terminal observations. We study the effect of
non-stationarity by establishing a lower bound on the number of samples and the
corresponding recovery error obtained by any algorithm. We establish the
convergence behaviour of the noisy power method using a novel proof technique
which maybe of independent interest. We conclude that the recovery guarantee of
the noisy power method matches the fundamental limit, thereby generalizing
existing results on streaming PCA to a non-stationary setting.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Bienstock_D/0/1/0/all/0/1&quot;&gt;Daniel Bienstock&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Shukla_A/0/1/0/all/0/1&quot;&gt;Apurv Shukla&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Yun_S/0/1/0/all/0/1&quot;&gt;SeYoung Yun&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1902.03988">
<title>A Fast Iterative Method for Removing Impulsive Noise from Sparse Signals. (arXiv:1902.03988v2 [eess.SP] UPDATED)</title>
<link>http://arxiv.org/abs/1902.03988</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we propose a new method to reconstruct a signal corrupted by
noise where both signal and noise are sparse but in different domains. The
problem investigated in this paper arises in different applications such as
impulsive noise removal from images, audios and videos, decomposition of
low-rank and sparse components of matrices, and separation of texts from
images. First, we provide a cost function for our problem and then present an
iterative method to find its local minimum. The analysis of the algorithm is
also provided. As an application of this problem, we apply our algorithm for
impulsive noise Salt-and-Pepper noise (SPN) and Random-Valued Impulsive Noise
(RVIN)) removal from images and compare our results with other notable
algorithms in the literature. Furthermore, we apply our algorithm for removing
clicks from audio signals. Simulation results show that our algorithms is
simple and fast, and it outperforms other state-of-the-art methods in terms of
reconstruction quality and/or complexity.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Sadrizadeh_S/0/1/0/all/0/1&quot;&gt;Sahar Sadrizadeh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Zarmehi_N/0/1/0/all/0/1&quot;&gt;Nematollah Zarmehi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Asadi_E/0/1/0/all/0/1&quot;&gt;Ehsan Asadi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Abin_H/0/1/0/all/0/1&quot;&gt;Hamidreza Abin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Marvasti_F/0/1/0/all/0/1&quot;&gt;Farokh Marvasti&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1902.05379">
<title>Improving Dense Crowd Counting Convolutional Neural Networks using Inverse k-Nearest Neighbor Maps and Multiscale Upsampling. (arXiv:1902.05379v3 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1902.05379</link>
<description rdf:parseType="Literal">&lt;p&gt;Gatherings of thousands to millions of people frequently occur for an
enormous variety of events, and automated counting of these high-density crowds
is useful for safety, management, and measuring significance of an event. In
this work, we show that the regularly accepted labeling scheme of crowd density
maps for training deep neural networks is less effective than our alternative
inverse k-nearest neighbor (i$k$NN) maps, even when used directly in existing
state-of-the-art network structures. We also provide a new network architecture
MUD-i$k$NN, which uses multi-scale upsampling via transposed convolutions to
take full advantage of the provided i$k$NN labeling. This upsampling combined
with the i$k$NN maps further improves crowd counting accuracy. Our new network
architecture performs favorably in comparison with the state-of-the-art.
However, our labeling and upsampling techniques are generally applicable to
existing crowd counting architectures.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Olmschenk_G/0/1/0/all/0/1&quot;&gt;Greg Olmschenk&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tang_H/0/1/0/all/0/1&quot;&gt;Hao Tang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_Z/0/1/0/all/0/1&quot;&gt;Zhigang Zhu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1902.05965">
<title>From Dark Matter to Galaxies with Convolutional Networks. (arXiv:1902.05965v2 [astro-ph.CO] UPDATED)</title>
<link>http://arxiv.org/abs/1902.05965</link>
<description rdf:parseType="Literal">&lt;p&gt;Cosmological surveys aim at answering fundamental questions about our
Universe, including the nature of dark matter or the reason of unexpected
accelerated expansion of the Universe. In order to answer these questions, two
important ingredients are needed: 1) data from observations and 2) a
theoretical model that allows fast comparison between observation and theory.
Most of the cosmological surveys observe galaxies, which are very difficult to
model theoretically due to the complicated physics involved in their formation
and evolution; modeling realistic galaxies over cosmological volumes requires
running computationally expensive hydrodynamic simulations that can cost
millions of CPU hours. In this paper, we propose to use deep learning to
establish a mapping between the 3D galaxy distribution in hydrodynamic
simulations and its underlying dark matter distribution. One of the major
challenges in this pursuit is the very high sparsity in the predicted galaxy
distribution. To this end, we develop a two-phase convolutional neural network
architecture to generate fast galaxy catalogues, and compare our results
against a standard cosmological technique. We find that our proposed approach
either outperforms or is competitive with traditional cosmological techniques.
Compared to the common methods used in cosmology, our approach also provides a
nice trade-off between time-consumption (comparable to fastest benchmark in the
literature) and the quality and accuracy of the predicted simulation. In
combination with current and upcoming data from cosmological observations, our
method has the potential to answer fundamental questions about our Universe
with the highest accuracy.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+Zhang_X/0/1/0/all/0/1&quot;&gt;Xinyue Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yanfang Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+Zhang_W/0/1/0/all/0/1&quot;&gt;Wei Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+Sun_Y/0/1/0/all/0/1&quot;&gt;Yueqiu Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+He_S/0/1/0/all/0/1&quot;&gt;Siyu He&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+Contardo_G/0/1/0/all/0/1&quot;&gt;Gabriella Contardo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+Villaescusa_Navarro_F/0/1/0/all/0/1&quot;&gt;Francisco Villaescusa-Navarro&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+Ho_S/0/1/0/all/0/1&quot;&gt;Shirley Ho&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1902.06042">
<title>R$^2$-CNN: Fast Tiny Object Detection in Large-Scale Remote Sensing Images. (arXiv:1902.06042v3 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1902.06042</link>
<description rdf:parseType="Literal">&lt;p&gt;Recently, the convolutional neural network has brought impressive
improvements for object detection. However, detecting tiny objects in
large-scale remote sensing images still remains challenging. First, the extreme
large input size makes the existing object detection solutions too slow for
practical use. Second, the massive and complex backgrounds cause serious false
alarms. Moreover, the ultratiny objects increase the difficulty of accurate
detection. To tackle these problems, we propose a unified and self-reinforced
network called remote sensing region-based convolutional neural network
($\mathcal{R}^2$-CNN), composing of backbone Tiny-Net, intermediate global
attention block, and final classifier and detector. Tiny-Net is a lightweight
residual structure, which enables fast and powerful features extraction from
inputs. Global attention block is built upon Tiny-Net to inhibit false
positives. Classifier is then used to predict the existence of targets in each
patch, and detector is followed to locate them accurately if available. The
classifier and detector are mutually reinforced with end-to-end training, which
further speed up the process and avoid false alarms. Effectiveness of
$\mathcal{R}^2$-CNN is validated on hundreds of GF-1 images and GF-2 images
that are 18 000 $\times$ 18 192 pixels, 2.0-m resolution, and 27 620 $\times$
29 200 pixels, 0.8-m resolution, respectively. Specifically, we can process a
GF-1 image in 29.4 s on Titian X just with single thread. According to our
knowledge, no previous solution can detect the tiny object on such huge remote
sensing images gracefully. We believe that it is a significant step toward
practical real-time remote sensing systems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pang_J/0/1/0/all/0/1&quot;&gt;Jiangmiao Pang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1&quot;&gt;Cong Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shi_J/0/1/0/all/0/1&quot;&gt;Jianping Shi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1&quot;&gt;Zhihai Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Feng_H/0/1/0/all/0/1&quot;&gt;Huajun Feng&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1902.06384">
<title>Topics of Concern: Identifying User Issues in Reviews of IoT Apps and Devices. (arXiv:1902.06384v2 [cs.HC] UPDATED)</title>
<link>http://arxiv.org/abs/1902.06384</link>
<description rdf:parseType="Literal">&lt;p&gt;Internet of Things (IoT) systems are bundles of networked sensors and
actuators that are deployed in an environment and act upon the sensory data
that they receive. These systems, especially consumer electronics, have two
main cooperating components: a device and a mobile app. The unique combination
of hardware and software in IoT systems presents challenges that are lesser
known to mainstream software developers. They might require innovative
solutions to support the development and integration of such systems. In this
paper, we analyze more than 90,000 reviews of ten IoT devices and their
corresponding apps and extract the issues that users encountered while using
these systems. Our results indicate that issues with connectivity, timing, and
updates are particularly prevalent in the reviews. Our results call for a new
software-hardware development framework to assist the development of reliable
IoT systems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Truelove_A/0/1/0/all/0/1&quot;&gt;Andrew Truelove&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chowdhury_F/0/1/0/all/0/1&quot;&gt;Farah Naz Chowdhury&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gnawali_O/0/1/0/all/0/1&quot;&gt;Omprakash Gnawali&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Alipour_M/0/1/0/all/0/1&quot;&gt;Mohammad Amin Alipour&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1902.08982">
<title>Flattening Karatsuba&apos;s recursion tree into a single summation. (arXiv:1902.08982v4 [math.NT] UPDATED)</title>
<link>http://arxiv.org/abs/1902.08982</link>
<description rdf:parseType="Literal">&lt;p&gt;The recursion tree resulting from Karatsuba&apos;s formula is built here by using
an interleaved splitting scheme rather than the traditional left/right one.
This allows an easier access to the nodes of the tree and $2n-1$ of them are
initially flattened all at once into a single recursive formula. The whole tree
is then flattened further into a convolution formula involving less elementary
multiplications than the usual Cauchy product. Unlike the traditional splitting
scheme, the interleaved approach may also be applied to infinite power series,
and corresponding formulas are also given.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Baruchel_T/0/1/0/all/0/1&quot;&gt;Thomas Baruchel&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1902.09314">
<title>Attentional Encoder Network for Targeted Sentiment Classification. (arXiv:1902.09314v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/1902.09314</link>
<description rdf:parseType="Literal">&lt;p&gt;Targeted sentiment classification aims at determining the sentimental
tendency towards specific targets. Most of the previous approaches model
context and target words with RNN and attention. However, RNNs are difficult to
parallelize and truncated backpropagation through time brings difficulty in
remembering long-term patterns. To address this issue, this paper proposes an
Attentional Encoder Network (AEN) which eschews recurrence and employs
attention based encoders for the modeling between context and target. We raise
the label unreliability issue and introduce label smoothing regularization. We
also apply pre-trained BERT to this task and obtain new state-of-the-art
results. Experiments and analysis demonstrate the effectiveness and lightweight
of our model.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Song_Y/0/1/0/all/0/1&quot;&gt;Youwei Song&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1&quot;&gt;Jiahai Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jiang_T/0/1/0/all/0/1&quot;&gt;Tao Jiang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1&quot;&gt;Zhiyue Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rao_Y/0/1/0/all/0/1&quot;&gt;Yanghui Rao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1902.09514">
<title>Lost in Machine Translation: A Method to Reduce Meaning Loss. (arXiv:1902.09514v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/1902.09514</link>
<description rdf:parseType="Literal">&lt;p&gt;A desideratum of high-quality translation systems is that they preserve
meaning, in the sense that two sentences with different meanings should not
translate to one and the same sentence in another language. However,
state-of-the-art systems often fail in this regard, particularly in cases where
the source and target languages partition the &quot;meaning space&quot; in different
ways. For instance, &quot;I cut my finger.&quot; and &quot;I cut my finger off.&quot; describe
different states of the world but are translated to French (by both Fairseq and
Google Translate) as &quot;Je me suis coupe le doigt.&quot;, which is ambiguous as to
whether the finger is detached. More generally, translation systems are
typically many-to-one (non-injective) functions from source to target language,
which in many cases results in important distinctions in meaning being lost in
translation. Building on Bayesian models of informative utterance production,
we present a method to define a less ambiguous translation system in terms of
an underlying pre-trained neural sequence-to-sequence model. This method
increases injectivity, resulting in greater preservation of meaning as measured
by improvement in cycle-consistency, without impeding translation quality
(measured by BLEU score).
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cohn_Gordon_R/0/1/0/all/0/1&quot;&gt;Reuben Cohn-Gordon&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Goodman_N/0/1/0/all/0/1&quot;&gt;Noah Goodman&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1902.09679">
<title>Community structure in co-inventor networks affects time to first citation for patents. (arXiv:1902.09679v2 [cs.SI] UPDATED)</title>
<link>http://arxiv.org/abs/1902.09679</link>
<description rdf:parseType="Literal">&lt;p&gt;We have investigated community structure in the co-inventor network of a
given cohort of patents and related this structure to the dynamics of how these
patents acquire their first citation. A statistically significant difference in
the time lag until first citation is linked to whether or not this citation
comes from a patent whose listed inventors share membership in the same
communities as the inventors of the cited patent. Although the
inventor-community structures identified by different community-detection
algorithms differ in several aspects, including the community-size
distribution, the magnitude of the difference in time to first citation is
robustly exhibited. Our work is able to quantify the expected acceleration of
knowledge flow within inventor communities and thereby further establishes the
utility of network-analysis tools for studying innovation dynamics.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Doonan_W/0/1/0/all/0/1&quot;&gt;W. Doonan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Higham_K/0/1/0/all/0/1&quot;&gt;K. W. Higham&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Governale_M/0/1/0/all/0/1&quot;&gt;M. Governale&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zulicke_U/0/1/0/all/0/1&quot;&gt;U. Z&amp;#xfc;licke&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1902.10658">
<title>Regularity Normalization: Constraining Implicit Space with Minimum Description Length. (arXiv:1902.10658v4 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1902.10658</link>
<description rdf:parseType="Literal">&lt;p&gt;Inspired by the adaptation phenomenon of biological neuronal firing, we
propose regularity normalization: a reparameterization of the activation in the
neural network that take into account the statistical regularity in the
implicit space. By considering the neural network optimization process as a
model selection problem, the implicit space is constrained by the normalizing
factor, the minimum description length of the optimal universal code. We
introduce an incremental version of computing this universal code as normalized
maximum likelihood and demonstrated its flexibility to include data prior such
as top-down attention and other oracle information and its compatibility to be
incorporated into batch normalization and layer normalization. The preliminary
results showed that the proposed method outperforms existing normalization
methods in tackling the limited and imbalanced data from a non-stationary
distribution benchmarked on computer vision task. As an unsupervised attention
mechanism given input data, this biologically plausible normalization has the
potential to deal with other complicated real-world scenarios as well as
reinforcement learning setting where the rewards are sparse and non-uniform.
Further research is proposed to discover these scenarios and explore the
behaviors among different variants.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_B/0/1/0/all/0/1&quot;&gt;Baihan Lin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1902.10807">
<title>autoAx: An Automatic Design Space Exploration and Circuit Building Methodology utilizing Libraries of Approximate Components. (arXiv:1902.10807v2 [cs.DC] UPDATED)</title>
<link>http://arxiv.org/abs/1902.10807</link>
<description rdf:parseType="Literal">&lt;p&gt;Approximate computing is an emerging paradigm for developing highly
energy-efficient computing systems such as various accelerators. In the
literature, many libraries of elementary approximate circuits have already been
proposed to simplify the design process of approximate accelerators. Because
these libraries contain from tens to thousands of approximate implementations
for a single arithmetic operation it is intractable to find an optimal
combination of approximate circuits in the library even for an application
consisting of a few operations. An open problem is &quot;how to effectively combine
circuits from these libraries to construct complex approximate accelerators&quot;.
This paper proposes a novel methodology for searching, selecting and combining
the most suitable approximate circuits from a set of available libraries to
generate an approximate accelerator for a given application. To enable fast
design space generation and exploration, the methodology utilizes machine
learning techniques to create computational models estimating the overall
quality of processing and hardware cost without performing full synthesis at
the accelerator level. Using the methodology, we construct hundreds of
approximate accelerators (for a Sobel edge detector) showing different but
relevant tradeoffs between the quality of processing and hardware cost and
identify a corresponding Pareto-frontier. Furthermore, when searching for
approximate implementations of a generic Gaussian filter consisting of 17
arithmetic operations, the proposed approach allows us to identify
approximately $10^3$ highly important implementations from $10^{23}$ possible
solutions in a few hours, while the exhaustive search would take four months on
a high-end processor.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mrazek_V/0/1/0/all/0/1&quot;&gt;Vojtech Mrazek&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hanif_M/0/1/0/all/0/1&quot;&gt;Muhammad Abdullah Hanif&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vasicek_Z/0/1/0/all/0/1&quot;&gt;Zdenek Vasicek&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sekanina_L/0/1/0/all/0/1&quot;&gt;Lukas Sekanina&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shafique_M/0/1/0/all/0/1&quot;&gt;Muhammad Shafique&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.00237">
<title>Dominant Dataset Selection Algorithms for Time-Series Data Based on Linear Transformation. (arXiv:1903.00237v3 [cs.DB] UPDATED)</title>
<link>http://arxiv.org/abs/1903.00237</link>
<description rdf:parseType="Literal">&lt;p&gt;With the explosive growth of time-series data, the scale of time-series data
has already exceeds the conventional computation and storage capabilities in
many applications. On the other hand, the information carried by time-series
data has high redundancy due to the strong correlation between time-series
data. In this paper, we propose the new dominant dataset selection algorithms
to extract the dataset that is only a small dataset but can represent the
kernel information carried by time-series data with the error rate less than
{\epsilon}, where {\epsilon} can be arbitrarily small. We prove that the
selection problem of the dominant dataset is an NP-complete problem. The affine
transformation model is introduced to define the linear transformation function
to ensure the selection function of dominant dataset with the constant time
complexity O(1). Furthermore, the scanning selection algorithm with the time
complexity O(n2) and the greedy selection algorithm with the time complexity
O(n3) are respectively proposed to extract the dominant dataset based on the
linear correlation between time-series data. The proposed algorithms are
evaluated on the real electric power consumption data of a city in China. The
experimental results show that the proposed algorithms not only reduce the size
of kernel dataset but ensure the time-series data integrity in term of accuracy
and efficiency
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1&quot;&gt;Yi Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1&quot;&gt;Yi Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Alghamdi_A/0/1/0/all/0/1&quot;&gt;Ahmed Alghamdi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Polat_K/0/1/0/all/0/1&quot;&gt;Kemal Polat&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Peng_J/0/1/0/all/0/1&quot;&gt;Jialiang Peng&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.02163">
<title>SNU_IDS at SemEval-2019 Task 3: Addressing Training-Test Class Distribution Mismatch in Conversational Classification. (arXiv:1903.02163v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/1903.02163</link>
<description rdf:parseType="Literal">&lt;p&gt;We present several techniques to tackle the mismatch in class distributions
between training and test data in the Contextual Emotion Detection task of
SemEval 2019, by extending the existing methods for class imbalance problem.
Reducing the distance between the distribution of prediction and ground truth,
they consistently show positive effects on the performance. Also we propose a
novel neural architecture which utilizes representation of overall context as
well as of each utterance. The combination of the methods and the models
achieved micro F1 score of about 0.766 on the final evaluation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bae_S/0/1/0/all/0/1&quot;&gt;Sanghwan Bae&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Choi_J/0/1/0/all/0/1&quot;&gt;Jihun Choi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1&quot;&gt;Sang-goo Lee&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.03178">
<title>Transfer Learning Using Ensemble Neural Networks for Organic Solar Cell Screening. (arXiv:1903.03178v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1903.03178</link>
<description rdf:parseType="Literal">&lt;p&gt;Organic Solar Cells are a promising technology for solving the clean energy
crisis in the world. However, generating candidate chemical compounds for solar
cells is a time-consuming process requiring thousands of hours of laboratory
analysis. For a solar cell, the most important property is the power conversion
efficiency which is dependent on the highest occupied molecular orbitals (HOMO)
values of the donor molecules. Recently, machine learning techniques have
proved to be very useful in building predictive models for HOMO values of donor
structures of Organic Photovoltaic Cells (OPVs). Since experimental datasets
are limited in size, current machine learning models are trained on data
derived from calculations based on density functional theory (DFT). Molecular
line notations such as SMILES or InChI are popular input representations for
describing the molecular structure of donor molecules. The two types of line
representations encode different information, such as SMILES defines the bond
types while InChi defines protonation. In this work, we present an ensemble
deep neural network architecture, called SINet, which harnesses both the SMILES
and InChI molecular representations to predict HOMO values and leverage the
potential of transfer learning from a sizeable DFT-computed dataset- Harvard
CEP to build more robust predictive models for relatively smaller HOPV
datasets. Harvard CEP dataset contains molecular structures and properties for
2.3 million candidate donor structures for OPV while HOPV contains DFT-computed
and experimental values of 350 and 243 molecules respectively. Our results
demonstrate significant performance improvement from the use of transfer
learning and leveraging both molecular representations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Paul_A/0/1/0/all/0/1&quot;&gt;Arindam Paul&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jha_D/0/1/0/all/0/1&quot;&gt;Dipendra Jha&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Al_Bahrani_R/0/1/0/all/0/1&quot;&gt;Reda Al-Bahrani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liao_W/0/1/0/all/0/1&quot;&gt;Wei-keng Liao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Choudhary_A/0/1/0/all/0/1&quot;&gt;Alok Choudhary&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Agrawal_A/0/1/0/all/0/1&quot;&gt;Ankit Agrawal&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.03243">
<title>Context-Aware Cross-Lingual Mapping. (arXiv:1903.03243v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/1903.03243</link>
<description rdf:parseType="Literal">&lt;p&gt;Cross-lingual word vectors are typically obtained by fitting an orthogonal
matrix that maps the entries of a bilingual dictionary from a source to a
target vector space. Word vectors, however, are most commonly used for sentence
or document-level representations that are calculated as the weighted average
of word embeddings. In this paper, we propose an alternative to word-level
mapping that better reflects sentence-level cross-lingual similarity. We
incorporate context in the transformation matrix by directly mapping the
averaged embeddings of aligned sentences in a parallel corpus. We also
implement cross-lingual mapping of deep contextualized word embeddings using
parallel sentences with word alignments. In our experiments, both approaches
resulted in cross-lingual sentence embeddings that outperformed
context-independent word mapping in sentence translation retrieval.
Furthermore, the sentence-level transformation could be used for word-level
mapping without loss in word translation quality.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Aldarmaki_H/0/1/0/all/0/1&quot;&gt;Hanan Aldarmaki&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Diab_M/0/1/0/all/0/1&quot;&gt;Mona Diab&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.03495">
<title>Improving Skin Condition Classification with a Visual Symptom Checker Trained using Reinforcement Learning. (arXiv:1903.03495v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1903.03495</link>
<description rdf:parseType="Literal">&lt;p&gt;We present a visual symptom checker that combines a pre-trained Convolutional
Neural Network (CNN) with a Reinforcement Learning (RL) agent as a Question
Answering (QA) model. This method increases the classification confidence and
accuracy of the visual symptom checker, and decreases the average number of
questions asked to narrow down the differential diagnosis. A Deep Q-Network
(DQN)-based RL agent learns how to ask the patient about the presence of
symptoms in order to maximize the probability of correctly identifying the
underlying condition. The RL agent uses the visual information provided by CNN
in addition to the answers to the asked questions to guide the QA system. We
demonstrate that the RL-based approach increases the accuracy more than 20%
compared to the CNN-only approach, which only uses the visual information to
predict the condition. Moreover, the increased accuracy is up to 10% compared
to the approach that uses the visual information provided by CNN along with a
conventional decision tree-based QA system. We finally show that the RL-based
approach not only outperforms the decision tree-based approach, but also
narrows down the diagnosis faster in terms of the average number of asked
questions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Akrout_M/0/1/0/all/0/1&quot;&gt;Mohamed Akrout&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Farahmand_A/0/1/0/all/0/1&quot;&gt;Amir-massoud Farahmand&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jarmain_T/0/1/0/all/0/1&quot;&gt;Tory Jarmain&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Abid_L/0/1/0/all/0/1&quot;&gt;Latif Abid&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.05164">
<title>Scaling Multi-Domain Dialogue State Tracking via Query Reformulation. (arXiv:1903.05164v3 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/1903.05164</link>
<description rdf:parseType="Literal">&lt;p&gt;We present a novel approach to dialogue state tracking and referring
expression resolution tasks. Successful contextual understanding of multi-turn
spoken dialogues requires resolving referring expressions across turns and
tracking the entities relevant to the conversation across turns. Tracking
conversational state is particularly challenging in a multi-domain scenario
when there exist multiple spoken language understanding (SLU) sub-systems, and
each SLU sub-system operates on its domain-specific meaning representation.
While previous approaches have addressed the disparate schema issue by learning
candidate transformations of the meaning representation, in this paper, we
instead model the reference resolution as a dialogue context-aware user query
reformulation task -- the dialog state is serialized to a sequence of natural
language tokens representing the conversation. We develop our model for query
reformulation using a pointer-generator network and a novel multi-task learning
setup. In our experiments, we show a significant improvement in absolute F1 on
an internal as well as a, soon to be released, public benchmark respectively.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rastogi_P/0/1/0/all/0/1&quot;&gt;Pushpendre Rastogi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gupta_A/0/1/0/all/0/1&quot;&gt;Arpit Gupta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1&quot;&gt;Tongfei Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mathias_L/0/1/0/all/0/1&quot;&gt;Lambert Mathias&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.05942">
<title>Dense Relational Captioning: Triple-Stream Networks for Relationship-Based Captioning. (arXiv:1903.05942v3 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1903.05942</link>
<description rdf:parseType="Literal">&lt;p&gt;Our goal in this work is to train an image captioning model that generates
more dense and informative captions. We introduce &quot;relational captioning,&quot; a
novel image captioning task which aims to generate multiple captions with
respect to relational information between objects in an image. Relational
captioning is a framework that is advantageous in both diversity and amount of
information, leading to image understanding based on relationships. Part-of
speech (POS, i.e. subject-object-predicate categories) tags can be assigned to
every English word. We leverage the POS as a prior to guide the correct
sequence of words in a caption. To this end, we propose a multi-task
triple-stream network (MTTSNet) which consists of three recurrent units for the
respective POS and jointly performs POS prediction and captioning. We
demonstrate more diverse and richer representations generated by the proposed
model against several baselines and competing methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_D/0/1/0/all/0/1&quot;&gt;Dong-Jin Kim&lt;/a&gt; (djnjusa@kaist.ac.kr), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Choi_J/0/1/0/all/0/1&quot;&gt;Jinsoo Choi&lt;/a&gt; (jinsc37@kaist.ac.kr), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Oh_T/0/1/0/all/0/1&quot;&gt;Tae-Hyun Oh&lt;/a&gt; (taehyun@csail.mit.edu), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kweon_I/0/1/0/all/0/1&quot;&gt;In So Kweon&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.07221">
<title>Multidimensional ground reaction forces and moments from wearable sensor accelerations via deep learning. (arXiv:1903.07221v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1903.07221</link>
<description rdf:parseType="Literal">&lt;p&gt;Objective: Monitoring athlete internal workload exposure, including
prevention of catastrophic non-contact knee injuries, relies on the existence
of a custom early-warning detection system. This system must be able to
estimate accurate, reliable, and valid musculoskeletal joint loads, for
sporting maneuvers in near real-time and during match play. However, current
methods are constrained to laboratory instrumentation, are labor and cost
intensive, and require highly trained specialist knowledge, thereby limiting
their ecological validity and volume deployment. Methods: Here we show that
kinematic data obtained from wearable sensor accelerometers, in lieu of
embedded force platforms, can leverage recent supervised learning techniques to
predict in-game near real-time multidimensional ground reaction forces and
moments (GRF/M). Competing convolutional neural network (CNN) deep learning
models were trained using laboratory-derived stance phase GRF/M data and
simulated sensor accelerations for running and sidestepping maneuvers derived
from nearly half a million legacy motion trials. Then, predictions were made
from each model driven by five sensor accelerations recorded during independent
inter-laboratory data capture sessions. Results: Despite adversarial
conditions, the proposed deep learning workbench achieved correlations to
ground truth, by GRF component, of vertical 0.9663, anterior 0.9579 (both
running), and lateral 0.8737 (sidestepping). Conclusion: The lessons learned
from this study will facilitate the use of wearable sensors in conjunction with
deep learning to accurately estimate near real-time on-field GRF/M.
Significance: Coaching, medical, and allied health staff can use this
technology to monitor a range of joint loading indicators during game play,
with the ultimate aim to minimize the occurrence of non-contact injuries in
elite and community-level sports.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Johnson_W/0/1/0/all/0/1&quot;&gt;William R. Johnson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mian_A/0/1/0/all/0/1&quot;&gt;Ajmal Mian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Robinson_M/0/1/0/all/0/1&quot;&gt;Mark A. Robinson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Verheul_J/0/1/0/all/0/1&quot;&gt;Jasper Verheul&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lloyd_D/0/1/0/all/0/1&quot;&gt;David G. Lloyd&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Alderson_J/0/1/0/all/0/1&quot;&gt;Jacqueline A. Alderson&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.09022">
<title>Subgraph Networks with Application to Structural Feature Space Expansion. (arXiv:1903.09022v2 [cs.SI] UPDATED)</title>
<link>http://arxiv.org/abs/1903.09022</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, the concept of subgraph network (SGN) is introduced and then
applied to network models, with algorithms designed for constructing the
1st-order and 2nd-order SGNs, which can be easily extended to build
higher-order ones. Furthermore, these SGNs are used to expand the structural
feature space of the underlying network, beneficial for network classification.
Numerical experiments demonstrate that the network classification model based
on the structural features of the original network together with the 1st-order
and 2nd-order SGNs always performs the best as compared to the models based
only on one or two of such networks. In other words, the structural features of
SGNs can complement that of the original network for better network
classification, regardless of the feature extraction method used, such as the
handcrafted, network embedding and kernel-based methods. More interestingly, it
is found that the model based on the handcrafted feature performs even better
than those based on automatically generated features, at least for most
datasets tested in the present investigation. This indicates that, in general,
properly chosen structural features are not only more interpretable due to
their clear physical meanings, but also effective in designing structure-based
algorithms for network classification.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xuan_Q/0/1/0/all/0/1&quot;&gt;Qi Xuan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1&quot;&gt;Jinhuan Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_M/0/1/0/all/0/1&quot;&gt;Minghao Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yuan_J/0/1/0/all/0/1&quot;&gt;Junkun Yuan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fu_C/0/1/0/all/0/1&quot;&gt;Chenbo Fu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ruan_Z/0/1/0/all/0/1&quot;&gt;Zhongyuan Ruan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_G/0/1/0/all/0/1&quot;&gt;Guanrong Chen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.09094">
<title>Learning Personalized Thermal Preferences via Bayesian Active Learning with Unimodality Constraints. (arXiv:1903.09094v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1903.09094</link>
<description rdf:parseType="Literal">&lt;p&gt;Thermal preferences vary from person to person and may change over time. The
main objective of this paper is to sequentially pose intelligent queries to
occupants in order to optimally learn the indoor air temperature values which
maximize their satisfaction. Our central hypothesis is that an occupant&apos;s
preference relation over indoor air temperature can be described using a scalar
function of these temperatures, which we call the &quot;occupant&apos;s thermal utility
function&quot;. Information about an occupant&apos;s preference over these temperatures
is available to us through their response to thermal preference queries :
&quot;prefer warmer,&quot; &quot;prefer cooler&quot; and &quot;satisfied&quot; which we interpret as
statements about the derivative of their utility function, i.e. the utility
function is &quot;increasing&quot;, &quot;decreasing&quot; and &quot;constant&quot; respectively. We model
this hidden utility function using a Gaussian process prior with built-in
unimodality constraint, i.e., the utility function has a unique maximum, and we
train this model using Bayesian inference. This permits an expected improvement
based selection of next preference query to pose to the occupant, which takes
into account both exploration (sampling from areas of high uncertainty) and
exploitation (sampling from areas which are likely to offer an improvement over
current best observation). We use this framework to sequentially design
experiments and illustrate its benefits by showing that it requires drastically
fewer observations to learn the maximally preferred temperature values as
compared to other methods. This framework is an important step towards the
development of intelligent HVAC systems which would be able to respond to
occupants&apos; personalized thermal comfort needs. In order to encourage the use of
our PE framework and ensure reproducibility in results, we publish an
implementation of our work named GPPrefElicit as an open-source package in
Python.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Awalgaonkar_N/0/1/0/all/0/1&quot;&gt;Nimish Awalgaonkar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bilionis_I/0/1/0/all/0/1&quot;&gt;Ilias Bilionis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1&quot;&gt;Xiaoqi Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Karava_P/0/1/0/all/0/1&quot;&gt;Panagiota Karava&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tzempelikos_A/0/1/0/all/0/1&quot;&gt;Athanasios Tzempelikos&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.09341">
<title>Unsupervised Speech Enhancement Based on Multichannel NMF-Informed Beamforming for Noise-Robust Automatic Speech Recognition. (arXiv:1903.09341v2 [cs.SD] UPDATED)</title>
<link>http://arxiv.org/abs/1903.09341</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper describes multichannel speech enhancement for improving automatic
speech recognition (ASR) in noisy environments. Recently, the minimum variance
distortionless response (MVDR) beamforming has widely been used because it
works well if the steering vector of speech and the spatial covariance matrix
(SCM) of noise are given. To estimating such spatial information, conventional
studies take a supervised approach that classifies each time-frequency (TF) bin
into noise or speech by training a deep neural network (DNN). The performance
of ASR, however, is degraded in an unknown noisy environment. To solve this
problem, we take an unsupervised approach that decomposes each TF bin into the
sum of speech and noise by using multichannel nonnegative matrix factorization
(MNMF). This enables us to accurately estimate the SCMs of speech and noise not
from observed noisy mixtures but from separated speech and noise components. In
this paper we propose online MVDR beamforming by effectively initializing and
incrementally updating the parameters of MNMF. Another main contribution is to
comprehensively investigate the performances of ASR obtained by various types
of spatial filters, i.e., time-invariant and variant versions of MVDR
beamformers and those of rank-1 and full-rank multichannel Wiener filters, in
combination with MNMF. The experimental results showed that the proposed method
outperformed the state-of-the-art DNN-based beamforming method in unknown
environments that did not match training data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shimada_K/0/1/0/all/0/1&quot;&gt;Kazuki Shimada&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bando_Y/0/1/0/all/0/1&quot;&gt;Yoshiaki Bando&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mimura_M/0/1/0/all/0/1&quot;&gt;Masato Mimura&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Itoyama_K/0/1/0/all/0/1&quot;&gt;Katsutoshi Itoyama&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yoshii_K/0/1/0/all/0/1&quot;&gt;Kazuyoshi Yoshii&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kawahara_T/0/1/0/all/0/1&quot;&gt;Tatsuya Kawahara&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.09722">
<title>Pre-trained Language Model Representations for Language Generation. (arXiv:1903.09722v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/1903.09722</link>
<description rdf:parseType="Literal">&lt;p&gt;Pre-trained language model representations have been successful in a wide
range of language understanding tasks. In this paper, we examine different
strategies to integrate pre-trained representations into sequence to sequence
models and apply it to neural machine translation and abstractive
summarization. We find that pre-trained representations are most effective when
added to the encoder network which slows inference by only 14%. Our experiments
in machine translation show gains of up to 5.3 BLEU in a simulated
resource-poor setup. While returns diminish with more labeled data, we still
observe improvements when millions of sentence-pairs are available. Finally, on
abstractive summarization we achieve a new state of the art on the full text
version of CNN/DailyMail.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Edunov_S/0/1/0/all/0/1&quot;&gt;Sergey Edunov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Baevski_A/0/1/0/all/0/1&quot;&gt;Alexei Baevski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Auli_M/0/1/0/all/0/1&quot;&gt;Michael Auli&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.09769">
<title>Progressive DNN Compression: A Key to Achieve Ultra-High Weight Pruning and Quantization Rates using ADMM. (arXiv:1903.09769v2 [cs.NE] UPDATED)</title>
<link>http://arxiv.org/abs/1903.09769</link>
<description rdf:parseType="Literal">&lt;p&gt;Weight pruning and weight quantization are two important categories of DNN
model compression. Prior work on these techniques are mainly based on
heuristics. A recent work developed a systematic frame-work of DNN weight
pruning using the advanced optimization technique ADMM (Alternating Direction
Methods of Multipliers), achieving one of state-of-art in weight pruning
results. In this work, we first extend such one-shot ADMM-based framework to
guarantee solution feasibility and provide fast convergence rate, and
generalize to weight quantization as well. We have further developed a
multi-step, progressive DNN weight pruning and quantization framework, with
dual benefits of (i) achieving further weight pruning/quantization thanks to
the special property of ADMM regularization, and (ii) reducing the search space
within each step. Extensive experimental results demonstrate the superior
performance compared with prior work. Some highlights: (i) we achieve 246x,36x,
and 8x weight pruning on LeNet-5, AlexNet, and ResNet-50 models, respectively,
with (almost) zero accuracy loss; (ii) even a significant 61x weight pruning in
AlexNet (ImageNet) results in only minor degradation in actual accuracy
compared with prior work; (iii) we are among the first to derive notable weight
pruning results for ResNet and MobileNet models; (iv) we derive the first
lossless, fully binarized (for all layers) LeNet-5 for MNIST and VGG-16 for
CIFAR-10; and (v) we derive the first fully binarized (for all layers) ResNet
for ImageNet with reasonable accuracy loss.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ye_S/0/1/0/all/0/1&quot;&gt;Shaokai Ye&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Feng_X/0/1/0/all/0/1&quot;&gt;Xiaoyu Feng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_T/0/1/0/all/0/1&quot;&gt;Tianyun Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ma_X/0/1/0/all/0/1&quot;&gt;Xiaolong Ma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_S/0/1/0/all/0/1&quot;&gt;Sheng Lin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1&quot;&gt;Zhengang Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_K/0/1/0/all/0/1&quot;&gt;Kaidi Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wen_W/0/1/0/all/0/1&quot;&gt;Wujie Wen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1&quot;&gt;Sijia Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1&quot;&gt;Jian Tang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fardad_M/0/1/0/all/0/1&quot;&gt;Makan Fardad&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_X/0/1/0/all/0/1&quot;&gt;Xue Lin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1&quot;&gt;Yongpan Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yanzhi Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.09795">
<title>Data-driven Prognostics with Predictive Uncertainty Estimation using Ensemble of Deep Ordinal Regression Models. (arXiv:1903.09795v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1903.09795</link>
<description rdf:parseType="Literal">&lt;p&gt;Prognostics or Remaining Useful Life (RUL) Estimation from multi-sensor time
series data is useful to enable condition-based maintenance and ensure high
operational availability of equipment. We propose a novel deep learning based
approach for Prognostics with Uncertainty Quantification that is useful in
scenarios where: (i) access to labeled failure data is scarce due to rarity of
failures (ii) future operational conditions are unobserved and (iii) inherent
noise is present in the sensor readings. All three scenarios mentioned are
unavoidable sources of uncertainty in the RUL estimation process often
resulting in unreliable RUL estimates. To address (i), we formulate RUL
estimation as an Ordinal Regression (OR) problem, and propose LSTM-OR: deep
Long Short Term Memory (LSTM) network based approach to learn the OR function.
We show that LSTM-OR naturally allows for incorporation of censored operational
instances in training along with the failed instances, leading to more robust
learning. To address (ii), we propose a simple yet effective approach to
quantify predictive uncertainty in the RUL estimation models by training an
ensemble of LSTM-OR models. Through empirical evaluation on C-MAPSS turbofan
engine benchmark datasets, we demonstrate that LSTM-OR is significantly better
than the commonly used deep metric regression based approaches for RUL
estimation, especially when failed training instances are scarce. Further, our
uncertainty quantification approach yields high quality predictive uncertainty
estimates while also leading to improved RUL estimates compared to single best
LSTM-OR models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+TV_V/0/1/0/all/0/1&quot;&gt;Vishnu TV&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Diksha/0/1/0/all/0/1&quot;&gt;Diksha&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Malhotra_P/0/1/0/all/0/1&quot;&gt;Pankaj Malhotra&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vig_L/0/1/0/all/0/1&quot;&gt;Lovekesh Vig&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shroff_G/0/1/0/all/0/1&quot;&gt;Gautam Shroff&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.09847">
<title>Monocular 3D Object Detection with Pseudo-LiDAR Point Cloud. (arXiv:1903.09847v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1903.09847</link>
<description rdf:parseType="Literal">&lt;p&gt;Monocular 3D scene understanding tasks, such as object size estimation,
heading angle estimation and 3D localization, is challenging. Successful modern
day methods for 3D scene understanding require the use of a 3D sensor such as a
depth camera, a stereo camera or LiDAR. On the other hand, single image based
methods have significantly worse performance, but rightly so, as there is
little explicit depth information in a 2D image. In this work, we aim at
bridging the performance gap between 3D sensing and 2D sensing for 3D object
detection by enhancing LiDAR-based algorithms to work with single image input.
Specifically, we perform monocular depth estimation and lift the input image to
a point cloud representation, which we call pseudo-LiDAR point cloud. Then we
can train a LiDAR-based 3D detection network with our pseudo-LiDAR end-to-end.
Following the pipeline of two-stage 3D detection algorithms, we detect 2D
object proposals in the input image and extract a point cloud frustum from the
pseudo-LiDAR for each proposal. Then an oriented 3D bounding box is detected
for each frustum. To handle the large amount of noise in the pseudo-LiDAR, we
propose two innovations: (1) use a 2D-3D bounding box consistency constraint,
adjusting the predicted 3D bounding box to have a high overlap with its
corresponding 2D proposal after projecting onto the image; (2) use the instance
mask instead of the bounding box as the representation of 2D proposals, in
order to reduce the number of points not belonging to the object in the point
cloud frustum. Through our evaluation on the KITTI benchmark, we achieve the
top-ranked performance on both bird&apos;s eye view and 3D object detection among
all monocular methods, effectively quadrupling the performance over previous
state-of-the-art.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Weng_X/0/1/0/all/0/1&quot;&gt;Xinshuo Weng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kitani_K/0/1/0/all/0/1&quot;&gt;Kris Kitani&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.09927">
<title>Using RGB Image as Visual Input for Mapless Robot Navigation. (arXiv:1903.09927v2 [cs.RO] UPDATED)</title>
<link>http://arxiv.org/abs/1903.09927</link>
<description rdf:parseType="Literal">&lt;p&gt;Robot navigation in mapless environment is one of the essential problems and
challenges in mobile robots. Deep reinforcement learning is a promising
direction to tackle the task of mapless navigation. Since reinforcement
learning requires a lot of exploration, it is usually necessary to train the
agent in the simulator and then migrate to the real environment.The big reality
gap makes RGB image, the most common visual sensor, rarely used. In this paper
we present a learning-based mapless motion planner by taking RGB images as
visual inputs. Many parameters in end-to-end navigation network taking RGB
images as visual input are used to extract visual features. Therefore, we
decouple visual features extracted module from the reinforcement learning
network to reduce the need of interactions between agent and environment. We
use Variational Autoencoder (VAE) to encode the image, and input the obtained
latent vector as low-dimensional visual features into the network together with
the target and motion information, so that the sampling efficiency of the agent
is greatly improved. We built simulation environment as robot navigation
environment for algorithm comparison. In the test environment, the proposed
method was compared with the end-to-end network, which proved its effectiveness
and efficiency. What&apos;s more, the proposed motion planner helps to find the
optimal path. Finally, experiments were carried out in our built environment.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ma_L/0/1/0/all/0/1&quot;&gt;Liulong Ma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1&quot;&gt;Jiao Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+%2A_Y/0/1/0/all/0/1&quot;&gt;Yanjie Liu *&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.10841">
<title>Data-Driven Microstructure Property Relations. (arXiv:1903.10841v2 [cs.CE] UPDATED)</title>
<link>http://arxiv.org/abs/1903.10841</link>
<description rdf:parseType="Literal">&lt;p&gt;An image based prediction of the effective heat conductivity for highly
heterogeneous microstructured materials is presented. The synthetic materials
under consideration show different inclusion morphology, orientation, volume
fraction and topology. The prediction of the effective property is made
exclusively based on image data with the main emphasis being put on the 2-point
spatial correlation function. This task is implemented using both unsupervised
and supervised machine learning methods. First, a snapshot proper orthogonal
decomposition (POD) is used to analyze big sets of random microstructures and
thereafter compress significant characteristics of the microstructure into a
low-dimensional feature vector. In order to manage the related amount of data
and computations, three different incremental snapshot POD methods are
proposed. In the second step, the obtained feature vector is used to predict
the effective material property by using feed forward neural networks.
Numerical examples regarding the incremental basis identification and the
prediction accuracy of the approach are presented. A Python code illustrating
the application of the surrogate is freely available.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lissner_J/0/1/0/all/0/1&quot;&gt;Julian Li&amp;#xdf;ner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fritzen_F/0/1/0/all/0/1&quot;&gt;Felix Fritzen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.11054">
<title>Effect of Personality Traits on UX Evaluation Metrics: A Study on Usability Issues, Valence-Arousal and Skin Conductance. (arXiv:1903.11054v2 [cs.HC] UPDATED)</title>
<link>http://arxiv.org/abs/1903.11054</link>
<description rdf:parseType="Literal">&lt;p&gt;Personality affect the way someone feels or acts. This paper examines the
effect of personality traits, as operationalized by the Big-five questionnaire,
on the number, type, and severity of the identified usability issues,
physiological signals (skin conductance), and subjective emotional ratings
(valence-arousal).Twenty-four users interacted with a web service and then
participated in a retrospective thinking aloud session. Results revealed that
the number of usability issues is significantly affected by the Openness trait.
Emotional Stability significantly affects the type of reported usability
issues. Problem severity is not affected by any trait. Valence ratings are
significantly affected by Conscientiousness, whereas Agreeableness, Emotional
Stability and Openness significantly affect arousal ratings. Finally, Openness
has a significant effect on the number of detected peaks in user&apos;s skin
conductance.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liapis_A/0/1/0/all/0/1&quot;&gt;Alexandros Liapis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Katsanos_C/0/1/0/all/0/1&quot;&gt;Christos Katsanos&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xenos_M/0/1/0/all/0/1&quot;&gt;Michalis Xenos&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Orphanoudakis_T/0/1/0/all/0/1&quot;&gt;Theofanis Orphanoudakis&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.11205">
<title>Airbnb&apos;s disruption of the housing structure in London. (arXiv:1903.11205v2 [cs.CY] UPDATED)</title>
<link>http://arxiv.org/abs/1903.11205</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper explores Airbnb, a peer-to-peer platform for short-term rental of
housing accommodation, examining the geographical pattern of those
establishments using data from London. Our purpose is to analyse whether or not
the diversity of dwelling types correlate with the distribution of listings. We
use a measure of spread based on entropy to indicate the diversity of dwelling
types and look at its relationship with the distribution of Airbnb
establishments, as well as the type of home ownership using correlation
analysis. It is important to note that our study only considers domestic
building types, and excludes any information on the diversity of land uses. Two
important findings emerge from our analysis. Firstly, the spatial location of
Airbnb rentals is negatively correlated with the diversity of dwelling types,
and positively correlated with a single dwelling type, which corresponds in
general to purpose built flats, conversions and flats in commercial buildings.
Secondly, Airbnb is associated with areas that have a high proportion of
privately rented properties, detracting more than 1.4% of the housing supply
into short-term rentals. Such a phenomenon can reach up to 20% in some
neighbourhoods, further exacerbating the process of gentrification. Finally, we
discuss the implications of these findings as instruments to inform policies
associated with the &apos;sharing&apos; economy in relation to the disruption of the
housing structure.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shabrina_Z/0/1/0/all/0/1&quot;&gt;Zahratu Shabrina&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Arcaute_E/0/1/0/all/0/1&quot;&gt;Elsa Arcaute&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Batty_M/0/1/0/all/0/1&quot;&gt;Michael Batty&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.11394">
<title>Spatially-Adaptive Residual Networks for Efficient Image and Video Deblurring. (arXiv:1903.11394v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1903.11394</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we address the problem of dynamic scene deblurring in the
presence of motion blur. Restoration of images affected by severe blur
necessitates a network design with a large receptive field, which existing
networks attempt to achieve through a simple increment in the number of generic
convolution layers, kernel-size, or the scales at which the image is processed.
However, increasing the network capacity in this manner comes at the expense of
an increase in model size and inference time, and ignoring the non-uniform
nature of blur. We present a new architecture composed of spatially adaptive
residual learning modules that implicitly discover the spatially varying shifts
responsible for non-uniform blur in the input image and learn to modulate the
filters. This capability is complemented by a self-attentive module which
captures non-local relationships among the intermediate features and enhances
the receptive field. We then incorporate a spatiotemporal recurrent module in
the design to also facilitate efficient video deblurring. Our networks can
implicitly model the spatially-varying deblurring process while dispensing with
multi-scale processing and large filters entirely. Extensive qualitative and
quantitative comparisons with prior art on benchmark dynamic scene deblurring
datasets clearly demonstrate the superiority of the proposed networks via a
reduction in model-size and significant improvements in accuracy and speed,
enabling almost real-time deblurring.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Purohit_K/0/1/0/all/0/1&quot;&gt;Kuldeep Purohit&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rajagopalan_A/0/1/0/all/0/1&quot;&gt;A. N. Rajagopalan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.11444">
<title>Accurate Monocular 3D Object Detection via Color-Embedded 3D Reconstruction for Autonomous Driving. (arXiv:1903.11444v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1903.11444</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we propose a monocular 3D object detection framework in the
domain of autonomous driving. Unlike previous image-based methods which focus
on RGB feature extracted from 2D images, our method solves this problem in the
reconstructed 3D space in order to exploit 3D contexts explicitly. To this end,
we first leverage a stand-alone module to transform the input data from 2D
image plane to 3D point clouds space for a better input representation, then we
perform the 3D detection using PointNet backbone net to obtain objects 3D
locations, dimensions and orientations. To enhance the discriminative
capability of point clouds, we propose a multi-modal feature fusion module to
embed the complementary RGB cue into the generated point clouds representation.
We argue that it is more effective to infer the 3D bounding boxes from the
generated 3D scene space (i.e., X,Y, Z space) compared to the image plane
(i.e., R,G,B image plane). Evaluation on the challenging KITTI dataset shows
that our approach boosts the performance of state-of-the-art monocular approach
by a large margin, i.e., around 15% absolute AP on both 3D localization and
detection tasks for Car category at 0.7 IoU threshold.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ma_X/0/1/0/all/0/1&quot;&gt;Xinzhu Ma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1&quot;&gt;Zhihui Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1&quot;&gt;Haojie Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ouyang_W/0/1/0/all/0/1&quot;&gt;Wanli Ouyang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_P/0/1/0/all/0/1&quot;&gt;Pengbo Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.11783">
<title>A dataset for resolving referring expressions in spoken dialogue via contextual query rewrites (CQR). (arXiv:1903.11783v3 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/1903.11783</link>
<description rdf:parseType="Literal">&lt;p&gt;We present Contextual Query Rewrite (CQR) a dataset for multi-domain
task-oriented spoken dialogue systems that is an extension of the Stanford
dialog corpus (Eric et al., 2017a). While previous approaches have addressed
the issue of diverse schemas by learning candidate transformations (Naik et
al., 2018), we instead model the reference resolution task as a user query
reformulation task, where the dialog state is serialized into a natural
language query that can be executed by the downstream spoken language
understanding system. In this paper, we describe our methodology for creating
the query reformulation extension to the dialog corpus, and present an initial
set of experiments to establish a baseline for the CQR task. We have released
the corpus to the public [1] to support further research in this area.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Regan_M/0/1/0/all/0/1&quot;&gt;Michael Regan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rastogi_P/0/1/0/all/0/1&quot;&gt;Pushpendre Rastogi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gupta_A/0/1/0/all/0/1&quot;&gt;Arpit Gupta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mathias_L/0/1/0/all/0/1&quot;&gt;Lambert Mathias&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.11848">
<title>Sogou Machine Reading Comprehension Toolkit. (arXiv:1903.11848v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/1903.11848</link>
<description rdf:parseType="Literal">&lt;p&gt;Machine reading comprehension have been intensively studied in recent years,
and neural network-based models have shown dominant performances. In this
paper, we present a Sogou Machine Reading Comprehension (SMRC) toolkit that can
be used to provide the fast and efficient development of modern machine
comprehension models, including both published models and original prototypes.
To achieve this goal, the toolkit provides dataset readers, a flexible
preprocessing pipeline, necessary neural network components, and built-in
models, which make the whole process of data preparation, model construction,
and training easier.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1&quot;&gt;Jindou Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1&quot;&gt;Yunlun Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Deng_C/0/1/0/all/0/1&quot;&gt;Chao Deng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tang_H/0/1/0/all/0/1&quot;&gt;Hongyi Tang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1&quot;&gt;Bingning Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_H/0/1/0/all/0/1&quot;&gt;Haoze Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yao_T/0/1/0/all/0/1&quot;&gt;Ting Yao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1&quot;&gt;Qi Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12020">
<title>Describing like humans: on diversity in image captioning. (arXiv:1903.12020v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1903.12020</link>
<description rdf:parseType="Literal">&lt;p&gt;Recently, the state-of-the-art models for image captioning have overtaken
human performance based on the most popular metrics, such as BLEU, METEOR,
ROUGE, and CIDEr. Does this mean we have solved the task of image captioning?
The above metrics only measure the similarity of the generated caption to the
human annotations, which reflects its accuracy. However, an image contains many
concepts and multiple levels of detail, and thus there is a variety of captions
that express different concepts and details that might be interesting for
different humans. Therefore only evaluating accuracy is not sufficient for
measuring the performance of captioning models --- the diversity of the
generated captions should also be considered. In this paper, we proposed a new
metric for measuring the diversity of image captions, which is derived from
latent semantic analysis and kernelized to use CIDEr similarity. We conduct
extensive experiments to re-evaluate recent captioning models in the context of
both diversity and accuracy. We find that there is still a large gap between
the model and human performance in terms of both accuracy and diversity and the
models that have optimized accuracy (CIDEr) have low diversity. We also show
that balancing the cross-entropy loss and CIDEr reward in reinforcement
learning during training can effectively control the tradeoff between diversity
and accuracy of the generated captions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1&quot;&gt;Qingzhong Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chan_A/0/1/0/all/0/1&quot;&gt;Antoni B. Chan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12141">
<title>Improving MAE against CCE under Label Noise. (arXiv:1903.12141v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1903.12141</link>
<description rdf:parseType="Literal">&lt;p&gt;Label noise is inherent in many deep learning tasks when the training set
becomes large. A typical approach to tackle noisy labels is using robust loss
functions. Categorical cross entropy (CCE) is a successful loss function in
many applications. However, CCE is also notorious for fitting samples with
corrupted labels easily. In contrast, mean absolute error (MAE) is
noise-tolerant theoretically, but it generally works much worse than CCE in
practice. In this work, we have three main points. First, to explain why MAE
generally performs much worse than CCE, we introduce a new understanding of
them fundamentally by exposing their intrinsic sample weighting schemes from
the perspective of every sample&apos;s gradient magnitude with respect to logit
vector. Consequently, we find that MAE&apos;s differentiation degree over training
examples is too small so that informative ones cannot contribute enough against
the non-informative during training. Therefore, MAE generally underfits
training data when noise rate is high. Second, based on our finding, we propose
an improved MAE (IMAE), which inherits MAE&apos;s good noise-robustness. Moreover,
the differentiation degree over training data points is controllable so that
IMAE addresses the underfitting problem of MAE. Third, the effectiveness of
IMAE against CCE and MAE is evaluated empirically with extensive experiments,
which focus on image classification under synthetic corrupted labels and video
retrieval under real noisy labels.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1&quot;&gt;Xinshao Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kodirov_E/0/1/0/all/0/1&quot;&gt;Elyor Kodirov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hua_Y/0/1/0/all/0/1&quot;&gt;Yang Hua&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Robertson_N/0/1/0/all/0/1&quot;&gt;Neil M. Robertson&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12287">
<title>PyTorch-BigGraph: A Large-scale Graph Embedding System. (arXiv:1903.12287v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1903.12287</link>
<description rdf:parseType="Literal">&lt;p&gt;Graph embedding methods produce unsupervised node features from graphs that
can then be used for a variety of machine learning tasks. Modern graphs,
particularly in industrial applications, contain billions of nodes and
trillions of edges, which exceeds the capability of existing embedding systems.
We present PyTorch-BigGraph (PBG), an embedding system that incorporates
several modifications to traditional multi-relation embedding systems that
allow it to scale to graphs with billions of nodes and trillions of edges. PBG
uses graph partitioning to train arbitrarily large embeddings on either a
single machine or in a distributed environment. We demonstrate comparable
performance with existing embedding systems on common benchmarks, while
allowing for scaling to arbitrarily large graphs and parallelization on
multiple machines. We train and evaluate embeddings on several large social
network graphs as well as the full Freebase dataset, which contains over 100
million nodes and 2 billion edges.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lerer_A/0/1/0/all/0/1&quot;&gt;Adam Lerer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_L/0/1/0/all/0/1&quot;&gt;Ledell Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shen_J/0/1/0/all/0/1&quot;&gt;Jiajun Shen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lacroix_T/0/1/0/all/0/1&quot;&gt;Timothee Lacroix&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wehrstedt_L/0/1/0/all/0/1&quot;&gt;Luca Wehrstedt&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bose_A/0/1/0/all/0/1&quot;&gt;Abhijit Bose&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Peysakhovich_A/0/1/0/all/0/1&quot;&gt;Alex Peysakhovich&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12436">
<title>From Variational to Deterministic Autoencoders. (arXiv:1903.12436v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1903.12436</link>
<description rdf:parseType="Literal">&lt;p&gt;Variational Autoencoders (VAEs) provide a theoretically-backed framework for
deep generative models. However, they often produce &quot;blurry&quot; images, which is
linked to their training objective. Sampling in the most popular
implementation, the Gaussian VAE, can be interpreted as simply injecting noise
to the input of a deterministic decoder. In practice, this simply enforces a
smooth latent space structure. We challenge the adoption of the full VAE
framework on this specific point in favor of a simpler, deterministic one.
Specifically, we investigate how substituting stochasticity with other explicit
and implicit regularization schemes can lead to a meaningful latent space
without having to force it to conform to an arbitrarily chosen prior. To
retrieve a generative mechanism for sampling new data points, we propose to
employ an efficient ex-post density estimation step that can be readily adopted
both for the proposed deterministic autoencoders as well as to improve sample
quality of existing VAEs. We show in a rigorous empirical study that
regularized deterministic autoencoding achieves state-of-the-art sample quality
on the common MNIST, CIFAR-10 and CelebA datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ghosh_P/0/1/0/all/0/1&quot;&gt;Partha Ghosh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sajjadi_M/0/1/0/all/0/1&quot;&gt;Mehdi S. M. Sajjadi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vergari_A/0/1/0/all/0/1&quot;&gt;Antonio Vergari&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Black_M/0/1/0/all/0/1&quot;&gt;Michael Black&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Scholkopf_B/0/1/0/all/0/1&quot;&gt;Bernhard Sch&amp;#xf6;lkopf&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12453">
<title>Frowning Frodo, Wincing Leia, and a Seriously Great Friendship: Learning to Classify Emotional Relationships of Fictional Characters. (arXiv:1903.12453v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/1903.12453</link>
<description rdf:parseType="Literal">&lt;p&gt;The development of a fictional plot is centered around characters who closely
interact with each other forming dynamic social networks. In literature
analysis, such networks have mostly been analyzed without particular relation
types or focusing on roles which the characters take with respect to each
other. We argue that an important aspect for the analysis of stories and their
development is the emotion between characters. In this paper, we combine these
aspects into a unified framework to classify emotional relationships of
fictional characters. We formalize it as a new task and describe the annotation
of a corpus, based on fan-fiction short stories. The extraction pipeline which
we propose consists of character identification (which we treat as given by an
oracle here) and the relation classification. For the latter, we provide
results using several approaches previously proposed for relation
identification with neural methods. The best result of 0.45 F1 is achieved with
a GRU with character position indicators on the task of predicting undirected
emotion relations in the associated social network graph.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_E/0/1/0/all/0/1&quot;&gt;Evgeny Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Klinger_R/0/1/0/all/0/1&quot;&gt;Roman Klinger&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12600">
<title>A proof of convergence of multi-class logistic regression network. (arXiv:1903.12600v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1903.12600</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper revisits the special type of a neural network known under two
names. In the statistics and machine learning community it is known as a
multi-class logistic regression neural network. In the neural network
community, it is simply the soft-max layer. The importance is underscored by
its role in deep learning: as the last layer, whose autput is actually the
classification of the input patterns, such as images. Our exposition focuses on
mathematically rigorous derivation of the key equation expressing the gradient.
The fringe benefit of our approach is a fully vectorized expression, which is a
basis of an efficient implementation. The second result of this paper is the
positivity of the second derivative of the cross-entropy loss function as
function of the weights. This result proves that optimization methods based on
convexity may be used to train this network. As a corollary, we demonstrate
that no $L^2$-regularizer is needed to guarantee convergence of gradient
descent.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Rychlik_M/0/1/0/all/0/1&quot;&gt;Marek Rychlik&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.10209">
<title>Capacity of Quantum Private Information Retrieval with Multiple Servers. (arXiv:1903.10209v1 [quant-ph] CROSS LISTED)</title>
<link>http://arxiv.org/abs/1903.10209</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider the capacity of quantum private information retrieval (QPIR) with
multiple servers. In the QPIR problem with multiple servers, a user retrieves a
classical file by downloading quantum systems from multiple servers each of
which containing the whole classical file set, without revealing the identity
of the retrieved file to any individual server. The QPIR capacity is defined as
the maximum rate of the file size over the whole dimension of the downloaded
quantum systems. Assuming the preexisting entanglement among servers, we prove
that the QPIR capacity with multiple servers is 1 regardlessly of the number of
servers and files. We propose a rate-one protocol which can be implemented by
using only two servers. This capacity-achieving protocol outperforms its
classical counterpart in the sense of the capacity, server secrecy, and upload
cost.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Song_S/0/1/0/all/0/1&quot;&gt;Seunghoan Song&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Hayashi_M/0/1/0/all/0/1&quot;&gt;Masahito Hayashi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.11579">
<title>Effect of Values and Technology Use on Exercise: Implications for Personalized Behavior Change Interventions. (arXiv:1903.11579v1 [cs.HC] CROSS LISTED)</title>
<link>http://arxiv.org/abs/1903.11579</link>
<description rdf:parseType="Literal">&lt;p&gt;Technology has recently been recruited in the war against the ongoing obesity
crisis; however, the adoption of Health &amp;amp; Fitness applications for regular
exercise is a struggle. In this study, we present a unique demographically
representative dataset of 15k US residents that combines technology use logs
with surveys on moral views, human values, and emotional contagion. Combining
these data, we provide a holistic view of individuals to model their physical
exercise behavior. First, we show which values determine the adoption of Health
&amp;amp; Fitness mobile applications, finding that users who prioritize the value of
purity and de-emphasize values of conformity, hedonism, and security are more
likely to use such apps. Further, we achieve a weighted AUROC of .673 in
predicting whether individual exercises, and we also show that the application
usage data allows for substantially better classification performance (.608)
compared to using basic demographics (.513) or internet browsing data (.546).
We also find a strong link of exercise to respondent socioeconomic status, as
well as the value of happiness. Using these insights, we propose actionable
design guidelines for persuasive technologies targeting health behavior
modification.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mejova_Y/0/1/0/all/0/1&quot;&gt;Yelena Mejova&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kalimeri_K/0/1/0/all/0/1&quot;&gt;Kyriaki Kalimeri&lt;/a&gt;</dc:creator>
</item>
</rdf:RDF>